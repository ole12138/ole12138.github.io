<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>概率论与数理统计 on Jingmin's blog</title><link>https://ole12138.github.io/series/%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1/</link><description>Recent content in 概率论与数理统计 on Jingmin's blog</description><generator>Hugo -- gohugo.io</generator><language>zh-cn</language><copyright>Copyright (c) 2020, Jingmin; All rights reserved.</copyright><lastBuildDate>Thu, 17 Dec 2020 19:57:46 +0800</lastBuildDate><atom:link href="https://ole12138.github.io/series/%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1/feed.xml" rel="self" type="application/rss+xml"/><item><title>概率论与数理统计-数理统计-参数估计</title><link>https://ole12138.github.io/post/%E6%95%B0%E5%AD%A6%E6%80%BB%E7%BB%93/%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1-%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1-%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1/</link><pubDate>Thu, 17 Dec 2020 19:57:46 +0800</pubDate><guid>https://ole12138.github.io/post/%E6%95%B0%E5%AD%A6%E6%80%BB%E7%BB%93/%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1-%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1-%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1/</guid><description>概率论与数理统计-数理统计-参数估计 统计推断的基本问题可以分为两大类，一类是估计问题，另一类是假设检验问题。本章讨论总体参数的点估计和区间估计.
点估计 设总体X的分布函数的形式已知，但它的一个或多个参数未知，借助于总体X的一个样本来估计总体未知参数的值的问题称为参数的点估计问题
点估计问题的一般提法如下: 设总体 \(X\) 的分布函数 \(F(x ; \theta)\) 的形式为已知, $ $ 是待估参数. \(X_{1}, X_{2}, \cdots, X_{n}\) 是 \(X\) 的一个样本 \(, x_{1}, x_{2}, \cdots, x_{n}\) 是相应的一个样本值. 点估计间题就是要构造一个适当的统计量 \(\hat{\theta}\left(X_{1}, X_{2}, \cdots, X_{n}\right),\) 用它的观察值 \(\hat{\theta}\left(x_{1}, x_{2}, \cdots, x_{n}\right)\) 作为未知参数 \(\theta\) 的近似值. 我们称 \(\hat{\theta}\left(X_{1}, X_{2}, \cdots, X_{n}\right)\) 为 \(\theta\) 的估计量,称 \(\hat{\theta}\left(x_{1}, x_{2}, \cdots, x_{n}\right)\) 为 \(\theta\) 的估计值. 在不致混淆的情况下统称估计量和估计值为估计。
注意：由于估计量是样本的函数. 因此对于不同的样本值， \(\theta\) 的估计值一般是不相同的.
矩估计法 设 \(X\) 为连续型随机变量,其概率密度为 \(f\left(x ; \theta_{1}, \theta_{2}, \cdots, \theta_{k}\right),\) 或 \(X\) 为离散型随机变量,其分布律为 \(P\{X=x\}=p\left(x ; \theta_{1}, \theta_{2}, \cdots, \theta_{k}\right),\) 其中 \(\theta_{1}, \theta_{2}, \cdots, \theta_{k}\) 为待估参数 \(, X_{1}, X_{2}, \cdots, X_{n}\) 是来自 \(X\) 的样本.</description></item><item><title>概率论与数理统计-数理统计-基本概念</title><link>https://ole12138.github.io/post/%E6%95%B0%E5%AD%A6%E6%80%BB%E7%BB%93/%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1-%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1-%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/</link><pubDate>Sun, 13 Dec 2020 07:31:02 +0800</pubDate><guid>https://ole12138.github.io/post/%E6%95%B0%E5%AD%A6%E6%80%BB%E7%BB%93/%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1-%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1-%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/</guid><description>概率论与数理统计-数理统计-基本概念 前面章节讲述了概率论的基本内容，随后将讲述数理统计。
数理统计以概率论为理论基础，根据试验或观察得到的数据，来研究随机现象，对研究对象的客观规律性作出种种合理的估计和判断。
数理统计的内容包括：
如何收集、整理数据资料1 如何对所得的数据资料进行分析、研究，从而对所研究的对象的性质、特点作出推断（统计推断）。 概率论与数理统计的对比：
在概率论中，我们所研究的随机变量，它的分布都是假设已知的，在这一前提下去研究它的性质、特点和规律性，例如求出它的数字特征，讨论随机变量函数的分布，介绍常用的各种分布等。 在数理统计中，我们研究的随机变量，它的分布是未知的，或者是不完全知道的，人们是通过对所研究的随机变量进行重复独立的观察，得到许多观察值，对这些数据进行分析，从而对所研究的随机变量的分布作出种种推断的。
本章我们介绍总体、随机样本及统计量等基本概念，并着重介绍几个常用统计量及抽样分布。
总体与样本 总体的概念 我们知道，随机试验的结果很多是可以用数来表示的，另有一些试验的结果虽是定性的，但总可以将它数量化。
例如 例如，检验某个学校学生的血型这一试验，其可能结果有O型、A型、B型、AB型4种，是定性的。如果分别以1,2,3,4依次记这4种血型，那么试验的结果就能用数来表示了。 研究对象的总体，简称为总体。 而在数理统计中，我们往往关心研究对象的某一项数量指标（即随机变量，例如研究某种型号灯泡的寿命这一数量指标），考虑与这一数量指标相联系的随机试验，对这一数量指标进行试验或观察，我们将试验的全部可能的观察值称为总体2，这些值不一定都不相同，数目上也不一定是有限的，每一个可能观察值称为个体。 总体中所包含的个体的个数称为总体的容量。容量为有限的称为有限总体，容量为无限的称为无限总体。
总体中的每一个个体是随机试验的一个观察值，因此它是某一随机变量X的值，这样，一个总体对应于一个随机变量X.我们对总体的研究就是对一个随机变量X的研究，X的分布函数和数字特征就称为总体的分布函数和数字特征，今后将不区分总体与相应的随机变量，笼统称为总体X
样本的概念 样本的引入 在实际中，总体的分布一般是未知的，或只知道它具有某种形式而其中包含着未知参数。 在数理统计中，人们都是通过从总体中抽取一部分个体，根据获得的数据来对总体分布作出推断的。被抽出的部分个体叫做总体的一个样本。
所谓从总体抽取一个个体，就是对总体X进行一次观察并记录其结果。 我们在相同的条件下对总体X，进行n次重复的、独立的观察，将n次观察结果按试验的次序记为\(X_{1}, X_{2}, \cdots, X_{n}\)。 由于\(X_{1}, X_{2}, \cdots, X_{n}\)是都随机变量X的观察结果，且每次观察都是在相同条件下进行的，有理由认为\(X_{1}, X_{2}, \cdots, X_{n}\)都是与X同分布的随机变量。 由于\(X_{1}, X_{2}, \cdots, X_{n}\)是都随机变量X的观察结果，且每次观察都是独立进行的，则\(X_{1}, X_{2}, \cdots, X_{n}\)作为随机变量是相互独立的。 这样获取的互相独立的、与X同分布的\(X_{1}, X_{2}, \cdots, X_{n}\)，称为来自总体的一个简单随机样本。
当 \(n\) 次观察一经完成,我们就得到一组实数 \(x_{1}, x_{2}, \cdots, x_{n},\) 它们依次是随机 变量 \(X_{1}, X_{2}, \cdots, X_{n}\) 的观察值,称为样本值.
对于有限总体，采用放回抽样（独立重复试验）就能得到简单随机样本，但放回抽样使用起来不方便，当个体的总数N比要得到的样本的容量n大得多时，在实际中可将不放回抽样近似地当作放回抽样来处理。 至于无限总体，因抽取一个个体不影响它的分布，所以总是用不放回抽样例如，在生产过程中，每隔一定时间抽取一个个体，抽取n个就得到一个简单随机样本，实验室中的记录，水文、气象等观察资料都是样本。试制新产品得到的样品的质量指标，也常被认为是样本
样本的定义 设 \(X\) 是具有分布函数 \(F\) 的随机变量,若 \(X_{1}, X_{2}, \cdots, X_{n}\) 是具有同一分布函数 \(F\) 的、相互独立的随机变量,则称 \(X_{1}, X_{2}, \cdots, X_{n}\) 为从分布函数 \(F\) （ 或总体F、或总体X）得到的容量为n的简单随机样本，简称样本，它们的观察值\(x_{1}, x_{2}, \cdots, x_{n}\) 称为样本值,又称为 \(X\) 的 \(n\) 个独立的观察值.</description></item><item><title>概率论与数理统计-概率论-大数定律与中心极限定理</title><link>https://ole12138.github.io/post/%E6%95%B0%E5%AD%A6%E6%80%BB%E7%BB%93/%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1-%E6%A6%82%E7%8E%87%E8%AE%BA-%E5%A4%A7%E6%95%B0%E5%AE%9A%E5%BE%8B%E4%B8%8E%E4%B8%AD%E5%BF%83%E6%9E%81%E9%99%90%E5%AE%9A%E7%90%86/</link><pubDate>Thu, 03 Dec 2020 07:31:02 +0800</pubDate><guid>https://ole12138.github.io/post/%E6%95%B0%E5%AD%A6%E6%80%BB%E7%BB%93/%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1-%E6%A6%82%E7%8E%87%E8%AE%BA-%E5%A4%A7%E6%95%B0%E5%AE%9A%E5%BE%8B%E4%B8%8E%E4%B8%AD%E5%BF%83%E6%9E%81%E9%99%90%E5%AE%9A%E7%90%86/</guid><description>概率论与数理统计-大数定律与中心极限定理 本章介绍概率统计理论中非常重要的两类定理：大数定律和中心极限定理。
大数定律讨论的是一列随机变量的均值的收敛性问题。（独立、同期望、同方差的随机变量列\(\{X_n\}\)的算数平均依概率收敛于期望\(\mu\)）
中心极限定理考虑的是一列随机变量和的极限分布问题。（独立、同分布的随机变量列\(\{X_n\}\)的和的分布近似为正态分布）
基本概念 依概率收敛 设\(X_{1}, X_{2}, \cdots\)为一随机变量序列，X为一随机变量， 若对任意\(\epsilon&amp;gt;0\)，有\(\lim _{n \rightarrow \infty} P\left(\left|X_{n}-X\right| \geqslant \epsilon\right)=0\)， 则称\(\{x_n\)}$依概率收敛于X.
切比雪夫不等式 切比雪夫不等式的提出 19世纪俄国数学家切比雪夫研究统计规律中，论证并用标准差表达了一个不等式，这个不等式具有普遍的意义，被称作切比雪夫定理，其大意是：
任意一个数据集中，位于其平均数m个标准差范围内的比例（或部分）总是至少为1－1/m2， 其中m为大于1的任意正数。对于m=2，m=3和m=5有如下结果：
所有数据中，至少有3/4（或75%）的数据位于平均数2个标准差范围内。 所有数据中，至少有8/9（或88.9%）的数据位于平均数3个标准差范围内。 所有数据中，至少有24/25（或96%)的数据位于平均数5个标准差范围内 。 换言之, 与平均相差k个标准差以上的值，数目不多于1/k^2
与平均相差2个标准差以上的值，数目不多于1/4 与平均相差3个标准差以上的值，数目不多于1/9 与平均相差5个标准差以上的值，数目不多于1/25 切比雪夫不等式的数学描述 说法一： 设随机变量X的数学期望为\(\mu\)，方差为\(\sigma^2\)， 则对于任意\(\epsilon&amp;gt;0\)，有\(P(|X-\mu| \geqslant \epsilon) \leqslant \frac{\sigma^{2}}{\epsilon^{2}}\)
说法二： 设随机变量X的数学期望为\(\mu\)，方差为\(\sigma^2\)， 则对于任意\(\epsilon&amp;gt;0\)，有\(P(|X-\mu|&amp;lt;\epsilon) \geqslant 1-\frac{\sigma^{2}}{\epsilon^{2}}\)
说法三：（取\(\epsilon=k \sigma\)） 设随机变量X的数学期望为\(\mu\)，方差为\(\sigma^2\)， 则\(P(\mu -k\sigma &amp;lt;X&amp;lt;\mu +k\sigma )\geq 1-{\frac {1}{k^{2}}}\)
证明: 以下仅证明X是连续型随机变量的情形(X是离散型随机变量类似): 设随机变量X的密度函数为\(f(x)\),则有 \(\begin{aligned} P(|X-\mu| \geqslant \epsilon) &amp;amp;=\int_{|x-\mu| \geqslant \epsilon} f(x) \mathrm{d} x \leqslant \int_{|x-\mu| \geqslant \epsilon} \frac{|x-\mu|^{2}}{\epsilon^{2}} f(x) \mathrm{d} x \\ &amp;amp; \leqslant \frac{1}{\epsilon^{2}} \int_{-\infty}^{+\infty}(x-\mu)^{2} f(x) \mathrm{d} x=\frac{\sigma^{2}}{\epsilon^{2}} \end{aligned}\)</description></item><item><title>概率论与数理统计-概率论-随机变量的数字特征</title><link>https://ole12138.github.io/post/%E6%95%B0%E5%AD%A6%E6%80%BB%E7%BB%93/%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1-%E6%A6%82%E7%8E%87%E8%AE%BA-%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E7%9A%84%E6%95%B0%E5%AD%97%E7%89%B9%E5%BE%81/</link><pubDate>Fri, 27 Nov 2020 09:24:48 +0800</pubDate><guid>https://ole12138.github.io/post/%E6%95%B0%E5%AD%A6%E6%80%BB%E7%BB%93/%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1-%E6%A6%82%E7%8E%87%E8%AE%BA-%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E7%9A%84%E6%95%B0%E5%AD%97%E7%89%B9%E5%BE%81/</guid><description>概率论与数理统计-随机变量的数字特征 随机变量及其概率分布章节，我们讨论了随机变量的分布函数，它完整反映了随机变量（在一定范围内）的概率特性。
然而很多时候，我们不需要或者很难知道随机变量的完整特性，只需要知道它的某些重要指标。 （比如在调查一群人的身高或者某地居民的收入时，我们经常关心这些量的均值或者个体之间的差异。在碰到多个随机变量时，还需要一些指标来反映这些随机变量之间的关系。）
与随机变量密切相关的指标统称为数字特征。重要的数字特征有数学期望、方差、协方差、相关系数以及矩等.
数学期望 离散型随机变量的数学期望 离散型随机变量的数学期望的定义 设离散型随机变量X的概率分布律为\(P\left(X=x_{k}\right)=p\left(x_{k}\right), \quad k=1,2, \cdots\) 如果无穷级数\(\sum_{k=1}^{\infty} x_{k} p\left(x_{k}\right)\)绝对收敛， 则称\(\sum_{k=1}^{\infty} x_{k} p\left(x_{k}\right)\)为（离散型）随机变量X的数学期望，简称数学期望或均值， 记作 \(E(X)\)，即\(E(X)=\sum_{k=1}^{\infty} x_{k} p\left(x_{k}\right)\)
常见离散型随机变量的数学期望 0-1分布的期望\(E(X)=p\) 设X服从参数为p的两点分布（0-1分布），即\(P(X=0)=1-p, \quad P(X=1)=p, \quad 0&amp;lt;p&amp;lt;1\) 则\(E(X)=1 \times p+0 \times(1-p)=p\)
二项分布\(X \sim B(n, p)\)的期望\(E(X)=n p\) 证明（方法一）：
因为\(X \sim B(n, p)\)，所以\(P(X=k)=C_{n}^{k} p^{k}(1-p)^{n-k}, \quad k=0,1,2, \cdots, n\) 则： \(\begin{aligned} E(X) &amp;amp;=\sum_{k=0}^{n} k \mathrm{C}_{n}^{k} p^{k}(1-p)^{n-k}=\sum_{k=0}^{n} \frac{k n !}{k !(n-k) !} p^{k}(1-p)^{n-k} \\ &amp;amp;=n p \sum_{k=1}^{n} \frac{(n-1) !}{(k-1) !</description></item><item><title>概率论与数理统计-概率论-随机事件与概率</title><link>https://ole12138.github.io/post/%E6%95%B0%E5%AD%A6%E6%80%BB%E7%BB%93/%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1-%E6%A6%82%E7%8E%87%E8%AE%BA-%E9%9A%8F%E6%9C%BA%E4%BA%8B%E4%BB%B6%E4%B8%8E%E6%A6%82%E7%8E%87/</link><pubDate>Wed, 25 Nov 2020 05:24:48 +0800</pubDate><guid>https://ole12138.github.io/post/%E6%95%B0%E5%AD%A6%E6%80%BB%E7%BB%93/%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1-%E6%A6%82%E7%8E%87%E8%AE%BA-%E9%9A%8F%E6%9C%BA%E4%BA%8B%E4%BB%B6%E4%B8%8E%E6%A6%82%E7%8E%87/</guid><description>概率论与数理统计-随机事件与概率 基本概念 现象 现象
现象是事物表现出来的，能被人感觉到的一切情况。现象是人能够看到、听到、闻到、触摸到的。
按照是否有自然属性来分，现象可分为自然现象和社会现象。 按照现象的结果是否唯一来分，现象可分为确定性现象和随机现象。
概率统计研究的主要目标是随机现象，即现象的结果有多种可能，且事先无法准确预测将会发生哪种结果。
随机试验 对随机现象进行一次观察，称为一次随机试验（试验）
概率论中将满足下面三个条件的试验称为随机试验，简称试验：
可在相同的条件下重复进行； 每次试验的结果不止一个 试验之前不能确定哪一个结果会发生，但所有的结果是明确可知的 样本点 随机试验中每一个可能发生的结果（现象观察到的结果），称为一个样本点。一般记作\(\omega\)
样本空间 随机试验中所有可能发生的结果，即所有的样本点，称为样本空间。一般记作\(\Omega= \{\omega\}\).
随机事件
样本空间的任意子集,都称为随机事件（事件）。
特殊事件(不可能事件与必然事件) 不可能事件：不含样本点的事件（不含任何元素），称为不可能事件。用集合的语言描述为空集\(\varnothing\)
必然事件：包含样本空间所有样本点的事件（包含所有可能的结果，因此该事件一定会发生），称为必然事件。用集合的语言描述为样本空间全集\(\Omega\)
事件的发生 若事件A中的某个样本点在随机试验中出现（某个样本点被观测到），称为事件A发生。 即事件A中某个样本点被观测到\(\Leftrightarrow\)事件A发生
事件的关系与运算 经常要用简单事件表示一些复杂事件（尤其是研究概率的过程中）。 因此需要讨论使事件的关系与运算。
这里的事件用集合来表示，所以实际上是集合的关系与运算。
包含关系\(A \subset B\) 定义:A发生导致B发生,称:B包含A,或称A被B包含.记\(A \subset B\).集合论：A的元素必属于B。图示：
B包含A （定义，称，记，集合论，图）
相等关系A=B \(B \subset A, B \subset A\)，则A=B
互斥关系\(A B=\varnothing\) 在试验中，事件A与B不能同时发生，即\(A B=\varnothing\)，则称A，B互为互斥事件
设\(A_1, A_2, \cdots, A_n\)是一组事件， 若它们两两互斥(都是互斥事件)， 且它们的并等于样本空间（\(\cup_{i=1}^{n} A_i = \Omega\)）， 称这组事件构成一个互不相容的完备事件组（完备事件组）
对立关系 每次事件中，“事件A不发生”的事件称为事件A的对立事件或者逆事件。记为\(\bar{A}\)。
性质： \((1) A+A=\Omega\) \((2) A \bar{A}=\varnothing\)</description></item><item><title>概率论与数理统计-概率论-随机变量及其分布</title><link>https://ole12138.github.io/post/%E6%95%B0%E5%AD%A6%E6%80%BB%E7%BB%93/%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1-%E6%A6%82%E7%8E%87%E8%AE%BA-%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E5%8F%8A%E5%85%B6%E6%A6%82%E7%8E%87%E5%88%86%E5%B8%83/</link><pubDate>Wed, 25 Nov 2020 05:24:48 +0800</pubDate><guid>https://ole12138.github.io/post/%E6%95%B0%E5%AD%A6%E6%80%BB%E7%BB%93/%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1-%E6%A6%82%E7%8E%87%E8%AE%BA-%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E5%8F%8A%E5%85%B6%E6%A6%82%E7%8E%87%E5%88%86%E5%B8%83/</guid><description>概率论与数理统计-随机变量及其分布 （一维）随机变量与分布函数 随机变量的概念 随机变量的引入 对于不同的随机现象， 有些随机现象的结果（样本点）往往是一个某个数量指标，可以用实数来表示（比如色子掷出点数）； 有些随机现象的结果（样本点）没有数量特征，只标记某种属性（比如硬币抛出正反面，公司某年是盈是亏）。
对于没有数量特征的样本点，我们可以人为引入数字来标记结果。 这样，每个随机现象的结果（或者说每次随机试验的结果），都有一个实数与之对应。
随机变量的定义 设试验的样本空间为\(\Omega\)，如果对于每个样本点\(\omega \in \Omega\)，都有一个实数\(X(\omega)\)与之对应，则称\(X(\omega)\)为随机变量。
注意：随机变量\(X(\omega)\)常简写为X 。但是，随机变量实际上是个因变量，对应的自变量是样本空间中的样本点。 注意：随机变量常用大写英文字母X,Y,Z等，或者希腊字母\(\xi,\eta,\zeta\)等表示。
落在某范围的随机变量可以表示随机事件 有了随机变量，随机事件（样本空间的子集）就可以用随机变量的区间来描述。 即随机事件可以用随机变量落在某个范围内来表示。
例如，抛掷硬币3次，用X表示正面朝上的次数， 随机事件”至少有两次正面朝上“可以写为\(\{\omega | X(\omega) \ge 2\}\)，一般直接简写为\(\{ X \ge 2\}\)
随机变量的分布函数 在随机事件章节，我们讨论过随机事件发生的概率。 我们已经知道随机事件可以用随机变量落在某个范围来表示， 则我们可以用随机变量描述事件的概率，即随机变量落在某个范围内的概率，引入随机变量的（概率）分布函数。
随机变量的分布函数定义 设X是一个随机变量，称\(F(x)=P(X \le x) , -\infty &amp;lt; x &amp;lt; +\infty\)为随机变量X的分布函数。
注意：\(F(x)\)的定义域是实数集\(R\)，对于每个实数x，\(F(X)\)表示随机变量小于等于x的概率，显然\(0\le x \le 1\)
随机变量的分布函数的性质 下面列出的是任何随机变量的分布函数的共性。之后还会单独讨论离散型随机变量和连续性随机变量的特性。
\(F(-\infty)=\lim_{-\infty} F(x) = 0, F(+\infty)=\lim_{+\infty} F(x) = 1\) \(P(a&amp;lt;X\le b) = F(b) - F(a)\) 因为\(\{a &amp;lt; X \le b\} = \{ X \le b\} - \{X \le a\}\) 所以随机变量X落在区间\((a,b]\)的概率为：\(P(a&amp;lt;X\le b) = P(b) - P(a) = F(b) - F(a)\)</description></item></channel></rss>