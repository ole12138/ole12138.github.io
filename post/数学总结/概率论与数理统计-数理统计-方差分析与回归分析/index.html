<!doctype html><html lang=en><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><link rel=alternate href=/index.xml type=application/rss+xml title="Jingmin's blog"><link rel=icon href=https://ole12138.gitee.io//favicon.ico><title>概率论与数理统计-数理统计-方差分析与回归分析 - Jingmin's blog</title><link rel=stylesheet href=https://ole12138.gitee.io//css/highlight/github.css><link rel=stylesheet href=https://ole12138.gitee.io//css/bootstrap.min.css><link rel=stylesheet href=https://ole12138.gitee.io//css/bootstrap-theme.min.css><link rel=stylesheet href=https://ole12138.gitee.io//css/theme.css><link rel=stylesheet href=https://ole12138.gitee.io//css/bootie-docs.css><link rel=stylesheet href=https://ole12138.gitee.io//css/site.css></head><body role=document><nav class="navbar navbar-inverse navbar-fixed-top"><div class=container><div class=navbar-header><button type=button class="navbar-toggle collapsed" data-toggle=collapse data-target=#navbar aria-expanded=false aria-controls=navbar>
<span class=sr-only>Toggle navigation</span>
<span class=icon-bar></span><span class=icon-bar></span><span class=icon-bar></span></button>
<a class=navbar-brand href=https://ole12138.gitee.io//>Jingmin's blog</a></div><div id=navbar class="navbar-collapse collapse"><ul class="nav navbar-nav"><li><a href=https://ole12138.gitee.io//>Home</a></li><li><a href=/post>All posts</a></li><li><a href=/tags>Tags</a></li><li><a href=/series>Series</a></li><li><a href=/categories>Categories</a></li><li><a href=/about>About</a></li></ul></div></div></nav><div class=container><div class=row><div class="col-sm-8 doc-main"><main role=main><article><a id=title></a><h1 class=doc-entry-title>概率论与数理统计-数理统计-方差分析与回归分析</h1><div class=doc-entry-meta><span><time datetime=2020-11-25>November 25, 2020</time></span></div><section><h1 id=概率论与数理统计-数理统计-方差分析与回归分析>概率论与数理统计-数理统计-方差分析与回归分析</h1><p>//TODO</p><p>参考：<a href=https://baike.baidu.com/item/回归分析>https://baike.baidu.com/item/%E5%9B%9E%E5%BD%92%E5%88%86%E6%9E%90</a> 参考：概率论与数理统计.浙大第四版</p><p>方差分析和回归分析都是数理统计中具有广泛应用的内容. 本章对它们的 最基本部分作一介绍.</p><p>（本章节最好直接阅读教材，这里总结并不到位。这里引入了许多统计量的分布，证明参见：概率论与数理统计.浙大第四版）</p><h2 id=单因素试验的方差分析>单因素试验的方差分析</h2><p>在科学试验和生产实践中，影响一事物的因素往往是很多的。 例如，在化工生产中，有原料成分、原料剂量、催化剂、反应温度、压力溶液浓度、反应时间、机器设备及操作人员的水平等因素每一因素的改变都有可能影响产品的数量和质量。 有些因素影响较大，有些较小。为了使生产过程得以稳定，保证优质、高产就<strong>有必要找出对产品质量有显著影响的那些因素</strong>.为此，我们需进行试验。 <strong>方差分析就是根据试验的结果进行分析，鉴别各个有关因素对试验结果影响的有效方法</strong>.</p><h3 id=单因素试验>单因素试验</h3><p>在试验中，我们将要考察的指标称为<strong>试验指标</strong>（对应随机变量）。影响试验指标的条件称为<strong>因素</strong>.（随机变量的参数，作为自变量看待） 因素可分为两类， 一类是人们可以控制的（可控因素）； 一类是人们不能控制的（不可控因素）。例如，反应温度、原料剂量、溶液浓度等是可以控制的，而测量误差、气象条件等一般是难以控制的。以下我们所说的因素都是指可控因素。 因素所处的状态，称为该<strong>因素的水平</strong>（见下述各例）。 如果在一项试验的过程中只有一个因素在改变称为<strong>单因素试验</strong>，如果多于一个因素在改变称为<strong>多因素试验</strong>。</p><blockquote><p>例子 设有三台机器,用来生产规格相同的铝合金薄板. 取样,测量薄板的 厚度精确至千分之一厘米.得结果： <img src=https://picgo12138.oss-cn-hangzhou.aliyuncs.com/md/image-20201225000929380.png alt=image-20201225000929380></p><p>这里，试验的指标是薄板的厚度。机器为因素，不同的三台机器就是这个因素的三个不同的水平。 我们假定除机器这一因素外，材料的规格、操作人员的水平等其他条件都相同。这是单因素试验。 试验的目的是为了考察各台机器所生产的薄板的厚度有无显著的差异，即考察机器这一因素对厚度有无显著的影响。 如果厚度有显著差异，就表明机器这一因素对厚度的影响是显著的</p></blockquote><p>本节仅限于讨论单因素试验.</p><h3 id=方差分析法>方差分析法</h3><blockquote><p>在实际中试验的指标往往要受到一种或多种因素的影响。方差分析就是通过对试验数据进行分析，检验方差相同的多个（多于两个）正态总体的均值是否相等，用以判断各因素对试验指标的影响是否显著。方差分析按影响试验指标的因素的个数分为单因素方差分析、双因素方差分析和多因素方差分析，本章只介绍前面两种。</p></blockquote><p>在上面例子中,我们在因素的每一个水平下进行独立试验,其结果是一个样本. 表中数据可<strong>看成</strong>来自<strong>三个不同总体</strong>(每个水平对应一个总体)的样本值. 将各个总体的均值依次记为 <span class="math inline">\(\mu_{1}, \mu_{2}, \mu_{3}\)</span>. 上面的例子的问题是：机器这一因素对厚度的影响是显著？按题意<strong>需检验假设</strong>： <span class="math inline">\(H_{0}: \mu_{1}=\mu_{2}=\mu_{3}\)</span> <span class="math inline">\(H_{1}: \mu_{1}, \mu_{2}, \mu_{3}\)</span> 不全相等.</p><p>现在进而假设各总体均为正态变量,且各总体的方差相等,但参数均未知. 那么 这是一个检验同方差的多个正态总体均值是否相等的问题.</p><p>下面所要讨论的方差分析法,就是解决这类问题（检验同方差的多个正态总体均值是否相等）的一种统计方法.</p><h4 id=单因素试验方差分析的数学模型与假设检验问题>单因素试验方差分析的数学模型与假设检验问题</h4><p>现在开始讨论单因素试验的方差分析. 设因素 <span class="math inline">\(A\)</span> 有 <span class="math inline">\(s\)</span> 个水平 <span class="math inline">\(A_{1}, A_{2}, \cdots, A_{s},\)</span> 在水平 <span class="math inline">\(A_{j}(j=1,2, \cdots, s)\)</span> 下,进行 <span class="math inline">\(n_{j}\left(n_{j} \geqslant 2\right)\)</span> 次独立试验,得到如下图表的结果： <img src=https://picgo12138.oss-cn-hangzhou.aliyuncs.com/md/image-20201225002130712.png alt=image-20201225002130712></p><p>我们<strong>假定</strong> : 各个水平 <span class="math inline">\(A_{j}(j=1,2, \cdots, s)\)</span> 下的样本 <span class="math inline">\(X_{1 j}, X_{2 j}, \cdots, X_{n_{j} j}\)</span> 来自具有相同方差 <span class="math inline">\(\sigma^{2},\)</span> 均值分别为 <span class="math inline">\(\mu_{j}(j=1,2, \cdots, s)\)</span> 的正态总体 <span class="math inline">\(N\left(\mu_{j}, \sigma^{2}\right), \mu_{j}\)</span> 与 <span class="math inline">\(\sigma^{2}\)</span> 未知. 且设不同水平 <span class="math inline">\(A_{j}\)</span> 下的样本之间相互独立.</p><p>由于 <span class="math inline">\(X_{i j} \sim N\left(\mu_{j}, \sigma^{2}\right),\)</span> 即有 <span class="math inline">\(X_{i j}-\mu_{j} \sim N\left(0, \sigma^{2}\right),\)</span> 故 <span class="math inline">\(X_{i j}-\mu_{j}\)</span> 可看成是随机误差. 记 <span class="math inline">\(X_{i j}-\mu_{j}=\varepsilon_{i j},\)</span> 则 <span class="math inline">\(X_{i j}\)</span> 可写成： <span class="math inline">\(\left.\begin{array}{l}X_{i j}=\mu_{j}+\varepsilon_{i j} \\ \varepsilon_{i j} \sim N\left(0, \sigma^{2}\right), \text { 各 } \varepsilon_{i j} \text { 独立 }, \\ i=1,2, \cdots, n_{j}, j=1,2, \cdots, s,\end{array}\right\}\)</span>， 其中 <span class="math inline">\(\mu_{j}\)</span> 与 <span class="math inline">\(\sigma^{2}\)</span> 均为未知参数. 上式称为<strong>单因素试验方差分析的数学模型</strong>. 这是本节的<strong>研究对象</strong>.</p><p><strong>方差分析的任务</strong>是对于以上模型： 1）检验 <span class="math inline">\(s\)</span> 个总体 <span class="math inline">\(N\left(\mu_{1}, \sigma^{2}\right), \cdots, N\left(\mu_{s}, \sigma^{2}\right)\)</span> 的均值是否相等,即检验假设： <span class="math inline">\(H_{0}: \mu_{1}=\mu_{2}=\cdots=\mu_{s}\)</span> <span class="math inline">\(H_{1}: \mu_{1}, \mu_{2}, \cdots, \mu_{s}\)</span> 不全相等. 2）作出未知参数 <span class="math inline">\(\mu_{1}, \mu_{2}, \cdots, \mu_{s}, \sigma^{2}\)</span> 的估计.</p><p>一些记号： 为了更好地讨论以上方差分析,我们将 <span class="math inline">\(\mu_{1}, \mu_{2}, \cdots, \mu_{s}\)</span> 的加权平均值<span class="math inline">\(\frac{1}{n} \sum_{j=1}^{s} n_{j} \mu_{j}\)</span> 记为 <span class="math inline">\(\mu,\)</span> 即<span class="math inline">\(\mu=\frac{1}{n} \sum_{j=1}^{s} n_{j} \mu_{j}\)</span>，其中 <span class="math inline">\(n=\sum_{j=1}^{s} n_{j}, \mu\)</span> 称为<strong>总平均</strong>. 再引入<span class="math inline">\(\delta_{j}=\mu_{j}-\mu, \quad j=1,2, \cdots, s\)</span>，此时有 <span class="math inline">\(n_{1} \delta_{1}+n_{2} \delta_{2}+\cdots+n_{s} \delta_{s}=0, \delta_{j}\)</span> 表示<strong>水平 <span class="math inline">\(A_{j}\)</span> 下的总体平均值与总平均的差异</strong>,习惯上将 <span class="math inline">\(\delta_{j}\)</span> 称为<strong>水平 <span class="math inline">\(A_{j}\)</span> 的效应</strong>.</p><p>有了上面的记号，<strong>单因素试验方差分析的数学模型</strong>可以改写成如下形式： <span class="math inline">\(\left.\begin{array}{l}X_{i j}=\mu+\delta_{j}+\varepsilon_{i j} \\ \varepsilon_{i j} \sim N\left(0, \sigma^{2}\right), \text { 各 } \varepsilon_{i j} \text { 独立 } \\ i=1,2, \cdots, n_{j}, j=1,2, \cdots, s \\ \sum_{j=1}^{s} n_{j} \delta_{j}=0\end{array}\right\}\)</span></p><p>有了上面的记号，假设检验问题也可以描述成如下形式： <span class="math inline">\(H_{0}: \delta_{1}=\delta_{2}=\cdots=\delta_{s}=0\)</span> <span class="math inline">\(H_{1}: \delta_{1}, \delta_{2}, \cdots, \delta_s\text {, 不全为零 } .\)</span></p><h4 id=平方和的分解>平方和的分解</h4><p>下面我们从平方和的分解着手,导出假设上面检验问题的检验统计量.</p><p>引入<strong>总偏差平方和</strong>：<span class="math inline">\(S_{T}=\sum_{j=1}^{s} \sum_{i=1}^{n_{j}}\left(X_{i j}-\bar{X}\right)^{2}\)</span>， 其中<span class="math inline">\(\bar{X}=\frac{1}{n} \sum_{j=1}^{s} \sum_{i=1}^{n_{j}} X_{i j}\)</span>是数据的总平均. <span class="math inline">\(\mathrm{S}_{\mathrm{T}}\)</span> 能<strong>反映全部试验数据之间的差异</strong>,因此 <span class="math inline">\(S_{T}\)</span> 又称为总变差.</p><p>记<strong>水平 <span class="math inline">\(A_{j}\)</span> 下的样本平均值</strong>为 <span class="math inline">\(\bar{X}_{\cdot j},\)</span> 即<span class="math inline">\(\bar{X}_{\cdot j}=\frac{1}{n_{j}} \sum_{i=1}^{n_{j}} X_{i j}\)</span></p><p>则可以改写<strong>总偏差平方和</strong><span class="math inline">\(S_{T}\)</span>： <span class="math inline">\(\begin{aligned} S_{T} &=\sum_{j=1}^{s} \sum_{i=1}^{n_{j}}\left[\left(X_{i j}-\bar{X}_{\cdot j}\right)+\left(\bar{X}_{\cdot j}-\bar{X}\right)\right]^{2} \\ &=\sum_{j=1}^{s} \sum_{i=1}^{n_{j}}\left(X_{i j}-\bar{X}_{\cdot j}\right)^{2}+\sum_{j=1}^{s} \sum_{i=1}^{n_{j}}\left(\bar{X}_{\cdot j}-\bar{X}\right)^{2}+2 \sum_{j=1}^{s} \sum_{i=1}^{n_{j}}\left(X_{i j}-\bar{X}_{\cdot j}\right)\left(\bar{X}_{\cdot j}-\bar{X}\right) \end{aligned}\)</span> 注意到上式第三项(即交叉项): <span class="math inline">\(2 \sum_{j=1}^{s} \sum_{i=1}^{n_{j}}\left(X_{i j}-\bar{X}_{\cdot j}\right)\left(\bar{X}_{\cdot j}-\bar{X}\right)\)</span> <span class="math inline">\(\quad=2 \sum_{i j}^{s}\left(\bar{X}_{\cdot j}-\bar{X}\right)\left[\sum_{i j}^{n_{j}}\left(X_{i j}-\bar{X}_{\cdot j}\right)\right]=2 \sum\left(\bar{X}_{\cdot j}-\bar{X}\right)\left(\sum_{i j}-n_{j} \bar{X}_{\cdot j}\right)=0\)</span></p><p>平方和分解式：我们将<strong>总偏差平方和</strong><span class="math inline">\(S_{T}\)</span>分解成为：<span class="math inline">\(S_{T}=S_{E}+S_{A}\)</span>， 其中<span class="math inline">\(S_{E}=\sum_{j=1}^{s} \sum_{i=1}^{n_{j}}\left(X_{i j}-\bar{X}_{\cdot j}\right)^{2}\)</span>，<span class="math inline">\(S_{E}\)</span> 的各项 <span class="math inline">\(\left(X_{i j}-\bar{X}_{\cdot j}\right)^{2}\)</span> 表示<strong>在水平 <span class="math inline">\(A_{j}\)</span> 下,样本观察值与样本均值的差异</strong> 这是由随机误差所引起的. <span class="math inline">\(S_{E}\)</span> 叫做<strong>误差平方和</strong>.<span class="math inline">\(,\)</span> <span class="math inline">\(S_{A}=\sum_{j=1}^{s} \sum_{i=1}^{n_{j}}\left(\bar{X}_{\cdot j}-\bar{X}\right)^{2}=\sum_{j=1}^{s} n_{j}\left(\bar{X}_{\cdot j}-\bar{X}\right)^{2}=\sum_{j=1}^{s} n_{j} \bar{X}_{\cdot j}^{2}-n \bar{X}^{2}\)</span>，<span class="math inline">\(S_{A}\)</span> 的各项 <span class="math inline">\(n_{j}\left(\bar{X}_{\cdot j}-\bar{X}\right)^{2}\)</span> 表示 <strong><span class="math inline">\(A_{j}\)</span> 水平下的样本平均值与数据总平均的差异</strong>,这是由水平 <span class="math inline">\(A_{j}\)</span> 的效应的差异以及随机误差引起的. <span class="math inline">\(S_{A}\)</span> 叫做因素 <span class="math inline">\(A\)</span> 的<strong>效应平方和</strong>.</p><h4 id=s_e-s_a-的统计特性><span class="math inline">\(S_{E}, S_{A}\)</span> 的统计特性</h4><p>为了引出上面检验问题的检验统计量,我们依次来讨论 <span class="math inline">\(S_{E}, S_{A}\)</span> 的一些统计特性. <span class="math inline">\(S_{E}=\sum_{i=1}^{n_{1}}\left(X_{i 1}-\bar{X}_{\cdot 1}\right)^{2}+\cdots+\sum_{i=1}^{n_{s}}\left(X_{i s}-\bar{X}_{\cdot s}\right)^{2}\)</span></p><p>注意每个j列都是一个正态总体总体 <span class="math inline">\(N\left(\mu_{j}, \sigma^{2}\right)\)</span>， 于是有<span class="math inline">\(\frac{\sum_{i=1}^{n_{j}}\left(X_{i j}-\bar{X}_{\cdot j}\right)^{2}}{\sigma^{2}} \sim \chi^{2}\left(n_{j}-1\right)\)</span></p><p>各列（各总体）互相独立，故<span class="math inline">\(S_{E}\)</span>式中各平方和相互独立. 由 <span class="math inline">\(\chi^{2}\)</span> 分布的可加性知<span class="math inline">\(\frac{S_{E}}{\sigma^{2}} \sim \chi^{2}\left(\sum_{i=1}^{s}\left(n_{j}-1\right)\right)\)</span>, 即：<span class="math inline">\(\frac{S_{E}}{\sigma^{2}} \sim \chi^{2}(n-s)\)</span>，</p><p>由上式还可知<span class="math inline">\(S_{E}\)</span> 的自由度为 <span class="math inline">\(n-s,\)</span> 且有<span class="math inline">\(E\left(S_{E}\right)=(n-s) \sigma^{2}\)</span></p><p>下面讨论 <span class="math inline">\(\mathrm{S}_{A}\)</span> 的统计特性, <span class="math inline">\(S_{A}=\sum_{j=1}^{s} \sum_{i=1}^{n_{j}}\left(\bar{X}_{\cdot j}-\bar{X}\right)^{2}=\sum_{j=1}^{s} n_{j}\left(\bar{X}_{\cdot j}-\bar{X}\right)^{2}=\sum_{j=1}^{s} n_{j} \bar{X}_{\cdot j}^{2}-n \bar{X}^{2}\)</span>， 我们看到 <span class="math inline">\(\mathrm{S}_{A}\)</span> 是 <span class="math inline">\(s\)</span> 个变量 <span class="math inline">\(\sqrt{n_{j}}\left(\bar{X}_{\cdot j}-\bar{X}\right)(j=1\)</span>, <span class="math inline">\(2, \cdots, s)\)</span> 的平方和， 它们之间仅有一个线性约束条件：<span class="math inline">\(\sum_{j=1}^{s} \sqrt{n_{j}}\left[\sqrt{n_{j}}\left(\bar{X}_{\cdot j}-\bar{X}\right)\right]=\sum_{j=1}^{s} n_{j}\left(\bar{X}_{\cdot j}-\bar{X}\right)=\sum_{j=1}^{s} \sum_{i=1}^{n_{j}} X_{i j}-n \bar{X}=0\)</span>， 故知 <span class="math inline">\(S_{A}\)</span> 的自由度是 <span class="math inline">\(s-1 .\)</span></p><p>由<span class="math inline">\(\mu=\frac{1}{n} \sum_{j=1}^{s} n_{j} \mu_{j}\)</span>，<span class="math inline">\(\bar{X}=\frac{1}{n} \sum_{j=1}^{s} \sum_{i=1}^{n_{j}} X_{i j}\)</span>，以及<span class="math inline">\(X_{ij}\)</span>的独立性， 知<span class="math inline">\(\bar{X} \sim N\left(\mu, \frac{\sigma^{2}}{n}\right)\)</span></p><p>可求得： <span class="math inline">\(\begin{aligned} E\left(S_{A}\right) &=E\left[\sum_{j=1}^{s} n_{j} \bar{X}_{\cdot j}^{2}-n \bar{X}^{2}\right]=\sum_{j=1}^{s} n_{j} E\left(\bar{X}_{\cdot j}^{2}\right)-n E\left(\bar{X}^{2}\right) \\ &=\sum_{j=1}^{s} n_{j}\left[\frac{\sigma^{2}}{n_{j}}+\left(\mu+\delta_{j}\right)^{2}\right]-n\left(\frac{\sigma^{2}}{n}+\mu^{2}\right) \\ &=(s-1) \sigma^{2}+2 \mu \sum_{j=1}^{s} n_{j} \delta_{j}+n \mu^{2}+\sum_{j=1}^{s} n_{j} \delta_{j}^{2}-n \mu^{2} \end{aligned}\)</span> 由改写后的单因素试验方差分析的数学模型可知<span class="math inline">\(\sum_{j=1}^{s} n_{j} \delta_{j}=0\)</span>， 即得<span class="math inline">\(E\left(S_{A}\right)=(s-1) \sigma^{2}+\sum_{j=1}^{s} n_{j} \delta_{j}^{2}\)</span>。</p><p>进一步还可以证明 <span class="math inline">\(S_{A}\)</span> 与 <span class="math inline">\(S_{E}\)</span> 独立,且当 <span class="math inline">\(H_{0}\)</span> 为真时，<span class="math inline">\(\frac{S_{A}}{\sigma^{2}} \sim \chi^{2}(s-1)\)</span></p><h4 id=假设检验问题的拒绝域>假设检验问题的拒绝域</h4><p>现在我们可以来确定原假设检验问题的拒绝域了.</p><p>由<span class="math inline">\(E\left(S_{A}\right)=(s-1) \sigma^{2}+\sum_{j=1}^{s} n_{j} \delta_{j}^{2}\)</span>知, 当 <span class="math inline">\(H_{0}\)</span> 为真时，<span class="math inline">\(E\left(\frac{S_{A}}{s-1}\right)=\sigma^{2}\)</span>。 即 <span class="math inline">\(\frac{S_{A}}{s-1}\)</span> 是 <span class="math inline">\(\sigma^{2}\)</span> 的无偏估计. 而当 <span class="math inline">\(H_{1}\)</span> 为真时 <span class="math inline">\(, \sum_{j=1}^{s} n_{j} \delta_{j}^{2}>0,\)</span> 此时<span class="math inline">\(E\left(\frac{S_{A}}{s-1}\right)=\sigma^{2}+\frac{1}{s-1} \sum_{j=1}^{s} n_{j} \delta_{j}^{2}>\sigma^{2}\)</span></p><p>由<span class="math inline">\(E\left(S_{E}\right)=(n-s) \sigma^{2}\)</span>知， <span class="math inline">\(E\left(\frac{S_{E}}{n-s}\right)=\sigma^{2}\)</span>， 即不管 <span class="math inline">\(H_{0}\)</span> 是否为真 <span class="math inline">\(, \frac{S_{E}}{n-s}\)</span> 都是 <span class="math inline">\(\sigma^{2}\)</span> 的无偏估计.</p><p>综上所述,分式 <span class="math inline">\(F=\frac{S_{A} /(s-1)}{S_{E} /(n-s)}\)</span> 的分子与分母独立, 分母 <span class="math inline">\(\frac{S_{E}}{n-s}\)</span> 不论 <span class="math inline">\(H_{0}\)</span> 是否为真,其数学期望总是 <span class="math inline">\(\sigma^{2} .\)</span> 当 <span class="math inline">\(H_{0}\)</span> 为真时,分子的数学期望为 <span class="math inline">\(\sigma^{2},\)</span> 当 <span class="math inline">\(H_{0}\)</span> 不真时， 由<span class="math inline">\(E\left(\frac{S_{A}}{s-1}\right)=\sigma^{2}+\frac{1}{s-1} \sum_{j=1}^{s} n_{j} \delta_{j}^{2}>\sigma^{2}\)</span>知分子的取值有偏大的趋势. 故知原检验问题的拒绝域具有形式<span class="math inline">\(F=\frac{S_{A} /(s-1)}{S_{E} /(n-s)} \geqslant k\)</span></p><p>其中 <span class="math inline">\(k\)</span> 由预先给定的显著性水平 <span class="math inline">\(\alpha\)</span> 确定. <span class="math inline">\(\frac{S_{E}}{\sigma^{2}} \sim \chi^{2}(n-s)\)</span>，<span class="math inline">\(\frac{S_{A}}{\sigma^{2}} \sim \chi^{2}(s-1)\)</span>，以及<span class="math inline">\(S_{E}\)</span> 与 <span class="math inline">\(S_{A}\)</span> 的独立性知, 当 <span class="math inline">\(H_{0}\)</span> 为真时，<span class="math inline">\(\frac{S_{A} /(s-1)}{S_{E} /(n-s)}=\frac{S_{A} / \sigma^{2}}{s-1} / \frac{S_{E} / \sigma^{2}}{n-s} \sim F(s-1, n-s)\)</span> 由此得原检验问题的拒绝域为<span class="math inline">\(F=\frac{S_{A} /(s-1)}{S_{E} /(n-s)} \geqslant F_{\alpha}(s-1, n-s)\)</span></p><p>上述分析的结果可排成下面图表的形式,称为<strong>方差分析表</strong>： <img src=https://picgo12138.oss-cn-hangzhou.aliyuncs.com/md/image-20201225013652933.png alt=image-20201225013652933> 图表中 <span class="math inline">\(\bar{S}_{A}=S_{A} /(s-1), \bar{S}_{E}=S_{E} /(n-s)\)</span> 分别称为 <span class="math inline">\(S_{A}, S_{E}\)</span> 的<strong>均方</strong>. 另外,因在<span class="math inline">\(S_{T}\)</span> 中 <span class="math inline">\(n\)</span> 个变量 <span class="math inline">\(X_{i j}-\bar{X}\)</span> 之间仅满足一个约束条件<span class="math inline">\(\bar{X}=\frac{1}{n} \sum_{j=1}^{s} \sum_{i=1}^{n_{j}} X_{i j}\)</span>,故 <span class="math inline">\(S_{T}\)</span> 的自由度为 <span class="math inline">\(n-1 .\)</span></p><p>在实际中,我们可以按以下较简便的公式来计算 <span class="math inline">\(S_{T}, S_{A}\)</span> 和 <span class="math inline">\(S_{E}\)</span>. 记： <span class="math inline">\(T_{\cdot j}=\sum_{i=1}^{n_{j}} X_{i j}, j=1,2, \cdots, s\)</span> <span class="math inline">\(T_{\cdot \cdot}=\sum_{j=1}^{s} \sum_{i=1}^{n_{j}} X_{i j}\)</span> 即有： <span class="math inline">\(\left.\begin{array}{l}S_{T}=\sum_{j=1}^{s} \sum_{i=1}^{n_{j}} X_{i j}^{2}-n \bar{X}^{2}=\sum_{j=1}^{s} \sum_{i=1}^{n_{j}} X_{i j}^{2}-\frac{T^{2}}{n} \\ S_{A}=\sum_{j=1}^{s} n_{j} \bar{X}_{\cdot j}^{2}-n \bar{X}^{2}=\sum_{j=1}^{s} \frac{T_{\cdot j}^{2}}{n_{j}}-\frac{T_{\cdots}^{2}}{n} \\ S_{E}=S_{T}-S_{A}\end{array}\right\}\)</span></p><h4 id=未知参数的估计>未知参数的估计</h4><p>上面已讲到过,不管 <span class="math inline">\(H_{0}\)</span> 是否为真，<span class="math inline">\(\hat{\sigma}^{2}=\frac{S_{E}}{n-s}\)</span>，是 <span class="math inline">\(\sigma^{2}\)</span> 的无偏估计. 由<span class="math inline">\(\bar{X} \sim N\left(\mu, \frac{\sigma^{2}}{n}\right)\)</span>，<span class="math inline">\(\bar{X}_{\cdot j}=\frac{1}{n_{j}} \sum_{i=1}^{n_{j}} X_{i j}\)</span>，知： <span class="math inline">\(E(\bar{X})=\mu\)</span>， <span class="math inline">\(E\left(\bar{X}_{\cdot j}\right)=\frac{1}{n_{j}} \sum_{i=1}^{n_{j}} E\left(X_{i j}\right)=\mu_{j}, j=1,2, \cdots, s\)</span> 故 <span class="math inline">\(\hat{\mu}=\bar{X}, \quad \hat{\mu}_{j}=\bar{X}_{\cdot j}\)</span> 分别是 <span class="math inline">\(\mu, \mu_{j}\)</span> 的无偏估计.</p><p>又若拒绝 <span class="math inline">\(H_{0},\)</span> 这意味着效应 <span class="math inline">\(\delta_{1}, \delta_{2}, \cdots, \delta_{s}\)</span> 不全为零. 由于<span class="math inline">\(\delta_{j}=\mu_{j}-\mu, \quad j=1,2, \cdots, s\)</span>， 知 <span class="math inline">\(\hat{\delta}_{j}=\bar{X}_{\cdot j}-\bar{X}\)</span> 是 <span class="math inline">\(\delta_{j}\)</span> 的无偏估计. 此时还有关系式<span class="math inline">\(\sum_{j=1}^{s} n_{j} \hat{\delta}_{j}=\sum_{j=1}^{s} n_{j} \bar{X}_{\cdot j}-n \bar{X}=0\)</span> 当拒绝 <span class="math inline">\(H_{0}\)</span> 时,常需要作出两总体 <span class="math inline">\(N\left(\mu_{j}, \sigma^{2}\right)\)</span> 和 <span class="math inline">\(N\left(\mu_{k}, \sigma^{2}\right), j \neq k\)</span> 的均值差 <span class="math inline">\(\mu_j-\mu_{k}=\delta_{j}-\delta_{k}\)</span> 的区间估计。做法如下： 由于<span class="math inline">\(E\left(\bar{X}_{\cdot j}-\bar{X}_{\cdot k}\right)=\mu_{j}-\mu_{k}\)</span>，<span class="math inline">\(D\left(\bar{X}_{\cdot j}-\bar{X}_{\cdot k}\right)=\sigma^{2}\left(\frac{1}{n_{j}}+\frac{1}{n_{k}}\right)\)</span>， 且<span class="math inline">\(\bar{X}_{\cdot j}-\bar{X}_{\cdot k} \frac{\vdash_{\sigma} \hat{\sigma}^{2}}{=} S_{E} /(n-s)\)</span> 独立. 于是<span class="math inline">\(\frac{\left(\bar{X}_{\cdot j}-\bar{X}_{\cdot k}\right)-\left(\mu_{j}-\mu_{k}\right)}{\bar{S}_{E}\left(\frac{1}{n_{j}}+\frac{1}{n_{k}}\right)}\)</span> <span class="math inline">\(\quad=\frac{\left(\bar{X}_{\cdot j}-\bar{X}_{\cdot k}\right)-\left(\mu_{j}-\mu_{k}\right)}{\sigma \sqrt{1 / n_{j}+1 / n_{k}}} / \sqrt{\frac{S_{E}}{\sigma^{2}} /(n-s)} \sim t(n-s)\)</span> 据此得均值差 <span class="math inline">\(\mu_{j}-\mu_{k}=\delta_{j}-\delta_{k}\)</span> 的置信水平为 <span class="math inline">\(1-\alpha\)</span> 的置信区间为： <span class="math inline">\(\left(\bar{X}_{\cdot j}-\bar{X}_{\cdot k} \pm t_{a / 2}(n-s) \sqrt{\bar{S}_{E}\left(\frac{1}{n_{j}}+\frac{1}{n_{k}}\right)}\right)\)</span></p><h2 id=双因素试验的方差分析>双因素试验的方差分析</h2><p>//TODO</p><h2 id=一元线性回归>一元线性回归</h2><p>在客观世界中普遍存在着变量之间的关系变量之间的关系。一般来说可分为确定性的与非确定性的两种。 <strong>确定性关系</strong>是指变量之间的关系可以用函数关系来表达的。 另一种<strong>非确定性的关系</strong>即所谓<strong>相关关系</strong>。例如人的身高与体重之间存在着关系，一般来说，人高一些，体重要重一些，但同样高度的人，体重往往不相同。人的血压与年龄之间也存在着关系，但同年龄的人的血压往往不相同。气象中的温度与湿度之间的关系也是这样。这是因为我们涉及的变量（如体重、血压、湿度）是随机变量，上面所说的变量关系是非确定性的回归分析是研究相关关系的一种数学工具。它能帮助我们从一个变量取得的值去估计另一变量所取的值。</p><h3 id=一元线性回归模型>一元线性回归模型</h3><p>设随机变量 <span class="math inline">\(Y\)</span> 与 <span class="math inline">\(x\)</span> 之间存在着某种相关关系. 这里, <span class="math inline">\(x\)</span> 是可以控制或可以精确观察的变量,如年龄、试验时的温度、施加的压力、电压与时间等.换句话说我 们可以随意指定 <span class="math inline">\(n\)</span> 个值 <span class="math inline">\(x_{1}, x_{2}, \cdots, x_{n} .\)</span> 因此我们干脆不把 <span class="math inline">\(x\)</span> 看成是随机变量,而 将它当作普通的变量. 本章中我们只讨论这种情况.</p><p>设<strong>随机变量 Y（因变量）与普通变量 <span class="math inline">\(x\)</span> (自变量) 之间存在着相关关系</strong>,由于 <span class="math inline">\(Y\)</span>是随机变量,对于 <span class="math inline">\(x\)</span> 的各个确定值,Y 有它 的分布如下图： <img src=https://picgo12138.oss-cn-hangzhou.aliyuncs.com/md/image-20201225102334470.png alt=image-20201225102334470> （图中 <span class="math inline">\(C_{1}, C_{2}\)</span> 分别是 <span class="math inline">\(x_{1}\)</span>,<span class="math inline">\(x_{2}\)</span> 处 <span class="math inline">\(Y\)</span> 的概率密度曲线 <span class="math inline">\() .\)</span> 用 <span class="math inline">\(F(y \mid x)\)</span> 表示 当 <span class="math inline">\(x\)</span> 取确定的 <span class="math inline">\(x\)</span> 值时,所对应的 <span class="math inline">\(Y\)</span> 的分布函数，如果我们掌握了 <span class="math inline">\(F(y \mid x)\)</span> 随着 <span class="math inline">\(x\)</span> 的 取值而变化的规律,那么就能完全掌握 Y与 <span class="math inline">\(x\)</span> 之间的关系了. 然而这样做<strong>往往比较复杂</strong>.</p><p>作为一种近似,我们<strong>转而去考察 <span class="math inline">\(Y\)</span> 的数学期望</strong>,若 <span class="math inline">\(Y\)</span> 的数学期望 <span class="math inline">\(E(Y)\)</span> 存在,则其值随 <span class="math inline">\(x\)</span> 的取值而定，<strong>它是 <span class="math inline">\(x\)</span> 的函 数</strong>. 将这一函数记为 <span class="math inline">\(\mu_{Y \mid x}\)</span> 或 <span class="math inline">\(\mu(x)\)</span>,称为 <span class="math inline">\(Y\)</span> 关于 <span class="math inline">\(x\)</span> 的<strong>回归函数</strong>（如上图中所示）. 这样， 我们就<strong>将讨论 <span class="math inline">\(Y\)</span> 与 <span class="math inline">\(x\)</span> 的相关关系的问题转换为讨论 <span class="math inline">\(E(Y)=\mu(x)\)</span> 与 <span class="math inline">\(x\)</span> 的函数关系</strong>了.</p><p>我们知道,若 <span class="math inline">\(\eta\)</span> 是一个随机变量,则 <span class="math inline">\(E\left[(\eta-c)^{2}\right]\)</span> 作为 <span class="math inline">\(c\)</span> 的函数,在 <span class="math inline">\(c=E(\eta)\)</span> 时 <span class="math inline">\(E\left[(\eta-c)^{2}\right]\)</span> 达到踏小(参见第四章习题第 17 题). 这表明在一切 <span class="math inline">\(x\)</span> 的函数中以 回归函数 <span class="math inline">\(\mu(x)\)</span> 作为 <span class="math inline">\(Y\)</span> 的近似,其均方误差 <span class="math inline">\(E\left[(Y-\mu(x))^{2}\right]\)</span> 为最小. 因此,作为一 种近似,为了研究 <span class="math inline">\(Y\)</span> 与 <span class="math inline">\(x\)</span> 的关系转而去研究 <span class="math inline">\(\mu(x)\)</span> 与 <span class="math inline">\(x\)</span> 的关系是合适的.</p><p>在实际问题中,回归函数 <span class="math inline">\(\mu(x)\)</span> 一般是未知的, <strong>回归分析的任务</strong>是在于根据 试验数据去估计回归函数,讨论有关的点估计、区间估计、假设检验等问题. 特别重要的是对随机变量 <span class="math inline">\(Y\)</span> 的观察值作出点预测和区间预测.</p><p>我们对于 <span class="math inline">\(x\)</span> 取定一组不完全相同的值 <span class="math inline">\(x_{1}, x_{2}, \cdots, x_{n},\)</span> 设 <span class="math inline">\(Y_{1}, Y_{2}, \cdots, Y_{n}\)</span> 分别是 在 <span class="math inline">\(x_{1}, x_{2}, \cdots, x_{n}\)</span> 处对 <span class="math inline">\(Y\)</span> 的独立观察结果,称<span class="math inline">\(\left(x_{1}, Y_{1}\right),\left(x_{2}, Y_{2}\right), \cdots,\left(x_{n}, Y_{n}\right)\)</span>是一个样本 , 对应的样本值记为<span class="math inline">\(\left(x_{1}, y_{1}\right),\left(x_{2}, y_{2}\right), \cdots,\left(x_{n}, y_{n}\right)\)</span></p><blockquote><p>注意：这里 <span class="math inline">\(Y_{1}, Y_{2}, \cdots, Y_{n}\)</span> 是相互独立的随机变量,但一般未必同分布，为方便计,也称 <span class="math inline">\(\left(x_{1}, Y_{1}\right),\left(x_{2},\right.\)</span> <span class="math inline">\(\left.Y_{2}\right), \cdots,\left(x_{n}, Y_{n}\right)\)</span> 是一个样本.</p></blockquote><p>我们首先要解决的问题是如何利用样本来估计 <span class="math inline">\(Y\)</span> 关于 <span class="math inline">\(x\)</span> 的回归函数 <span class="math inline">\(\mu(x) .\)</span> 为此,首先需要推测 <span class="math inline">\(\mu(x)\)</span> 的形式. 在一些问题中,我们可以由专业知识知道 <span class="math inline">\(\mu(x)\)</span> 的形式. 否则 <span class="math inline">\(,\)</span> 可将每对观察值 <span class="math inline">\(\left(x_{i}, y_{i}\right)\)</span> 在直角坐标系中描出它的相应的点(如下例子图所示)，这种图称为<strong>散点图</strong>. 散点图可以帮助我们粗略地看出 <span class="math inline">\(\mu(x)\)</span> 的 形式.</p><blockquote><p>例子： 为研究某一化学反应过程中,温度 <span class="math inline">\(x\left({ }^{\circ} \mathrm{C}\right)\)</span> 对产品得率 <span class="math inline">\(Y(\%)\)</span> 的影响，测得数据如下： <img src=https://picgo12138.oss-cn-hangzhou.aliyuncs.com/md/image-20201225112853528.png alt=image-20201225112853528> 这里自变量 <span class="math inline">\(x\)</span> 是普通变量, <span class="math inline">\(Y\)</span> 是随机变 量.画出散点图如下图所示. 由图大致看出 <span class="math inline">\(\mu(x)\)</span> 具有线性函数 <span class="math inline">\(a+b x\)</span> 的形 式. <img src=https://picgo12138.oss-cn-hangzhou.aliyuncs.com/md/image-20201225112557356.png alt=image-20201225112557356></p></blockquote><p>设 <span class="math inline">\(Y\)</span> 关于 <span class="math inline">\(x\)</span> 的回归函数为 <span class="math inline">\(\mu(x) .\)</span> 利 用样本来估计 <span class="math inline">\(\mu(x)\)</span> 的问题称为求 <span class="math inline">\(Y\)</span> 关 于 <span class="math inline">\(x\)</span> 的<strong>回归问题</strong>. 特别,若 <span class="math inline">\(\mu(x)\)</span> 为线性 函数 <span class="math inline">\(: \mu(x)=a+b x,\)</span> 此时估计 <span class="math inline">\(\mu(x)\)</span> 的 问题称为求<strong>一元线性回归问题</strong>. 本节只讨论这个问题.</p><p>我们假设对于 <span class="math inline">\(x\)</span> (在某个区间内) 的每一个值有<span class="math inline">\(Y \sim N\left(a+b x, \sigma^{2}\right)\)</span>， 其中 <span class="math inline">\(a, b\)</span> 及 <span class="math inline">\(\sigma^{2}\)</span> 都是不依赖于 <span class="math inline">\(x\)</span> 的未知参数. 记 <span class="math inline">\(\varepsilon=Y-(a+b x)\)</span>,对 <span class="math inline">\(Y\)</span> 作这样的正态假设,相当于假设： <span class="math inline">\(Y=a+b x+\varepsilon, \quad \varepsilon \sim N\left(0, \sigma^{2}\right)\)</span>， 其中未知参数 <span class="math inline">\(a, b\)</span> 及 <span class="math inline">\(\sigma^{2}\)</span> 都不依赖于 <span class="math inline">\(x .\)</span> (3. 2 ) 称为<strong>一元线性回归模型</strong>,其中 <span class="math inline">\(b\)</span> 称为<strong>回归系数</strong>.</p><p>上面的一元线性回归模型表明，因变量 <span class="math inline">\(Y\)</span> 由两部分组成,一部分是 <span class="math inline">\(x\)</span> 的线性函数 <span class="math inline">\(a+b x,\)</span> 另一部分 <span class="math inline">\(\varepsilon \sim N\left(0, \sigma^{2}\right)\)</span> 是随机误差,是人们不可控制的.</p><h3 id=a-b-的估计><span class="math inline">\(a, b\)</span> 的估计</h3><p>现用<strong>最大似然估计法来估计未知参数 <span class="math inline">\(a, b .\)</span></strong></p><p>取 <span class="math inline">\(x\)</span> 的 <span class="math inline">\(n\)</span> 个不全相同的值 <span class="math inline">\(x_{1}, x_{2}, \cdots, x_{n}\)</span> 作独立试验,得到样本 <span class="math inline">\(\left(x_{1}, Y_{1}\right),\left(x_{2},\right.\left.Y_{2}\right), \cdots,\left(x_{n}, Y_{n}\right) .\)</span> 由一元线性回归模型得<span class="math inline">\(Y_{i}=a+b x_{i}+\varepsilon_{i}, \varepsilon_{i} \sim N\left(0, \sigma^{2}\right),\)</span> 各 <span class="math inline">\(\varepsilon_{i}\)</span> 相互独立. 也即 <span class="math inline">\(Y_{i} \sim N\left(a+b x_{i}, \sigma^{2}\right), i=1,2, \cdots, n .\)</span></p><p>由 <span class="math inline">\(Y_{1}, Y_{2}, \cdots, Y_{n}\)</span> 的独立性, 知 <span class="math inline">\(Y_{1},\)</span><span class="math inline">\(Y_{2}, \cdots, Y_{n}\)</span> 的联合密度为： <span class="math inline">\(\begin{aligned} L &=\prod_{i=1}^{n} \frac{1}{\sigma \sqrt{2 \pi}} \exp \left[-\frac{1}{2 \sigma^{2}}\left(y_{i}-a-b x_{i}\right)^{2}\right] \\ &=\left(\frac{1}{\sigma \sqrt{2 \pi}}\right)^{n} \exp \left[-\frac{1}{2 \sigma^{2}} \sum_{i=1}^{n}\left(y_{i}-a-b x_{i}\right)^{2}\right] \end{aligned}\)</span></p><p>对于任意一组观察值 <span class="math inline">\(y_{1}, y_{2}, \cdots, y_{n},\)</span> 联合密度函数L就是样本的似然函数. 显然,要 <span class="math inline">\(L\)</span> 取最大值,只要L式右端方括弧中的平方和部分为最小,即<strong>只需函数<span class="math inline">\(Q(a, b)=\sum_{i=1}^{n}\left(y_{i}-a-b x_{i}\right)^{2}\)</span>取最小值</strong>。 取 <span class="math inline">\(Q\)</span> 分别关于 <span class="math inline">\(a, b\)</span> 的偏导数,并令它们等于零： <span class="math inline">\(\left.\begin{array}{l}\frac{\partial Q}{\partial a}=-2 \sum_{i=1}^{n}\left(y_{i}-a-b x_{i}\right)=0 \\ \frac{\partial Q}{\partial b}=-2 \sum_{i=1}^{n}\left(y_{i}-a-b x_{i}\right) x_{i}=0\end{array}\right\}\)</span> 得方程组（称为正规方程组）： <span class="math inline">\(\left\{\begin{array}{l}n a+\left(\sum_{i=1}^{n} x_{i}\right) b=\sum_{i=1}^{n} y_{i} \\ \left(\sum_{i=1}^{n} x_{i}\right) a+\left(\sum_{i=1}^{n} x_{i}^{2}\right) b=\sum_{i=1}^{n} x_{i} y_{i}\end{array}\right.\)</span> 由于 <span class="math inline">\(x_{i}\)</span> 不全相同,正规方程组的系数行列式： <span class="math inline">\(\left|\begin{array}{cc}n & \sum_{i=1}^{n} x_{i} \\ \sum_{i=1}^{n} x_{i} & \sum_{i=1}^{n} x_{i}^{2}\end{array}\right|=n \sum_{i=1}^{n} x_{i}^{2}-\left(\sum_{i=1}^{n} x_{i}\right)^{2}=n \sum_{i=1}^{n}\left(x_{i}-\bar{x}\right)^{2} \neq 0\)</span> 于是正规方程组有唯一的一组解. 解得 <span class="math inline">\(b, a\)</span> 的最大似然估计值为 <span class="math inline">\(\left.\begin{array}{l}\hat{b}=\frac{n \sum_{i=1}^{n} x_{i} y_{i}-\left(\sum_{i=1}^{n} x_{i}\right)\left(\sum_{i=1}^{n} y_{i}\right)}{n \sum_{i=1}^{n} x_{i}^{2}-\left(\sum_{i=1}^{n} x_{i}\right)^{2}}=\frac{\sum_{i=1}^{n}\left(x_{i}-\bar{x}\right)\left(y_{i}-\bar{y}\right)}{\sum_{i=1}^{n}\left(x_{i}-\bar{x}\right)^{2}} \\ \hat{a}=\frac{1}{n} \sum_{i=1}^{n} y_{i}-\frac{\hat{b}}{n} \sum_{i=1}^{n} x_{i}=\bar{y}-\hat{b} \bar{x}\end{array}\right\}\)</span> 其中 <span class="math inline">\(\bar{x}=\frac{1}{n} \sum_{i=1}^{n} x_{i}, \quad \bar{y}=\frac{1}{n} \sum_{i=1}^{n} y_{i}\)</span></p><p>为了理解和计算的方便，引入以下记号： <span class="math inline">\(\left.\begin{array}{l}S_{x x}=\sum_{i=1}^{n}\left(x_{i}-\bar{x}\right)^{2}=\sum_{i=1}^{n} x_{i}^{2}-\frac{1}{n}\left(\sum_{i=1}^{n} x_{i}\right)^{2} \\ S_{y y}=\sum_{i=1}^{n}\left(y_{i}-\bar{y}\right)^{2}=\sum_{i=1}^{n} y_{i}^{2}-\frac{1}{n}\left(\sum_{i=1}^{n} y_{i}\right)^{2} \\ S_{x y}=\sum_{i=1}^{n}\left(x_{i}-\bar{x}\right)\left(y_{i}-\bar{y}\right)=\sum_{i=1}^{n} x_{i} y_{i}-\frac{1}{n}\left(\sum_{i=1}^{n} x_{i}\right)\left(\sum_{i=1}^{n} y_{i}\right)\end{array}\right\}\)</span> 这样a，b的估计可以简记为： <span class="math inline">\(\left.\begin{array}{l}\hat{b}=\frac{S_{x y}}{S_{x x}} \\ \hat{a}=\bar{y}-\hat{b} \bar{x}\end{array}\right\}\)</span></p><blockquote><p>注意：如果 Y不且正态变量,可直接用<span class="math inline">\(Q(a, b)=\sum_{i=1}^{n}\left(y_{i}-a-b x_{i}\right)^{2}\)</span>估计 <span class="math inline">\(a, b,\)</span> 使 <span class="math inline">\(Y\)</span> 的观察值 <span class="math inline">\(y_{i}\)</span> 与 <span class="math inline">\(a+b x_{i}\)</span> 偏差的平方和 <span class="math inline">\(Q (a,b)\)</span>为最小.这种方法叫<strong>最小二乘法</strong>,它是求经验公式的一种常用方法. 若 <span class="math inline">\(Y\)</span> 是正态变量,则最小二乘法与最大似然估计法给出相同的结果.</p></blockquote><p>在得到 <span class="math inline">\(a, b\)</span> 的估计 <span class="math inline">\(\hat{a}, \hat{b}\)</span> 后，对于给定的 <span class="math inline">\(x,\)</span> 我们就取 <span class="math inline">\(\hat{a}+\hat{b} x\)</span> 作为回归函数 <span class="math inline">\(\mu(x)=a+b x\)</span> 的估计, 即 <span class="math inline">\(\mu(x)=\hat{a}+\hat{b} x\)</span>,称为 <span class="math inline">\(Y\)</span> 关于 <span class="math inline">\(x\)</span> 的<strong>经验回归函数</strong>. 记 <span class="math inline">\(\hat{a}+\hat{b} x\)</span> <span class="math inline">\(=\hat{y},\)</span> 方程<span class="math inline">\(\hat{y}=\hat{a}+\hat{b} x\)</span>称为 <span class="math inline">\(Y\)</span> 关于 <span class="math inline">\(x\)</span> 的<strong>经验回归方程</strong>,简称<strong>回归方程</strong>,其图形称为<strong>回归直线</strong>.</p><p>将 <span class="math inline">\(\hat{a}\)</span> 的表达式代入<span class="math inline">\(\hat{y}=\hat{a}+\hat{b} x\)</span>,则回归方程可写成<span class="math inline">\(\hat{y}=\bar{y}+\hat{b}(x-\bar{x})\)</span>， 这表明,对于样本值 <span class="math inline">\(\left(x_{1}, y_{1}\right),\left(x_{2}, y_{2}\right), \cdots,\left(x_{n}, y_{n}\right),\)</span> 回归直线通过散点图的几何中心 <span class="math inline">\((\bar{x}, \bar{y})\)</span>.</p><h3 id=sigma2-的估计><span class="math inline">\(\sigma^{2}\)</span> 的估计</h3><p>由<span class="math inline">\(Y=a+b x+\varepsilon, \quad \varepsilon \sim N\left(0, \sigma^{2}\right)\)</span>可知： <span class="math inline">\(E\left\{[Y-(a+b x)]^{2}\right\}=E\left(\varepsilon^{2}\right)=D(\varepsilon)+[E(\varepsilon)]^{2}=\sigma^{2}\)</span></p><p>这表示 <span class="math inline">\(\sigma^{2}\)</span> 愈小,以回归函数 <span class="math inline">\(\mu(x)=a+b x\)</span> 作为 <span class="math inline">\(Y\)</span> 的近似导致的均方误差就愈小. 这样,利用回归函数 <span class="math inline">\(\mu(x)=a+b x\)</span> 去研究随机变量 <span class="math inline">\(Y\)</span> 与 <span class="math inline">\(x\)</span> 的关系就愈有效. 然而 <span class="math inline">\(\sigma^{2}\)</span> 是未知的,因而我们需要利用样本去估计 <span class="math inline">\(\sigma^{2} .\)</span> 为了估计 <span class="math inline">\(\sigma^{2},\)</span> 先引入下述残差平方和.</p><p>记 <span class="math inline">\(\hat{y}_{i}=\left.\hat{y}\right|_{x=x_{i}}=\hat{a}+\hat{b} x_{i},\)</span> 称<span class="math inline">\(y_{i}-\hat{y}_{i}\)</span> 为 <span class="math inline">\(x_{i}\)</span> 处的<strong>残差</strong>. 平方和<span class="math inline">\(Q_{e}=\sum_{i=1}^{n}\left(y_{i}-\hat{y}_{i}\right)^{2}=\sum_{i=1}^{n}\left(y_{i}-\hat{a}-\hat{b} x_{i}\right)^{2}\)</span>称为<strong>残差平方和</strong>. 它是经验回归函数在 <span class="math inline">\(x_{i}\)</span> 处的函数值 <span class="math inline">\(\mu\left(x_{i}\right)=\hat{a}+\hat{b} x_{i}\)</span> 与 <span class="math inline">\(x_{i}\)</span> 处的观察值 <span class="math inline">\(y_{i}\)</span> 的 偏差的平方和. <img src=https://picgo12138.oss-cn-hangzhou.aliyuncs.com/md/image-20201225124345680.png alt=image-20201225124345680> 为了计算 <span class="math inline">\(Q_{e},\)</span> 我们将 <span class="math inline">\(Q_{e}\)</span> 作如下的分解 : <span class="math inline">\(\begin{aligned} Q_{e}=& \sum_{i=1}^{n}\left(y_{i}-\hat{y}_{i}\right)^{2}=\sum_{i=1}^{n}\left[y_{i}-\bar{y}-\hat{b}\left(x_{i}-\bar{x}\right)\right]^{2} \\=& \sum_{i=1}^{n}\left(y_{i}-\bar{y}\right)^{2}-2 \hat{b} \sum_{i=1}^{n}\left(x_{i}-\bar{x}\right)\left(y_{i}-\bar{y}\right) \\ &+(\hat{b})^{2} \sum_{i=1}^{n}\left(x_{i}-\bar{x}\right)^{2}=S_{y y}-2 \hat{b} S_{x y}+(\hat{b})^{2} S_{x x} \end{aligned}\)</span></p><p>由b的估计<span class="math inline">\(\left.\begin{array}{l}\hat{b}=\frac{S_{x y}}{S_{x x}} \\ \hat{a}=\bar{y}-\hat{b} \bar{x}\end{array}\right\}\)</span>，将<span class="math inline">\(\hat{b}\)</span>代入<span class="math inline">\(Q_e\)</span>得：</p><p><span class="math inline">\(Q_{e}=S_{y y}-\hat{b} S_{x y}\)</span></p><p>在 <span class="math inline">\(S_{x y}, S_{x y}\)</span> 的表达式式中,将 <span class="math inline">\(y_{i}\)</span> 改为 <span class="math inline">\(Y_{i}\)</span><span class="math inline">\((i=1,2, \cdots, n),\)</span> 并把它们分别记为 <span class="math inline">\(S_{Y Y}, S_{x Y},\)</span> 即<span class="math inline">\(S_{Y Y}=\sum_{i=1}^{n}\left(Y_{i}-\bar{Y}\right)^{2}, S_{x Y}=\sum_{i=1}^{n}\left(x_{i}-\bar{x}\right)\left(Y_{i}-\bar{Y}\right)\)</span></p><p>则残差平方和 <span class="math inline">\(Q_{e}\)</span> 的相应的统计量(仍记为 <span class="math inline">\(\left.Q_{e}\right)\)</span> 为<span class="math inline">\(Q_{e}=S_{Y Y}-\hat{b} S_{x Y}\)</span></p><p>残差平方和 <span class="math inline">\(Q_{e}\)</span> 服从分布<span class="math inline">\(\frac{Q_{e}}{\sigma^{2}} \sim \chi^{2}(n-2)\)</span>， 于是<span class="math inline">\(E\left(\frac{Q_{e}}{\sigma^{2}}\right)=n-2\)</span> 即知 <span class="math inline">\(E\left(Q_{e} /(n-2)\right)=\sigma^{2} .\)</span> 这样就得到了 <span class="math inline">\(\sigma^{2}\)</span> 的无偏估计量 :<span class="math inline">\(\widehat{\sigma}^{2}=\frac{Q_{e}}{n-2}=\frac{1}{n-2}\left(S_{Y Y}-\hat{b} S_{x Y}\right)\)</span></p><h3 id=线性假设的显著性检验>线性假设的显著性检验</h3><p>在以上的讨论中,我们假定 <span class="math inline">\(Y\)</span> 关于 <span class="math inline">\(x\)</span> 的回归 <span class="math inline">\(\mu(x)\)</span> 具有形式 <span class="math inline">\(a+b x\)</span>, 在处理实际问题时 <span class="math inline">\(, \mu(x)\)</span> 是否为 <span class="math inline">\(x\)</span> 的线性函数,首先要根据有关专业知识和实践来判断， 其次就要根据实际观察得到的数据运用假设检验的方法来判断. 这就是说,求得的线性回归方程是否具有实用价值,一般来说,需要经过假设检验才能确定. 若线性假设<span class="math inline">\(Y=a+b x+\varepsilon, \quad \varepsilon \sim N\left(0, \sigma^{2}\right)\)</span>符合实际,则 <span class="math inline">\(b\)</span> 不应为零,因为若 <span class="math inline">\(b=0,\)</span> 则 <span class="math inline">\(E(Y)=\mu(x)\)</span> 就不依赖于 <span class="math inline">\(x\)</span> 了. 因此我们需要检验假设<span class="math inline">\(\begin{array}{ll}H_{0}: & b=0 \\ H_{1}: & b \neq 0\end{array}\)</span>， 我们使用 <span class="math inline">\(t\)</span> 检验法来进行检验. 我们有<span class="math inline">\(\hat{b} \sim N\left(b, \sigma^{2} / S_{x x}\right)\)</span>。 又由<span class="math inline">\(\frac{Q_{e}}{\sigma^{2}} \sim \chi^{2}(n-2)\)</span>，<span class="math inline">\(\hat{\sigma}^{2}=\frac{Q_{e}}{n-2}=\frac{1}{n-2}\left(S_{Y Y}-\hat{b} S_{x Y}\right)\)</span>， 知<span class="math inline">\(\frac{(n-2) \hat{\sigma}^{2}}{\sigma^{2}}=\frac{Q_{e}}{\sigma^{2}} \sim \chi^{2}(n-2)\)</span></p><p>且 <span class="math inline">\(\hat{b}\)</span> 与 <span class="math inline">\(Q_{e}\)</span> 独立，故有<span class="math inline">\(\frac{\hat{b}-b}{\sqrt{\sigma^{2} / S_{x x}}} / \sqrt{\frac{(n-2) \hat{\sigma}^{2}}{\sigma^{2}} /(n-2)} \sim t(n-2)\)</span> 即<span class="math inline">\(\frac{\hat{b}-b}{\hat{\sigma}} \sqrt{S_{x x}} \sim t(n-2)\)</span></p><p>当 <span class="math inline">\(H_{0}\)</span> 为真时 <span class="math inline">\(b=0,\)</span> 此时<span class="math inline">\(t=\frac{\hat{b}}{\hat{\sigma}} \sqrt{S_{x x}} \sim t(n-2)\)</span>。 且 <span class="math inline">\(E(\hat{b})=b=0,\)</span> 即得 <span class="math inline">\(H_{0}\)</span> 的<strong>拒绝域</strong>为<span class="math inline">\(|t|=\frac{|\hat{b}|}{\hat{\sigma}} \sqrt{S_{x x}} \geqslant t_{a / 2}(n-2)\)</span>，此处 <span class="math inline">\(\alpha\)</span> 为显著性水平.</p><p>当假设 <span class="math inline">\(H_{0}: b=0\)</span> 被拒绝时,认为回归效果是显著的,反之,就认为回归效果 不显著. 回归效果不显著的原因可能有如下几种： <span class="math inline">\(1^{\circ}\)</span> 影响 <span class="math inline">\(Y\)</span> 取值的,除 <span class="math inline">\(x\)</span> 及随机误差外还有其他不可忽略的因素. <span class="math inline">\(2^{\circ} E(Y)\)</span> 与 <span class="math inline">\(x\)</span> 的关系不是线性的,而存在着其他的关系. <span class="math inline">\(3^{\circ} Y\)</span> 与 <span class="math inline">\(x\)</span> 不存在关系.</p><p>因此需要进一步的分析原因,分别处理.</p><h3 id=系数-b-的置信区间>系数 <span class="math inline">\(b\)</span> 的置信区间</h3><p>当回归效果显著时,我们常需要对系数 <span class="math inline">\(b\)</span> 作区间估计. 事实上,可由<span class="math inline">\(\frac{\hat{b}-b}{\hat{\sigma}} \sqrt{S_{x x}} \sim t(n-2)\)</span>得到 <span class="math inline">\(b\)</span> 的置信水平为 <span class="math inline">\(1-\alpha\)</span> 的置信区间为<span class="math inline">\(\left(\hat{b} \pm t_{a / 2}(n-2) \times \frac{\hat{\sigma}}{\sqrt{S_{x x}}}\right)\)</span></p><h3 id=回归函数-muxab-x-函数值的点估计和置信区间>回归函数 <span class="math inline">\(\mu(x)=a+b x\)</span> 函数值的点估计和置信区间</h3><p>设 <span class="math inline">\(x_{0}\)</span> 是自变量 <span class="math inline">\(x\)</span> 的某一指定值. 根据回归方程<span class="math inline">\(\hat{y}=\hat{a}+\hat{b} x\)</span>，可以用经验回归函数 <span class="math inline">\(\hat{y}=\widehat{\mu(x)}\)</span> <span class="math inline">\(=\hat{a}+\hat{b} x\)</span> 在 <span class="math inline">\(x_{0}\)</span> 的函数值 <span class="math inline">\(\left.\hat{y}_{0}=\mu \widehat{\left(x_{0}\right.}\right)=\hat{a}+\hat{b} x_{0}\)</span> 作为 <span class="math inline">\(\mu\left(x_{0}\right)=a+b x_{0}\)</span> 的点估计. 即<span class="math inline">\(\hat{y}_{0}=\mu\left(x_{0}\right)=\hat{a}+\hat{b} x_{0}\)</span>, 考虑相应的估计量<span class="math inline">\(\hat{Y}_{0}=\hat{a}+\hat{b} x_{0}\)</span>， 由<span class="math inline">\(\hat{Y}_{0}=\hat{a}+\hat{b} x_{0}=\bar{Y}+\hat{b}\left(x_{0}-\bar{x}\right) \sim N\left(a+b x_{0},\left[\frac{1}{n}+\frac{\left(x_{0}-\bar{x}\right)^{2}}{S_{x r}}\right] \sigma^{2}\right)\)</span>， 知<span class="math inline">\(E\left(\hat{Y}_{0}\right)=a+b x_{0},\)</span> 因此这一估计量是无偏的.</p><p>下面来求 <span class="math inline">\(\mu\left(x_{0}\right)\)</span><span class="math inline">\(=a+b x_{0}\)</span> 的置信区间. 由<span class="math inline">\(\hat{Y}_{0}=\hat{a}+\hat{b} x_{0}=\bar{Y}+\hat{b}\left(x_{0}-\bar{x}\right) \sim N\left(a+b x_{0},\left[\frac{1}{n}+\frac{\left(x_{0}-\bar{x}\right)^{2}}{S_{x r}}\right] \sigma^{2}\right)\)</span>， 知<span class="math inline">\(\frac{\hat{Y}_{0}-\left(a+b x_{0}\right)}{\sigma \sqrt{\frac{1}{n}+\frac{\left(x_{0}-\bar{x}\right)^{2}}{S_{x x}}}} \sim N(0,1)\)</span></p><p>由<span class="math inline">\(\frac{Q_{e}}{\sigma^{2}} \sim \chi^{2}(n-2)\)</span>，<span class="math inline">\(\hat{\sigma}^{2}=\frac{Q_{e}}{n-2}=\frac{1}{n-2}\left(S_{Y Y}-\hat{b} S_{x Y}\right)\)</span>， 知<span class="math inline">\(\frac{(n-2) \hat{\sigma}^{2}}{\sigma^{2}}=\frac{Q_{e}}{\sigma^{2}} \sim \chi^{2}(n-2)\)</span></p><p>若 <span class="math inline">\(Y_{0}=a+b x_{0}+\varepsilon_{0}\)</span> 与 <span class="math inline">\(Y_{1}, \cdots, Y_{n}\)</span> 独立,则 <span class="math inline">\(Y_{0}, \hat{Y}_{0}, Q_e\)</span> 相互独立. 由上述结论知 <span class="math inline">\(Q_{e}, \hat{Y}_{0}\)</span> 相互独立. 于是<span class="math inline">\(\frac{\hat{Y}_{0}-\left(a+b x_{0}\right)}{\sigma \sqrt{\frac{1}{n}+\frac{\left(x_{0}-\bar{x}\right)^{2}}{S_{x x}}}} / \sqrt{\frac{(n-2) \hat{\sigma}^{2}}{\sigma^{2}} /(n-2)} \sim t(n-2)\)</span> 即<span class="math inline">\(\frac{\hat{Y}_{0}-\left(a+b x_{0}\right)}{\hat{\sigma} \sqrt{\frac{1}{n}+\frac{\left(x_{0}-\bar{x}\right)^{2}}{S_{x x}}}} \sim t(n-2)\)</span></p><p>于是得到 <span class="math inline">\(\mu\left(x_{0}\right)=a+b x_{0}\)</span> 的置信水平为 <span class="math inline">\(1-\alpha\)</span> 的置信区间为<span class="math inline">\(\left(\hat{Y}_{0} \pm t_{\alpha / 2}(n-2) \hat{\sigma} \sqrt{\frac{1}{n}+\frac{\left(x_{0}-\bar{x}\right)^{2}}{S_{x x}}}\right)\)</span>, 或即<span class="math inline">\(\left(\hat{a}+\hat{b} x_{0} \pm t_{a / 2}(n-2) \hat{\sigma} \sqrt{\frac{1}{n}+\frac{\left(x_{0}-\bar{x}\right)^{2}}{S_{x x}}}\right)\)</span> 这一置信区间的长度是 <span class="math inline">\(x_{0}\)</span> 的函数,它随 <span class="math inline">\(\left|x_{0}-\bar{x}\right|\)</span> 的增加而增加 <span class="math inline">\(,\)</span> 当 <span class="math inline">\(x_{0}=\bar{x}\)</span> 时为 最短.</p><h3 id=y-的观察值的点预测和预测区间><span class="math inline">\(Y\)</span> 的观察值的点预测和预测区间</h3><p>若我们对指定点 <span class="math inline">\(x=x_{0}\)</span> 处因变量 <span class="math inline">\(Y\)</span> 的观察值 <span class="math inline">\(Y_{0}\)</span> 感兴趣,然而我们在 <span class="math inline">\(x=x_{0}\)</span> 处并未进行观察或者暂时无法观察. 经验回归函数的一个重要应用是,可利用它对因变量 <span class="math inline">\(Y\)</span> 的新观察值 <span class="math inline">\(Y_{0}\)</span> 进行点预测或区间预测. 若 <span class="math inline">\(Y_{0}\)</span> 是在 <span class="math inline">\(x=x_{0}\)</span> 处对 <span class="math inline">\(Y\)</span> 的观察结果,可知它满足 :<span class="math inline">\(Y_{0}=a+b x_{0}+\varepsilon_{0}, \quad \varepsilon_{0} \sim N\left(0, \sigma^{2}\right)\)</span> 随机误差 <span class="math inline">\(\varepsilon_{0}\)</span> 可正也可负,其值无法预料,我们就用 <span class="math inline">\(x_{0}\)</span> 处的经验回归函数值<span class="math inline">\(\hat{Y}_{0}=\mu\left(x_{0}\right)=\hat{a}+\hat{b} x_{0}\)</span>作为 <span class="math inline">\(Y_{0}=a+b x_{0}+\varepsilon_{0}\)</span> 的点预测.</p><p>下面来求 <span class="math inline">\(Y_{0}\)</span> 的预测区间.</p><p>因 <span class="math inline">\(Y_{0}\)</span> 是将要做的一次独立试验的结果,因此它与已经得到的试验的结果<span class="math inline">\(Y_{1}, Y_{2}, \cdots, Y_{n}\)</span> 相互独立. 由这样a，b的估计<span class="math inline">\(\left.\begin{array}{l}\hat{b}=\frac{S_{x y}}{S_{x x}} \\ \hat{a}=\bar{y}-\hat{b} \bar{x}\end{array}\right\}\)</span>知 <span class="math inline">\(\hat{b}\)</span> 是 <span class="math inline">\(Y_{1}, Y_{2}, \cdots, Y_{n}\)</span> 的线性组合, 故 <span class="math inline">\(\hat{Y}_{0}=\)</span><span class="math inline">\(\bar{Y}+\hat{b}\left(x_{0}-\bar{x}\right)\)</span> 是 <span class="math inline">\(Y_{1}, Y_{2}, \cdots, Y_{n}\)</span> 的线性组合,故 <span class="math inline">\(Y_{0}\)</span> 与 <span class="math inline">\(\hat{Y}_{0}\)</span> 相互独立. 由 <span class="math inline">\(Y_{0}=a+b x_{0}+\varepsilon_{0}, \quad \varepsilon_{0} \sim N\left(0, \sigma^{2}\right)\)</span>和<span class="math inline">\(\hat{Y}_{0}=\hat{a}+\hat{b} x_{0}=\bar{Y}+\hat{b}\left(x_{0}-\bar{x}\right) \sim N\left(a+b x_{0},\left[\frac{1}{n}+\frac{\left(x_{0}-\bar{x}\right)^{2}}{S_{s x}}\right] \sigma^{2}\right)\)</span>, 得<span class="math inline">\(\hat{Y}_{0}-Y_{0} \sim N\left(0,\left[1+\frac{1}{n}+\frac{\left(x_{0}-\bar{x}\right)^{2}}{S_{x x}}\right] \sigma^{2}\right)\)</span>， 即<span class="math inline">\(\frac{\hat{Y}_{0}-Y_{0}}{\sigma \sqrt{1+\frac{1}{n}+\frac{\left(x_{0}-\bar{x}\right)^{2}}{S_{x x}}}} \sim N(0,1)\)</span></p><p>再由<span class="math inline">\(\frac{(n-2) \hat{\sigma}^{2}}{\sigma^{2}}=\frac{Q_{e}}{\sigma^{2}} \sim \chi^{2}(n-2)\)</span>，及 <span class="math inline">\(Y_{0}, \hat{Y}_{0}, Q_{.}\)</span> 的相互独立性 知<span class="math inline">\(\frac{\hat{Y}_{0}-Y_{0}}{\sigma \sqrt{1+\frac{1}{n}+\frac{\left(x_{0}-\bar{x}\right)^{2}}{S_{x x}}}} / \sqrt{\frac{(n-2) \hat{\sigma}^{2}}{\sigma^{2}} /(n-2)} \sim t(n-2)\)</span> 即<span class="math inline">\(\frac{\hat{Y}_{0}-Y_{0}}{\hat{\sigma} \sqrt{1+\frac{1}{n}+\frac{\left(x_{0}-\bar{x}\right)^{2}}{S_{x x}}}} \sim t(n-2)\)</span></p><p>于是对于给定的置信水平 <span class="math inline">\(1-\alpha\)</span> 有<span class="math inline">\(P\left\{\frac{\left|\hat{Y}_{0}-Y_{0}\right|}{\hat{\sigma} \sqrt{1+\frac{1}{n}+\frac{\left(x_{0}-\bar{x}\right)^{2}}{S_{x x}}}} \leqslant t_{a / 2}(n-2)\right\}=1-\alpha\)</span> 或<span class="math inline">\(P\left\{\hat{Y}_{0}-t_{a / 2}(n-2) \hat{\sigma} \sqrt{1+\frac{1}{n}+\frac{\left(x_{0}-\bar{x}\right)^{2}}{S_{x x}}}&lt;Y_{0}\right.\)</span><span class="math inline">\(\left.&lt;\hat{Y}_{0}+t_{a / 2}(n-2) \hat{\sigma} \sqrt{1+\frac{1}{n}+\frac{\left(x_{0}-\bar{x}\right)^{2}}{S_{x x}}}\right\}=1-\alpha\)</span></p><p>则区间<span class="math inline">\(\left(\hat{Y}_{0} \pm t_{a / 2}(n-2) \hat{\sigma} \sqrt{1+\frac{1}{n}+\frac{\left(x_{0}-\bar{x}\right)^{2}}{S_{x x}}}\right)\)</span>， 即<span class="math inline">\(\left(\hat{a}+\hat{b} x_{0} \pm t_{a / 2}(n-2) \hat{\sigma} \sqrt{\left.1+\frac{1}{n}+\frac{\left(x_{0}-\bar{x}\right)^{2}}{S_{x x}}\right)}\right.\)</span>称为<span class="math inline">\(Y_{0}\)</span> 的置信水平为 <span class="math inline">\(1-\alpha\)</span> 的预测区间.</p><p>这一预测区间的长度是 <span class="math inline">\(x_{0}\)</span> 的函数,它随 <span class="math inline">\(\left|x_{0}-\bar{x}\right|\)</span> 的增加而增加. 当 <span class="math inline">\(x_{0}=\bar{x}\)</span> 时为最短. 将上面得区间与回归函数<span class="math inline">\(\mu\left(x_{0}\right)=a+b x_{0}\)</span> 的置信区间比较， 知道在相同的置信水平下,回归函数值 <span class="math inline">\(\mu\left(x_{0}\right)\)</span> 的置信区间要比 <span class="math inline">\(Y_{0}\)</span> 的预测区间要 短. 这是因为 <span class="math inline">\(Y_{0}=a+b x_{0}+\varepsilon_{0}\)</span> 比 <span class="math inline">\(\mu\left(x_{0}\right)=a+b x_{0}\)</span> 多了一项 <span class="math inline">\(\varepsilon_{0}\)</span> 的缘故.</p><h3 id=可化为一元线性回归的例子>可化为一元线性回归的例子</h3><p>以上讨论了一元线性回归问题,在实际中常会遇到更为复杂的回归问题,但 在某些情况下,可以通过适当的变量变换,可以将它化成一元线性回归来处理. 下面介绍几种常见的可转化为一元线性回归的模型.</p><h4 id=yalpha-mathrmebeta-x-cdot-varepsilon-quad-ln-varepsilon-sim-nleft0-sigma2right><span class="math inline">\(Y=\alpha \mathrm{e}^{\beta x} \cdot \varepsilon, \quad \ln \varepsilon \sim N\left(0, \sigma^{2}\right)\)</span></h4><p>其中 <span class="math inline">\(\alpha, \beta, \sigma^{2}\)</span> 是与 <span class="math inline">\(x\)</span> 无关的未知参数.</p><p>将 <span class="math inline">\(Y=\alpha \mathrm{e}^{-\beta x} \cdot \varepsilon\)</span> 两边取对数,得<span class="math inline">\(\ln Y=\ln \alpha+\beta x+\ln \varepsilon\)</span> 令 <span class="math inline">\(\ln Y=Y^{\prime}, \ln \alpha=a, \beta=b, x=x^{\prime}, \ln \varepsilon=\varepsilon^{\prime},\)</span> 上面的对数式可转化为一元线性回归模型：<span class="math inline">\(Y^{\prime}=a+b x^{\prime}+\varepsilon^{\prime}, \quad \varepsilon^{\prime} \sim N\left(0, \sigma^{2}\right)\)</span></p><h4 id=yalpha-xbeta-cdot-varepsilon-quad-ln-varepsilon-sim-nleft0-sigma2right><span class="math inline">\(Y=\alpha x^{\beta} \cdot \varepsilon, \quad \ln \varepsilon \sim N\left(0, \sigma^{2}\right)\)</span></h4><p>其中 <span class="math inline">\(\alpha, \beta, \sigma^{2}\)</span> 是与 <span class="math inline">\(x\)</span> 无关的未知参数.</p><p>将 <span class="math inline">\(Y=\alpha x^{\beta} \cdot \varepsilon\)</span> 两边取对数,得<span class="math inline">\(\ln Y=\ln \alpha+\beta \ln x+\ln \varepsilon\)</span> 令 <span class="math inline">\(\ln Y=Y^{\prime}, \ln \alpha=a, \beta=b, \ln x=x^{\prime}, \ln \varepsilon=\varepsilon^{\prime},\)</span> 上面的对数式可转化为一元线性回归模型：<span class="math inline">\(Y^{\prime}=a+b x^{\prime}+\varepsilon^{\prime}, \quad \varepsilon^{\prime} \sim N\left(0, \sigma^{2}\right)\)</span></p><h4 id=yalphabeta-hxvarepsilon-quad-varepsilon-sim-nleft0-sigma2right><span class="math inline">\(Y=\alpha+\beta h(x)+\varepsilon, \quad \varepsilon \sim N\left(0, \sigma^{2}\right)\)</span></h4><p>其中 <span class="math inline">\(\alpha, \beta, \sigma^{2}\)</span> 是与 <span class="math inline">\(x\)</span> 无关的未知参数. <span class="math inline">\(h(x)\)</span> 是 <span class="math inline">\(x\)</span> 的已知函数 <span class="math inline">\(,\)</span> 令 <span class="math inline">\(\alpha=a, \beta=b, h(x)\)</span> <span class="math inline">\(=x^{\prime},\)</span> 可转化为一元线性回归模型：<span class="math inline">\(Y=a+b x^{\prime}+\varepsilon, \quad \varepsilon \sim N\left(0, \sigma^{2}\right)\)</span></p><p>若在原模型下，例如在原模型 下，对于 <span class="math inline">\((x, Y)\)</span> 有样本 <span class="math inline">\(\left(x_{1}, y_{1}\right),\left(x_{2},\right.\)</span> <span class="math inline">\(\left.y_{2}\right), \cdots,\left(x_{n}, y_{n}\right)\)</span> 就相当于在新模型下有样本 <span class="math inline">\(\left(x_{1}^{\prime}, y_{1}\right),\left(x_{2}^{\prime}, y_{2}\right), \cdots,\left(x_{n}^{\prime},\right.\)</span><span class="math inline">\(\left.y_{n}\right),\)</span> 其中 <span class="math inline">\(x_{i}^{\prime}=h\left(x_{i}\right) .\)</span> 于是就能利用上节的方法来估计 <span class="math inline">\(a, b\)</span> 或对 <span class="math inline">\(b\)</span> 作假设检验,或对 <span class="math inline">\(Y\)</span> 进行预测. 在得到 <span class="math inline">\(Y\)</span> 关于 <span class="math inline">\(x^{\prime}\)</span> 的回归方程后,再将原自变量 <span class="math inline">\(x\)</span> 代回,就得到<span class="math inline">\(Y\)</span> 关于 <span class="math inline">\(x\)</span> 的回归方程,它的图形是一条曲线,也称为<strong>曲线回归方程</strong>.</p><p>之前所讨论的<strong>一元线性回归模型</strong>是<span class="math inline">\(Y=a+b x+\varepsilon, \quad \varepsilon \sim N\left(0, \sigma^{2}\right)\)</span>。 一般情况,<strong>一元回归模型</strong>为<span class="math inline">\(Y=\mu\left(x ; \theta_{1}, \theta_{2}, \cdots, \theta_{p}\right)+\varepsilon, \quad \varepsilon \sim N\left(0, \sigma^{2}\right)\)</span>，其中 <span class="math inline">\(\theta_{1}, \theta_{2}, \cdots, \theta_{p}, \sigma^{2}\)</span> 是与 <span class="math inline">\(x\)</span> 无关的未知参数.</p><p>如果回归函数 <span class="math inline">\(\mu\left(x ; \theta_{1}, \theta_{2}, \cdots, \theta_{p}\right)\)</span> 是参数 <span class="math inline">\(\theta_{1}, \theta_{2}, \cdots, \theta_{p}\)</span> 的线性函数 <span class="math inline">\((\)</span> 不必是 <span class="math inline">\(x\)</span>的线性函数 <span class="math inline">\()\)</span>,则称该一元回归模型为<strong>线性回归模型</strong>; 若 <span class="math inline">\(\mu\left(x ; \theta_{1}, \theta_{2}, \cdots, \theta_{p}\right)\)</span> 是 <span class="math inline">\(\theta_{1}, \theta_{2}, \cdots, \theta_{p}\)</span>的非线性函数,则称为<strong>非线性回归模型</strong>.</p><p>上面提到的模型<span class="math inline">\(Y=\alpha+\beta h(x)+\varepsilon, \quad \varepsilon \sim N\left(0, \sigma^{2}\right)\)</span>是线性回归模型， 而模型<span class="math inline">\(Y=\alpha \mathrm{e}^{\beta x} \cdot \varepsilon, \quad \ln \varepsilon \sim N\left(0, \sigma^{2}\right)\)</span>以及<span class="math inline">\(Y=\alpha x^{\beta} \cdot \varepsilon, \quad \ln \varepsilon \sim N\left(0, \sigma^{2}\right)\)</span>都不是线性回归模型,但是它们都能经过变量变换转化为线 性回归模型. 又如<span class="math inline">\(Y=\theta_{1} \mathrm{e}^{\theta_{2} x}+\varepsilon, \quad \varepsilon \sim N\left(0, \sigma^{2}\right)\)</span>它是非线性回归模型. 它不能经过变量变换将它转化为线性回归模型,称为<strong>本 质的非线性回归模型</strong>, 又如<span class="math inline">\(Y=\left(\theta_{1}+\theta_{2} x+\theta_{3} x^{2}\right)^{-1}+\varepsilon \quad(\)</span> Holliday 模型 <span class="math inline">\(),\)</span> 又如<span class="math inline">\(Y=\frac{\theta_{1}}{1+\exp \left(\theta_{2}-\theta_{3}^{x}\right)}+\varepsilon \quad(\)</span> Logistic 模型 <span class="math inline">\(),\)</span> 都是本质的非线性回归模型. 非线性回归模型的解法参见《近代非线性回归分析》(韦博成,南京 : 东南大学出版社,1989).</p><h2 id=多元线性回归>多元线性回归</h2><p>在实际问题中,随机变量 <span class="math inline">\(Y\)</span> 往往与多个普通变量 <span class="math inline">\(x_{1}, x_{2}, \cdots, x_{p} \quad(p>1)\)</span> 有关. 对于自变量 <span class="math inline">\(x_{1}, x_{2}, \cdots, x_{p}\)</span> 的一组确定的值,Y有它的分布. 若 <span class="math inline">\(Y\)</span> 的数学期望存在,则它是 <span class="math inline">\(x_{1}, x_{2}, \cdots, x_{p}\)</span> 的函数,记为 <span class="math inline">\(\mu_{Y \mid x_{1}}, x_{2}, \cdots, x_{p}\)</span> 或 <span class="math inline">\(\mu\left(x_{1}, x_{2}, \cdots, x_{p}\right),\)</span> 它就是 <span class="math inline">\(Y\)</span> 关于 <span class="math inline">\(x\)</span> 的回归函数. 我们感兴趣的是 <span class="math inline">\(\mu\left(x_{1}, x_{2}, \cdots, x_{p}\right)\)</span> 是 <span class="math inline">\(x_{1}, x_{2}, \cdots, x_{p}\)</span> 的线性函 数的情况.</p><p>在这里,仅讨论下述多元线性回归模型 :<span class="math inline">\(Y=b_{0}+b_{1} x_{1}+\cdots+b_{p} x_{p}+\varepsilon, \varepsilon \sim N\left(0, \sigma^{2}\right)\)</span> 其中 <span class="math inline">\(b_{0}, b_{1}, \cdots, b_{p}, \sigma^{2}\)</span> 都是与 <span class="math inline">\(x_{1}, x_{2}, \cdots, x_{p}\)</span> 无关的未知参数.</p><p>设<span class="math inline">\(\left(x_{11}, x_{12}, \cdots, x_{1 p}, y_{1}\right), \cdots,\left(x_{n 1}, x_{n 2}, \cdots, x_{n p}, y_{n}\right)\)</span>是一个样本.</p><p>和一元线性回归的情况一样,我们用最大似然估计法来估计参数. 即取 <span class="math inline">\(\hat{b}_{0}, \hat{b}_{1}, \cdots, \hat{b}_{p}\)</span> 使当 <span class="math inline">\(b_{0}=\hat{b}_{0}, b_{1}=\hat{b}_{1}, \cdots, b_{p}=\hat{b}_{p}\)</span> 时<span class="math inline">\(Q=\sum_{i=1}^{n}\left(y_{i}-b_{0}-b_{1} x_{i 1}-\cdots-b_{p} x_{i p}\right)^{2}\)</span>达到最小.</p><p>求 <span class="math inline">\(Q\)</span> 分别关于 <span class="math inline">\(b_{0}, b_{1}, \cdots, b_{p}\)</span> 的偏导数,并令它们等于实,得： <span class="math inline">\(\left.\begin{array}{r}\frac{\partial Q}{\partial b_{0}}=-2 \sum_{i=1}^{n}\left(y_{i}-b_{0}-b_{1} x_{i 1}-\cdots-b_{p} x_{i p}\right)=0, \\ \frac{\partial Q}{\partial b_{j}}=-2 \sum_{i=1}^{n}\left(y_{i}-b_{0}-b_{1} x_{i 1}-\cdots-b_{p} x_{i j}\right) x_{i j}=0, \\ j=1,2, \cdots, p .\end{array}\right\}\)</span></p><p>化简得： <span class="math inline">\(\left.\begin{array}{l}b_{0} n+b_{1} \sum_{i=1}^{n} x_{i 1}+b_{2} \sum_{i=1}^{n} x_{i 2}+\cdots+b_{p} \sum_{i=1}^{n} x_{i p}=\sum_{i=1}^{n} y_{i} \\ b_{0} \sum_{i=1}^{n} x_{i 1}+b_{1} \sum_{i=1}^{n} x_{i 1}^{2}+b_{2} \sum_{i=1}^{n} x_{i 1} x_{i 2}+\cdots+b_{p} \sum_{i=1}^{n} x_{i 1} x_{i p}=\sum_{i=1}^{n} x_{i 1} y_{i} \\ \vdots \\ b_{0} \sum_{i=1}^{n} x_{i p}+b_{1} \sum_{i=1}^{n} x_{i_{i}} x_{i 1}+b_{2} \sum_{i=1}^{n} x_{i p} x_{i 2}+\cdots+b_{p} \sum_{i=1}^{n} x_{i_{p}}^{2}=\sum_{i=1}^{n} x_{i p} y_{i} .\end{array}\right\}\)</span> 称为<strong>正规方程组</strong>. 为了求解的方便,常要将上方程组写成矩阵的形式.</p><p>为此，引入矩阵： <span class="math inline">\(\boldsymbol{X}=\left(\begin{array}{ccccc}1 & x_{11} & x_{12} & \cdots & x_{1 p} \\ 1 & x_{2 i} & x_{22} & \cdots & x_{2 p} \\ \vdots & \vdots & \vdots & & \vdots \\ 1 & x_{n 1} & x_{n 2} & \cdots & x_{n p}\end{array}\right), \boldsymbol{Y}=\left[\begin{array}{c}y_{1} \\ y_{2} \\ \vdots \\ y_{n}\end{array}\right), \boldsymbol{B}=\left(\begin{array}{c}b_{0} \\ b_{1} \\ \vdots \\ b_{p}\end{array}\right) .\)</span></p><p>而有： <span class="math inline">\(\boldsymbol{X}^{\mathrm{T}} \boldsymbol{X}=\left(\begin{array}{cccc}1 & 1 & \cdots & 1 \\ x_{11} & x_{21} & \cdots & x_{n 1} \\ \vdots & \vdots & & \vdots \\ x_{1 p} & x_{2 p} & \cdots & x_{n p}\end{array}\right)\left(\begin{array}{ccccc}1 & x_{11} & x_{12} & \cdots & x_{1 p} \\ 1 & x_{21} & x_{22} & \cdots & x_{2 p} \\ \vdots & \vdots & \vdots & & \vdots \\ 1 & x_{n 1} & x_{n 2} & \cdots & x_{n p}\end{array}\right)\)</span> <span class="math inline">\(=\left(\begin{array}{cccc}n & \sum_{i=1}^{n} x_{i 1} & \cdots & \sum_{i=1}^{n} x_{i p} \\ \sum_{i=1}^{n} x_{i 1} & \sum_{i=1}^{n} x_{i 1}^{2} & \cdots & \sum_{i=1}^{n} x_{i 1} x_{i p} \\ \vdots & \vdots & & \vdots \\ \sum_{i=1}^{n} x_{i p} & \sum_{i=1}^{n} x_{i p} x_{i 1} & \cdots & \sum_{i=1}^{n} x_{i p}^{2}\end{array}\right),\)</span></p><p><span class="math inline">\(\boldsymbol{X}^{\mathrm{T}} \boldsymbol{Y}=\left(\begin{array}{cccc}1 & 1 & \cdots & 1 \\ x_{11} & x_{21} & \cdots & x_{n 1} \\ \vdots & \vdots & & \vdots \\ x_{1 p} & x_{2 p} & \cdots & x_{n p}\end{array}\right)\left(\begin{array}{c}y_{1} \\ y_{2} \\ \vdots \\ y_{n}\end{array}\right)=\left(\begin{array}{c}\sum_{i=1}^{n} y_{i} \\ \sum_{i=1}^{n} x_{i 1} y_{i} \\ \vdots \\ \sum_{i=1}^{n} x_{i p} y_{i}\end{array}\right) .\)</span></p><p>于是正规方程组可以写成： <span class="math inline">\(\boldsymbol{X}^{\mathrm{T}} \boldsymbol{X B}=\boldsymbol{X}^{\mathrm{T}} \boldsymbol{Y}\)</span></p><p>上式两边左乘 <span class="math inline">\(\boldsymbol{X}^{\mathrm{T}} \boldsymbol{X}\)</span> 的逆矩阵 <span class="math inline">\(\left(\boldsymbol{X}^{\mathrm{T}} \boldsymbol{X}\right)^{-1}\)</span> (设<span class="math inline">\(\left(\boldsymbol{X}^{\mathrm{T}} \boldsymbol{X}\right)^{-1}\)</span> 存在 <span class="math inline">\()\)</span> 解得： <span class="math inline">\(\hat{\boldsymbol{B}}=\left(\begin{array}{c}\hat{b}_{0} \\ \hat{b}_{1} \\ \vdots \\ \hat{b}_{p}\end{array}\right)=\left(\boldsymbol{X}^{\mathrm{T}} \boldsymbol{X}\right)^{-1} \mathbf{X}^{\mathrm{T}} \boldsymbol{Y}\)</span> 这就是我们需要求的 <span class="math inline">\(\left(b_{0}, b_{1}, \cdots, b_{p}\right)^{\mathrm{T}}\)</span> 的最大似然估计.</p><p>我们取<span class="math inline">\(\hat{b}_{0}+\hat{b}_{1} x_{1}+\cdots+\hat{b}_{p} x_{p} \stackrel{\text { 记成 }}{=}\hat{y}\)</span>作为 <span class="math inline">\(\mu\left(x_{1}, x_{2}, \cdots, x_{p}\right)=b_{0}+b_{1} x_{1}+\cdots+b_{p} x_{p}\)</span> 的估计. 方程<span class="math inline">\(\hat{y}=\hat{b}_{0}+\hat{b}_{1} x_{1}+\cdots+\hat{b}_{p} x_{p}\)</span>称为 <strong><span class="math inline">\(p\)</span> 元经验线性回归方程</strong>,简称<strong>回归方程</strong>.</p><blockquote><p>例子 下面给出了某种产品每件平均单价 <span class="math inline">\(Y\)</span> (元) 与批量 <span class="math inline">\(x\)</span> (件) 之间的关系的一组数据： <img src=https://picgo12138.oss-cn-hangzhou.aliyuncs.com/md/image-20201225165628628.png alt=image-20201225165628628> 画出散点图： <img src=https://picgo12138.oss-cn-hangzhou.aliyuncs.com/md/image-20201225165659292.png alt=image-20201225165659292> 我们选取模型<span class="math inline">\(Y=b_{0}+b_{1} x+b_{2} x^{2}+\varepsilon, \varepsilon \sim N\left(0, \sigma^{2}\right)\)</span>来拟合它。</p><p>现在来求它的回归方程： 令 <span class="math inline">\(x_{1}=x, x_{2}=x^{2}\)</span>，则模型可以写成<span class="math inline">\(Y=b_{0}+b_{1} x_{1}+b_{2} x_{2}+\varepsilon, \quad \varepsilon \sim N\left(0, \sigma^{2}\right)\)</span>， 这是一个二元线性回归模型。 现在有： <span class="math inline">\(\boldsymbol{X}=\left(\begin{array}{lll}1 & 20 & 400 \\ 1 & 25 & 625 \\ 1 & 30 & 900 \\ 1 & 35 & 1 & 225 \\ 1 & 40 & 1 & 600 \\ 1 & 50 & 2 & 500 \\ 1 & 60 & 3 & 600 \\ 1 & 65 & 4 & 225 \\ 1 & 70 & 4 & 900 \\ 1 & 75 & 5 & 625 \\ 1 & 80 & 6 & 400 \\ 1 & 90 & 8 & 100\end{array}\right), \boldsymbol{Y}=\left(\begin{array}{l}1.81 \\ 1.70 \\ 1.65 \\ 1.55 \\ 1.48 \\ 1.40 \\ 1.30 \\ 1.26 \\ 1.24 \\ 1.21 \\ 1.20 \\ 1.18\end{array}\right), \boldsymbol{B}=\left[\begin{array}{l}b_{0} \\ b_{1} \\ b_{2}\end{array}\right) .\)</span> 经计算： <span class="math inline">\(\boldsymbol{X}^{\mathrm{T}} \boldsymbol{X}=\left(\begin{array}{ccc}12 & 640 & 40100 \\ 640 & 40100 & 2779000 \\ 40100 & 2779000 & 204 702 500\end{array}\right)\)</span> <img src=https://picgo12138.oss-cn-hangzhou.aliyuncs.com/md/image-20201225170109081.png alt=image-20201225170109081> <span class="math inline">\(\Delta=1.41918 \times 10^{11}\)</span>， 得正规方程组的解： <span class="math inline">\(\hat{\boldsymbol{B}}=\left(\begin{array}{l}\hat{b}_{0} \\ \hat{b}_{1} \\ \hat{b}_{2}\end{array}\right)=\left(\boldsymbol{X}^{\mathrm{T}} \boldsymbol{X}\right)^{-1} \boldsymbol{X}^{\mathrm{T}} \boldsymbol{Y}=\left(\boldsymbol{X}^{\mathrm{T}} \boldsymbol{X}\right)^{-1} \quad\left(\begin{array}{l}16.98 \\ 851.3 \\ 51162\end{array}\right)\)</span> <span class="math inline">\(=\left(\begin{array}{lll}2.198 266 29 \\ -0.022 522 36 \\ 0.000 125 07\end{array}\right)\)</span> 于是得到回归方程为<span class="math inline">\(\hat{y}=2.19826629-0.02252236 x+0.00012507 x^{2} .\)</span></p></blockquote><p>像一元线性回归一样,多元线性回归模型<span class="math inline">\(Y=b_{0}+b_{1} x_{1}+\cdots+b_{p} x_{p}+\varepsilon, \varepsilon \sim N\left(0, \sigma^{2}\right)\)</span>往往是一种假定,为了考察这一假定是否符合实际观察结果,还需进行以下的假设检验 : <span class="math inline">\(H_{0}: \quad b_{1}=b_{2}=\cdots=b_{p}=0\)</span> <span class="math inline">\(\mathrm{H}_{1}: b_{i}\)</span> 不全为零 若在显著性水平 <span class="math inline">\(\alpha\)</span> 下拒绝 <span class="math inline">\(H_{0} .\)</span> 我们就认为回归效果是显著的.</p><p>另外,也与一元线性回归一样,多元线性回归方程的一个重要应用是确定给定点 <span class="math inline">\(\left(x_{01}, x_{02}, \cdots, x_{0 p}\right)\)</span> 处对应的 <span class="math inline">\(Y\)</span> 的观察值的预测区间.</p><p>最后我们指出，在实际问题中，与Y有关的因素往往很多，如果将它们都取作自变量必然会导致所得到的回归方程很庞大。 实际上，有些自变量对Y的影响很小，如果将这些自变量剔除，不但能使回归方程较为简洁，便于应用，且能明确哪些因素（即自变量）的改变对Y有显著的影响，从而使人们对事物有进一步的认识。 通常可用<strong>逐步回归法</strong>达到这一目的。 上述关于模型的线性假设的检验、观察值的预测区间、逐步回归等内容，读者可参阅华东师范大学出版社出版的《回归分析及其试验设计》一书</p><p>在实际中，需要考虑的影响Y的因素较多，即自变量的个数较多。因此要求解一个多元线性回归的问题，计算工作量是相当大的，这就需要借助于计算机来进行计算。</p></section></article></main></div><div class="col-sm-3 col-sm-offset-1 doc-sidebar"><div id=sidebar><div class=sidebar-module><div class=sidebar-toc><h4 class=sidebar-heading>Table of Contents</h4><ul><li><strong><a href=#title>概率论与数理统计-数理统计-方差分析与回归分析</a></strong></li></ul></div></div><div class=sidebar-module><h4 class=sidebar-heading>Pages in Categories</h4><ul class=sidebar-category-list><li><a href=https://ole12138.gitee.io//categories/http><span class=doc-list-category>Http</span></a><ul><li><a href=/Servlet3.1-Specification.pdf>Servlet3.1-Specification（转载）</a></li><li><a href=/post/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%8A%80%E6%9C%AF/http%E8%AE%A4%E8%AF%81%E6%96%B9%E5%BC%8F/>HTTP认证方式</a></li><li><a href=/post/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%8A%80%E6%9C%AF/%E5%8F%91%E8%B5%B7http%E8%AF%B7%E6%B1%82%E4%BD%BF%E7%94%A8okhttpclient/>发起HTTP请求：使用OkHttpClient</a></li><li><a href=/post/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%8A%80%E6%9C%AF/%E5%8F%91%E8%B5%B7http%E8%AF%B7%E6%B1%82%E4%BD%BF%E7%94%A8httpurlconnection/>发起HTTP请求：使用HttpURLConnection</a></li><li><a href=/post/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%8A%80%E6%9C%AF/https%E7%AE%80%E5%8D%95%E4%BB%8B%E7%BB%8D%E8%BD%AC%E8%BD%BD/>HTTPS简单介绍（转载）</a></li><li><a href=/post/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%8A%80%E6%9C%AF/ssl%E6%88%96tls%E5%8D%8F%E8%AE%AE%E8%BF%90%E8%A1%8C%E6%9C%BA%E5%88%B6%E7%9A%84%E6%A6%82%E8%BF%B0%E8%BD%AC%E8%BD%BD/>SSL或TLS协议运行机制的概述（转载）</a></li><li><a href=/post/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%8A%80%E6%9C%AF/%E5%BD%BB%E5%BA%95%E6%90%9E%E6%87%82https%E7%9A%84%E5%8A%A0%E5%AF%86%E6%9C%BA%E5%88%B6%E8%BD%AC%E8%BD%BD/>彻底搞懂HTTPS的加密机制（转载）</a></li><li><a href=/post/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%8A%80%E6%9C%AF/%E5%8F%91%E8%B5%B7http%E8%AF%B7%E6%B1%82%E4%BD%BF%E7%94%A8jdk11%E7%9A%84httpclient/>发起HTTP请求：使用JDK11的HttpClient</a></li><li><a href=/post/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%8A%80%E6%9C%AF/%E5%8F%91%E8%B5%B7http%E8%AF%B7%E6%B1%82%E4%BD%BF%E7%94%A8apache%E7%9A%84httpclient/>发起HTTP请求：使用Apache的HttpClient</a></li><li><a href=/post/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%8A%80%E6%9C%AF/http%E5%8D%8F%E8%AE%AE%E4%B8%8E%E6%8A%A5%E6%96%87/>HTTP协议介绍(转载)</a></li><li><a href=/post/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%8A%80%E6%9C%AF/%E5%8F%91%E8%B5%B7http%E8%AF%B7%E6%B1%82spring%E4%B8%ADresttempalate%E8%AE%BE%E7%BD%AE%E8%AF%B7%E6%B1%82%E5%A4%B4%E8%BD%AC%E8%BD%BD/>发起HTTP请求：Spring中RestTemplate设置与携带请求头（转载）</a></li><li><a href=/post/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%8A%80%E6%9C%AF/%E5%8F%91%E8%B5%B7http%E8%AF%B7%E6%B1%82spring%E4%B8%AD%E7%9A%84resttempalate%E7%9A%84%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8%E8%BD%AC%E8%BD%BD/>发起HTTP请求：Spring中的RestTempalate的基本使用（转载）</a></li><li><a href=/post/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%8A%80%E6%9C%AF/%E5%8F%91%E8%B5%B7http%E8%AF%B7%E6%B1%82%E6%96%B9%E5%BC%8F%E6%B1%87%E6%80%BBjava/>Java发起HTTP请求方式汇总</a></li></ul></li><li><a href=https://ole12138.gitee.io//categories/java><span class=doc-list-category>Java</span></a><ul><li><a href=/post/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%8A%80%E6%9C%AF/java%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E8%A7%82%E5%AF%9F%E8%80%85%E6%A8%A1%E5%BC%8F%E8%BD%AC%E8%BD%BD/>Java设计模式之观察者模式（转载）</a></li><li><a href=/post/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%8A%80%E6%9C%AF/java%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E5%A7%94%E6%B4%BE%E6%A8%A1%E5%BC%8F%E4%B8%8E%E6%A8%A1%E6%9D%BF%E6%A8%A1%E5%BC%8F%E8%BD%AC%E8%BD%BD/>Java设计模式之委派模式与模板模式（转载）</a></li><li><a href=/post/%E9%9A%8F%E7%AC%94/%E9%9A%8F%E7%AC%94-spring%E5%8F%8Aspringmvc%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E4%B8%ADannotation-config%E5%92%8Cannotation-driven%E5%92%8Ccomponent-scan%E7%9A%84%E5%8C%BA%E5%88%AB%E8%BD%AC%E8%BD%BD/>随笔-Spring及SpringMVC配置文件中annotation-config和annotation-driven和component-scan的区别（转载）</a></li><li><a href=/post/%E9%9A%8F%E7%AC%94/%E9%9A%8F%E7%AC%94-spring%E9%A1%B9%E7%9B%AE%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6xsd%E5%BC%95%E7%94%A8%E9%97%AE%E9%A2%98/>随笔-Spring项目配置文件xsd引用问题</a></li><li><a href=/post/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%8A%80%E6%9C%AF/springmvc%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E8%BD%AC%E8%BD%BD/>SpringMVC源码分析（转载）</a></li><li><a href=/post/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%8A%80%E6%9C%AF/springmvc%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B%E4%B8%8E%E4%BD%BF%E7%94%A8%E8%BD%AC%E8%BD%BD/>SpringMVC工作流程与使用方式（转载）</a></li><li><a href=/post/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%8A%80%E6%9C%AF/java%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E9%80%82%E9%85%8D%E5%99%A8%E6%A8%A1%E5%BC%8F%E8%BD%AC%E8%BD%BD/>Java设计模式之适配器模式（转载）</a></li><li><a href=/post/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%8A%80%E6%9C%AF/%E5%8F%91%E8%B5%B7http%E8%AF%B7%E6%B1%82%E4%BD%BF%E7%94%A8okhttpclient/>发起HTTP请求：使用OkHttpClient</a></li><li><a href=/post/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%8A%80%E6%9C%AF/%E5%8F%91%E8%B5%B7http%E8%AF%B7%E6%B1%82%E4%BD%BF%E7%94%A8httpurlconnection/>发起HTTP请求：使用HttpURLConnection</a></li><li><a href=/post/%E9%9A%8F%E7%AC%94/%E9%9A%8F%E7%AC%94-jdk%E7%89%88%E6%9C%AC%E7%9A%84%E5%88%87%E6%8D%A2/>随笔-JDK版本的切换</a></li><li><a href=/post/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%8A%80%E6%9C%AF/%E5%8F%91%E8%B5%B7http%E8%AF%B7%E6%B1%82%E4%BD%BF%E7%94%A8jdk11%E7%9A%84httpclient/>发起HTTP请求：使用JDK11的HttpClient</a></li><li><a href=/post/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%8A%80%E6%9C%AF/%E5%8F%91%E8%B5%B7http%E8%AF%B7%E6%B1%82%E4%BD%BF%E7%94%A8apache%E7%9A%84httpclient/>发起HTTP请求：使用Apache的HttpClient</a></li><li><a href=/post/%E9%9A%8F%E7%AC%94/%E9%9A%8F%E7%AC%94-java%E4%B8%AD%E8%B5%84%E6%BA%90%E7%9A%84%E5%85%B3%E9%97%AD/>Java中资源的关闭</a></li><li><a href=/post/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%8A%80%E6%9C%AF/java%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E4%BB%A3%E7%90%86%E6%A8%A1%E5%BC%8F/>Java设计模式之代理模式</a></li><li><a href=/post/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%8A%80%E6%9C%AF/%E5%8F%91%E8%B5%B7http%E8%AF%B7%E6%B1%82spring%E4%B8%ADresttempalate%E8%AE%BE%E7%BD%AE%E8%AF%B7%E6%B1%82%E5%A4%B4%E8%BD%AC%E8%BD%BD/>发起HTTP请求：Spring中RestTemplate设置与携带请求头（转载）</a></li><li><a href=/post/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%8A%80%E6%9C%AF/%E5%8F%91%E8%B5%B7http%E8%AF%B7%E6%B1%82spring%E4%B8%AD%E7%9A%84resttempalate%E7%9A%84%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8%E8%BD%AC%E8%BD%BD/>发起HTTP请求：Spring中的RestTempalate的基本使用（转载）</a></li><li><a href=/post/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%8A%80%E6%9C%AF/%E5%8F%91%E8%B5%B7http%E8%AF%B7%E6%B1%82%E6%96%B9%E5%BC%8F%E6%B1%87%E6%80%BBjava/>Java发起HTTP请求方式汇总</a></li><li><a href=/post/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%8A%80%E6%9C%AF/java8%E5%87%BD%E6%95%B0%E5%BC%8F%E7%BC%96%E7%A8%8B%E5%85%A5%E9%97%A8%E8%BD%AC%E8%BD%BD/>Java8函数式编程入门（转载）</a></li><li><a href=/post/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%8A%80%E6%9C%AF/java%E6%B3%A8%E8%A7%A3annotation%E8%BD%AC%E8%BD%BD/>Java Annotation认知（转载）</a></li></ul></li><li><a href=https://ole12138.gitee.io//categories/java%E9%9A%8F%E7%AC%94><span class=doc-list-category>Java随笔</span></a><ul><li><a href=/post/%E9%9A%8F%E7%AC%94/%E9%9A%8F%E7%AC%94-spring%E5%8F%8Aspringmvc%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E4%B8%ADannotation-config%E5%92%8Cannotation-driven%E5%92%8Ccomponent-scan%E7%9A%84%E5%8C%BA%E5%88%AB%E8%BD%AC%E8%BD%BD/>随笔-Spring及SpringMVC配置文件中annotation-config和annotation-driven和component-scan的区别（转载）</a></li><li><a href=/post/%E9%9A%8F%E7%AC%94/%E9%9A%8F%E7%AC%94-spring%E9%A1%B9%E7%9B%AE%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6xsd%E5%BC%95%E7%94%A8%E9%97%AE%E9%A2%98/>随笔-Spring项目配置文件xsd引用问题</a></li></ul></li><li><a href=https://ole12138.gitee.io//categories/spring><span class=doc-list-category>Spring</span></a><ul><li><a href=/post/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%8A%80%E6%9C%AF/spring%E7%9A%84aop%E7%9A%84%E4%BD%BF%E7%94%A8/>Spring的AOP的使用</a></li><li><a href=/post/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%8A%80%E6%9C%AF/spring%E4%BB%8Exml%E5%90%AF%E5%8A%A8%E6%B3%A8%E8%A7%A3%E6%89%AB%E6%8F%8F%E7%9A%84%E8%BF%87%E7%A8%8B/>Spring从xml启动注解扫描的过程</a></li><li><a href=/post/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%8A%80%E6%9C%AF/spring%E6%96%87%E6%A1%A3%E4%B8%AD%E6%96%87%E7%BF%BB%E8%AF%91%E8%BD%AC%E8%BD%BD/>Spring文档中文翻译</a></li><li><a href=/post/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%8A%80%E6%9C%AF/spring%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E8%B5%B7%E6%AD%A5/>Spring源码分析起步</a></li><li><a href=/post/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%8A%80%E6%9C%AF/springboot%E6%9E%84%E5%BB%BArestfulwebservice/>Spring构建restfulWebService</a></li></ul></li><li><a href=https://ole12138.gitee.io//categories/todo><span class=doc-list-category>Todo</span></a><ul><li><a href=/post/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%8A%80%E6%9C%AF/%E5%8F%91%E8%B5%B7http%E8%AF%B7%E6%B1%82%E4%BD%BF%E7%94%A8httpurlconnection/>发起HTTP请求：使用HttpURLConnection</a></li></ul></li><li><a href=https://ole12138.gitee.io//categories/%E5%89%8D%E5%90%8E%E7%AB%AF%E5%88%86%E7%A6%BB><span class=doc-list-category>前后端分离</span></a><ul><li><a href=/post/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%8A%80%E6%9C%AF/web%E5%89%8D%E5%90%8E%E7%AB%AF%E5%88%86%E7%A6%BB%E7%9A%84%E5%AE%9E%E7%8E%B0%E6%96%B9%E5%BC%8F%E8%BD%AC%E8%BD%BD/>Web前后端分离的实现方式（转载）</a></li></ul></li><li><a href=https://ole12138.gitee.io//categories/%E5%90%8E%E7%AB%AF><span class=doc-list-category>后端</span></a><ul><li><a href=/post/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%8A%80%E6%9C%AF/%E7%99%BB%E5%BD%95%E4%B8%8E%E5%AE%89%E5%85%A8/%E7%AE%80%E5%8D%95%E7%99%BB%E5%BD%95%E9%AA%8C%E8%AF%81%E7%9A%84%E5%AE%9E%E7%8E%B0/>简单登录验证的实现</a></li></ul></li><li><a href=https://ole12138.gitee.io//categories/%E5%B7%A5%E5%85%B7><span class=doc-list-category>工具</span></a><ul><li><a href=/post/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%8A%80%E6%9C%AF/maven%E6%89%93%E5%8C%85/>Maven打包</a></li><li><a href=/post/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%8A%80%E6%9C%AF/maven%E4%BD%BF%E7%94%A8%E8%BD%AC%E8%BD%BD/>Maven pom.xml中的元素modules、parent、properties以及import（转载）</a></li></ul></li><li><a href=https://ole12138.gitee.io//categories/%E6%95%B0%E5%AD%A6><span class=doc-list-category>数学</span></a><ul><li><a href=/post/%E6%95%B0%E5%AD%A6%E6%80%BB%E7%BB%93/%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1-%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1-%E5%81%87%E8%AE%BE%E6%A3%80%E9%AA%8C/>概率论与数理统计-数理统计-假设检验</a></li><li><a href=/post/%E6%95%B0%E5%AD%A6%E6%80%BB%E7%BB%93/%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1-%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1-%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1/>概率论与数理统计-数理统计-参数估计</a></li><li><a href=/post/%E6%95%B0%E5%AD%A6%E6%80%BB%E7%BB%93/%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1-%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1-%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/>概率论与数理统计-数理统计-基本概念</a></li><li><a href=/post/%E6%95%B0%E5%AD%A6%E6%80%BB%E7%BB%93/%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1-%E6%A6%82%E7%8E%87%E8%AE%BA-%E5%A4%A7%E6%95%B0%E5%AE%9A%E5%BE%8B%E4%B8%8E%E4%B8%AD%E5%BF%83%E6%9E%81%E9%99%90%E5%AE%9A%E7%90%86/>概率论与数理统计-概率论-大数定律与中心极限定理</a></li><li><a href=/post/%E6%95%B0%E5%AD%A6%E6%80%BB%E7%BB%93/%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1-%E6%A6%82%E7%8E%87%E8%AE%BA-%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E7%9A%84%E6%95%B0%E5%AD%97%E7%89%B9%E5%BE%81/>概率论与数理统计-概率论-随机变量的数字特征</a></li><li><a href=/post/%E6%95%B0%E5%AD%A6%E6%80%BB%E7%BB%93/%E6%95%B0%E5%AD%A6%E5%88%86%E6%94%AF%E7%9A%84%E6%80%BB%E7%BB%93/>数学分支的总结</a></li><li><a href=/post/%E6%95%B0%E5%AD%A6%E6%80%BB%E7%BB%93/%E6%95%B0%E5%AD%A6%E7%89%A9%E7%90%86%E6%96%B9%E6%B3%95%E6%80%BB%E7%BB%93/>数学物理方法总结</a></li><li><a href=/post/%E6%95%B0%E5%AD%A6%E6%80%BB%E7%BB%93/%E6%9C%80%E4%BC%98%E5%8C%96%E9%97%AE%E9%A2%98%E6%80%BB%E7%BB%93/>最优化问题总结</a></li><li><span class=active>概率论与数理统计-数理统计-方差分析与回归分析</span></li><li><a href=/post/%E6%95%B0%E5%AD%A6%E6%80%BB%E7%BB%93/%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1-%E6%A6%82%E7%8E%87%E8%AE%BA-%E9%9A%8F%E6%9C%BA%E4%BA%8B%E4%BB%B6%E4%B8%8E%E6%A6%82%E7%8E%87/>概率论与数理统计-概率论-随机事件与概率</a></li><li><a href=/post/%E6%95%B0%E5%AD%A6%E6%80%BB%E7%BB%93/%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1-%E6%A6%82%E7%8E%87%E8%AE%BA-%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E5%8F%8A%E5%85%B6%E6%A6%82%E7%8E%87%E5%88%86%E5%B8%83/>概率论与数理统计-概率论-随机变量及其分布</a></li><li><a href=/post/%E6%95%B0%E5%AD%A6%E6%80%BB%E7%BB%93/%E6%B3%9B%E5%87%BD%E5%88%86%E6%9E%90%E6%80%BB%E7%BB%93/>泛函分析</a></li><li><a href=/post/%E6%95%B0%E5%AD%A6%E6%80%BB%E7%BB%93/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0-%E7%9B%B8%E4%BC%BC%E7%9F%A9%E9%98%B5%E4%B8%8E%E4%BA%8C%E6%AC%A1%E5%9E%8B/>线性代数-相似矩阵与二次型</a></li><li><a href=/post/%E6%95%B0%E5%AD%A6%E6%80%BB%E7%BB%93/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0-%E7%9B%B8%E4%BC%BC%E7%9F%A9%E9%98%B5%E4%B8%8E%E4%BA%8C%E6%AC%A1%E5%9E%8B%E4%B9%A0%E9%A2%98/>线性代数-相似矩阵与二次型习题</a></li><li><a href=/post/%E6%95%B0%E5%AD%A6%E6%80%BB%E7%BB%93/%E9%AB%98%E7%AD%89%E6%95%B0%E5%AD%A6-%E7%BA%A7%E6%95%B0/>高等数学-级数</a></li><li><a href=/post/%E6%95%B0%E5%AD%A6%E6%80%BB%E7%BB%93/%E9%AB%98%E7%AD%89%E6%95%B0%E5%AD%A6-%E7%BA%A7%E6%95%B0%E4%B9%A0%E9%A2%98/>高等数学-级数习题</a></li><li><a href=/post/%E6%95%B0%E5%AD%A6%E6%80%BB%E7%BB%93/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0-%E5%90%91%E9%87%8F%E7%BB%84%E7%9A%84%E7%BA%BF%E6%80%A7%E7%9B%B8%E5%85%B3%E6%80%A7/>线性代数-向量组的线性相关性</a></li><li><a href=/post/%E6%95%B0%E5%AD%A6%E6%80%BB%E7%BB%93/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0-%E5%90%91%E9%87%8F%E7%BB%84%E7%9A%84%E7%BA%BF%E6%80%A7%E7%9B%B8%E5%85%B3%E6%80%A7%E4%B9%A0%E9%A2%98/>线性代数-向量组的线性相关性习题</a></li><li><a href=/post/%E6%95%B0%E5%AD%A6%E6%80%BB%E7%BB%93/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0-%E7%9F%A9%E9%98%B52%E7%9F%A9%E9%98%B5%E5%88%9D%E7%AD%89%E5%8F%98%E6%8D%A2%E4%B8%8E%E7%BA%BF%E6%80%A7%E6%96%B9%E7%A8%8B%E7%BB%84%E4%B9%A0%E9%A2%98/>线性代数-矩阵初等变换与线性方程组习题</a></li><li><a href=/post/%E6%95%B0%E5%AD%A6%E6%80%BB%E7%BB%93/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0-%E7%9F%A9%E9%98%B52%E7%9F%A9%E9%98%B5%E5%88%9D%E7%AD%89%E5%8F%98%E6%8D%A2%E4%B8%8E%E7%BA%BF%E6%80%A7%E6%96%B9%E7%A8%8B%E7%BB%84/>线性代数-矩阵初等变换与线性方程组习题</a></li><li><a href=/post/%E6%95%B0%E5%AD%A6%E6%80%BB%E7%BB%93/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0-%E7%9F%A9%E9%98%B51/>线性代数-矩阵1</a></li><li><a href=/post/%E6%95%B0%E5%AD%A6%E6%80%BB%E7%BB%93/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0-%E7%9F%A9%E9%98%B51%E4%B9%A0%E9%A2%98/>线性代数-矩阵1习题</a></li><li><a href=/post/%E6%95%B0%E5%AD%A6%E6%80%BB%E7%BB%93/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0-%E8%A1%8C%E5%88%97%E5%BC%8F/>线性代数-行列式</a></li><li><a href=/post/%E6%95%B0%E5%AD%A6%E6%80%BB%E7%BB%93/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0-%E8%A1%8C%E5%88%97%E5%BC%8F%E4%B9%A0%E9%A2%98/>线性代数-行列式习题</a></li><li><a href=/post/%E6%95%B0%E5%AD%A6%E6%80%BB%E7%BB%93/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E6%80%BB%E7%BB%93/>线性代数总结</a></li><li><a href=/post/%E6%95%B0%E5%AD%A6%E6%80%BB%E7%BB%93/%E9%AB%98%E7%AD%89%E6%95%B0%E5%AD%A6-%E5%A4%9A%E5%85%83%E5%BE%AE%E7%A7%AF%E5%88%86-%E5%A4%9A%E5%85%83%E7%A7%AF%E5%88%86%E5%AD%A6-%E6%9B%B2%E7%BA%BF%E7%A7%AF%E5%88%86%E4%B8%8E%E6%9B%B2%E9%9D%A2%E7%A7%AF%E5%88%86%E4%B9%A0%E9%A2%98/>高等数学-多元微积分-曲线积分与曲面积分习题</a></li><li><a href=/post/%E6%95%B0%E5%AD%A6%E6%80%BB%E7%BB%93/%E9%AB%98%E7%AD%89%E6%95%B0%E5%AD%A6-%E5%A4%9A%E5%85%83%E5%BE%AE%E7%A7%AF%E5%88%86-%E5%A4%9A%E5%85%83%E7%A7%AF%E5%88%86%E5%AD%A6-%E6%9B%B2%E7%BA%BF%E7%A7%AF%E5%88%86%E4%B8%8E%E6%9B%B2%E9%9D%A2%E7%A7%AF%E5%88%86/>高等数学-多元微积分-曲线积分与曲面积分</a></li><li><a href=/post/%E6%95%B0%E5%AD%A6%E6%80%BB%E7%BB%93/%E9%AB%98%E7%AD%89%E6%95%B0%E5%AD%A6-%E5%A4%9A%E5%85%83%E5%BE%AE%E7%A7%AF%E5%88%86-%E5%A4%9A%E5%85%83%E7%A7%AF%E5%88%86%E5%AD%A6-%E9%87%8D%E7%A7%AF%E5%88%86%E4%B9%A0%E9%A2%98/>高等数学-多元积分学-重积分习题</a></li><li><a href=/post/%E6%95%B0%E5%AD%A6%E6%80%BB%E7%BB%93/%E9%AB%98%E7%AD%89%E6%95%B0%E5%AD%A6-%E5%A4%9A%E5%85%83%E5%BE%AE%E7%A7%AF%E5%88%86-%E5%A4%9A%E5%85%83%E7%A7%AF%E5%88%86%E5%AD%A6-%E9%87%8D%E7%A7%AF%E5%88%86/>高等数学-多元积分学-重积分</a></li><li><a href=/post/%E6%95%B0%E5%AD%A6%E6%80%BB%E7%BB%93/%E9%AB%98%E7%AD%89%E6%95%B0%E5%AD%A6-%E5%A4%9A%E5%85%83%E5%BE%AE%E7%A7%AF%E5%88%86-%E5%A4%9A%E5%85%83%E5%BE%AE%E5%88%86%E5%AD%A6%E4%B9%A0%E9%A2%98/>高等数学-多元微分学习题</a></li><li><a href=/post/%E6%95%B0%E5%AD%A6%E6%80%BB%E7%BB%93/%E9%AB%98%E7%AD%89%E6%95%B0%E5%AD%A6-%E5%A4%9A%E5%85%83%E5%BE%AE%E7%A7%AF%E5%88%86-%E5%A4%9A%E5%85%83%E5%BE%AE%E5%88%86%E5%AD%A6-%E5%87%A0%E4%BD%95%E5%BA%94%E7%94%A8%E5%90%91%E9%87%8F%E5%80%BC%E5%87%BD%E6%95%B0%E4%B8%8E%E5%90%91%E9%87%8F%E5%88%86%E6%9E%90/>高等数学-多元微积分-多元微分学-向量值函数和向量分析</a></li><li><a href=/post/%E6%95%B0%E5%AD%A6%E6%80%BB%E7%BB%93/%E9%AB%98%E7%AD%89%E6%95%B0%E5%AD%A6-%E5%A4%9A%E5%85%83%E5%BE%AE%E7%A7%AF%E5%88%86-%E5%A4%9A%E5%85%83%E5%BE%AE%E5%88%86%E5%AD%A6-%E4%BB%A3%E6%95%B0%E5%BA%94%E7%94%A8%E6%9E%81%E5%80%BC%E4%B8%8E%E6%9C%80%E5%80%BC/>高等数学-多元微分学-代数应用：多元函数的极值</a></li><li><a href=/post/%E6%95%B0%E5%AD%A6%E6%80%BB%E7%BB%93/%E9%AB%98%E7%AD%89%E6%95%B0%E5%AD%A6-%E5%A4%9A%E5%85%83%E5%BE%AE%E7%A7%AF%E5%88%86-%E5%A4%9A%E5%85%83%E5%BE%AE%E5%88%86%E5%AD%A6-%E6%A6%82%E5%BF%B5%E4%B8%8E%E6%80%A7%E8%B4%A8/>高等数学-多元微分学</a></li><li><a href=/post/%E6%95%B0%E5%AD%A6%E6%80%BB%E7%BB%93/%E9%AB%98%E7%AD%89%E6%95%B0%E5%AD%A6-%E5%A4%9A%E5%85%83%E5%BE%AE%E7%A7%AF%E5%88%86-%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%8C%83%E5%9B%B4/>高等数学-多元微积分概述</a></li><li><a href=/post/%E6%95%B0%E5%AD%A6%E6%80%BB%E7%BB%93/%E9%AB%98%E7%AD%89%E6%95%B0%E5%AD%A6-%E5%90%91%E9%87%8F%E4%BB%A3%E6%95%B0%E4%B8%8E%E7%A9%BA%E9%97%B4%E8%A7%A3%E6%9E%90%E5%87%A0%E4%BD%95/>高等数学-向量代数与空间解析几何</a></li><li><a href=/post/%E6%95%B0%E5%AD%A6%E6%80%BB%E7%BB%93/%E9%AB%98%E7%AD%89%E6%95%B0%E5%AD%A6-%E5%90%91%E9%87%8F%E4%BB%A3%E6%95%B0%E4%B8%8E%E7%A9%BA%E9%97%B4%E8%A7%A3%E6%9E%90%E5%87%A0%E4%BD%95%E4%B9%A0%E9%A2%98/>高等数学-向量代数与空间解析几何习题</a></li><li><a href=/post/%E6%95%B0%E5%AD%A6%E6%80%BB%E7%BB%93/%E9%AB%98%E7%AD%89%E6%95%B0%E5%AD%A6-%E5%BE%AE%E5%88%86%E6%96%B9%E7%A8%8B/>高等数学-微分方程</a></li><li><a href=/post/%E6%95%B0%E5%AD%A6%E6%80%BB%E7%BB%93/%E9%AB%98%E7%AD%89%E6%95%B0%E5%AD%A6-%E5%BE%AE%E5%88%86%E6%96%B9%E7%A8%8B%E4%B9%A0%E9%A2%98/>高等数学-微分方程习题</a></li><li><a href=/post/%E6%95%B0%E5%AD%A6%E6%80%BB%E7%BB%93/%E9%AB%98%E7%AD%89%E6%95%B0%E5%AD%A6-%E4%B8%80%E5%85%83%E5%BE%AE%E7%A7%AF%E5%88%86-%E4%B8%80%E5%85%83%E7%A7%AF%E5%88%86%E5%AD%A6-%E5%AE%9A%E7%A7%AF%E5%88%86%E7%9A%84%E5%BA%94%E7%94%A8/>高等数学-一元积分学-定积分的应用</a></li><li><a href=/post/%E6%95%B0%E5%AD%A6%E6%80%BB%E7%BB%93/%E9%AB%98%E7%AD%89%E6%95%B0%E5%AD%A6-%E4%B8%80%E5%85%83%E5%BE%AE%E7%A7%AF%E5%88%86-%E4%B8%80%E5%85%83%E7%A7%AF%E5%88%86%E5%AD%A6-%E5%AE%9A%E7%A7%AF%E5%88%86%E7%9A%84%E5%BA%94%E7%94%A8%E4%B9%A0%E9%A2%98/>高等数学-一元积分学-定积分的应用</a></li><li><a href=/post/%E6%95%B0%E5%AD%A6%E6%80%BB%E7%BB%93/%E9%AB%98%E7%AD%89%E6%95%B0%E5%AD%A6-%E4%B8%80%E5%85%83%E5%BE%AE%E7%A7%AF%E5%88%86-%E4%B8%80%E5%85%83%E7%A7%AF%E5%88%86%E5%AD%A6-%E5%AE%9A%E7%A7%AF%E5%88%86%E4%B8%8E%E5%B9%BF%E4%B9%89%E7%A7%AF%E5%88%86/>高等数学-一元积分学-定积分与反常积分</a></li><li><a href=/post/%E6%95%B0%E5%AD%A6%E6%80%BB%E7%BB%93/%E9%AB%98%E7%AD%89%E6%95%B0%E5%AD%A6-%E4%B8%80%E5%85%83%E5%BE%AE%E7%A7%AF%E5%88%86-%E4%B8%80%E5%85%83%E7%A7%AF%E5%88%86%E5%AD%A6-%E5%AE%9A%E7%A7%AF%E5%88%86%E4%B8%8E%E5%B9%BF%E4%B9%89%E7%A7%AF%E5%88%86%E4%B9%A0%E9%A2%98/>高等数学-一元积分学-定积分与反常积分</a></li><li><a href=/post/%E6%95%B0%E5%AD%A6%E6%80%BB%E7%BB%93/%E9%AB%98%E7%AD%89%E6%95%B0%E5%AD%A6-%E4%B8%80%E5%85%83%E5%BE%AE%E7%A7%AF%E5%88%86-%E4%B8%80%E5%85%83%E7%A7%AF%E5%88%86%E5%AD%A6-%E4%B8%8D%E5%AE%9A%E7%A7%AF%E5%88%86/>高等数学-一元积分学-不定积分</a></li><li><a href=/post/%E6%95%B0%E5%AD%A6%E6%80%BB%E7%BB%93/%E9%AB%98%E7%AD%89%E6%95%B0%E5%AD%A6-%E4%B8%80%E5%85%83%E5%BE%AE%E7%A7%AF%E5%88%86-%E4%B8%80%E5%85%83%E7%A7%AF%E5%88%86%E5%AD%A6-%E4%B8%8D%E5%AE%9A%E7%A7%AF%E5%88%86%E4%B9%A0%E9%A2%98/>高等数学-一元积分学-不定积分</a></li><li><a href=/post/%E6%95%B0%E5%AD%A6%E6%80%BB%E7%BB%93/%E9%AB%98%E7%AD%89%E6%95%B0%E5%AD%A6-%E4%B8%80%E5%85%83%E5%BE%AE%E7%A7%AF%E5%88%86-%E4%B8%80%E5%85%83%E5%BE%AE%E5%88%86%E5%AD%A6-%E5%BA%94%E7%94%A8-%E5%BC%A7%E5%BE%AE%E5%88%86%E4%B8%8E%E6%9B%B2%E7%8E%87%E4%B9%A0%E9%A2%98/>高等数学-一元微分学-一元微分学的应用-弧微分与曲率</a></li><li><a href=/post/%E6%95%B0%E5%AD%A6%E6%80%BB%E7%BB%93/%E9%AB%98%E7%AD%89%E6%95%B0%E5%AD%A6-%E4%B8%80%E5%85%83%E5%BE%AE%E7%A7%AF%E5%88%86-%E4%B8%80%E5%85%83%E5%BE%AE%E5%88%86%E5%AD%A6-%E5%BA%94%E7%94%A8-%E5%BC%A7%E5%BE%AE%E5%88%86%E4%B8%8E%E6%9B%B2%E7%8E%87/>高等数学-一元微分学-导数的应用</a></li><li><a href=/post/%E6%95%B0%E5%AD%A6%E6%80%BB%E7%BB%93/%E9%AB%98%E7%AD%89%E6%95%B0%E5%AD%A6-%E4%B8%80%E5%85%83%E5%BE%AE%E7%A7%AF%E5%88%86-%E4%B8%80%E5%85%83%E5%BE%AE%E5%88%86%E5%AD%A6-%E5%AF%BC%E6%95%B0%E4%B8%8E%E5%BE%AE%E5%88%86%E4%B9%A0%E9%A2%98/>高等数学-一元函数微分学-单调性与极值</a></li><li><a href=/post/%E6%95%B0%E5%AD%A6%E6%80%BB%E7%BB%93/%E9%AB%98%E7%AD%89%E6%95%B0%E5%AD%A6-%E4%B8%80%E5%85%83%E5%BE%AE%E7%A7%AF%E5%88%86-%E4%B8%80%E5%85%83%E5%BE%AE%E5%88%86%E5%AD%A6-%E5%BA%94%E7%94%A8-%E5%8D%95%E8%B0%83%E6%80%A7%E4%B8%8E%E6%9E%81%E5%80%BC/>高等数学-一元函数微分学-单调性与极值</a></li><li><a href=/post/%E6%95%B0%E5%AD%A6%E6%80%BB%E7%BB%93/%E9%AB%98%E7%AD%89%E6%95%B0%E5%AD%A6-%E4%B8%80%E5%85%83%E5%BE%AE%E7%A7%AF%E5%88%86-%E4%B8%80%E5%85%83%E5%BE%AE%E5%88%86%E5%AD%A6-%E5%BA%94%E7%94%A8-%E4%B8%AD%E5%80%BC%E5%AE%9A%E7%90%86/>高等数学-一元微分学-可导函数的中值定理</a></li><li><a href=/post/%E6%95%B0%E5%AD%A6%E6%80%BB%E7%BB%93/%E9%AB%98%E7%AD%89%E6%95%B0%E5%AD%A6-%E4%B8%80%E5%85%83%E5%BE%AE%E7%A7%AF%E5%88%86-%E4%B8%80%E5%85%83%E5%BE%AE%E5%88%86%E5%AD%A6-%E5%BA%94%E7%94%A8-%E4%B8%AD%E5%80%BC%E5%AE%9A%E7%90%86%E4%B9%A0%E9%A2%98/>高等数学-一元微分学-可导函数的中值定理习题</a></li><li><a href=/post/%E6%95%B0%E5%AD%A6%E6%80%BB%E7%BB%93/%E9%AB%98%E7%AD%89%E6%95%B0%E5%AD%A6-%E4%B8%80%E5%85%83%E5%BE%AE%E7%A7%AF%E5%88%86-%E4%B8%80%E5%85%83%E5%BE%AE%E5%88%86%E5%AD%A6-%E5%BA%94%E7%94%A8-%E5%8D%95%E8%B0%83%E6%80%A7%E4%B8%8E%E6%9E%81%E5%80%BC%E4%B9%A0%E9%A2%98/>高等数学-一元微分学-导数的应用-单调性与极值</a></li><li><a href=/post/%E6%95%B0%E5%AD%A6%E6%80%BB%E7%BB%93/%E9%AB%98%E7%AD%89%E6%95%B0%E5%AD%A6-%E4%B8%80%E5%85%83%E5%BE%AE%E7%A7%AF%E5%88%86-%E4%B8%80%E5%85%83%E5%BE%AE%E5%88%86%E5%AD%A6-%E5%AF%BC%E6%95%B0%E5%92%8C%E5%BE%AE%E5%88%86/>高等数学-一元微分学-导数和微分</a></li><li><a href=/post/%E6%95%B0%E5%AD%A6%E6%80%BB%E7%BB%93/%E9%AB%98%E7%AD%89%E6%95%B0%E5%AD%A6-%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5-%E5%87%BD%E6%95%B0%E4%B8%8E%E6%9E%81%E9%99%90/>高等数学-基础概念-函数与极限</a></li><li><a href=/post/%E6%95%B0%E5%AD%A6%E6%80%BB%E7%BB%93/%E9%AB%98%E7%AD%89%E6%95%B0%E5%AD%A6-%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5-%E5%87%BD%E6%95%B0%E4%B8%8E%E6%9E%81%E9%99%90%E4%B9%A0%E9%A2%98/>高等数学-基础概念-函数与极限习题</a></li><li><a href=/post/%E6%95%B0%E5%AD%A6%E6%80%BB%E7%BB%93/%E9%AB%98%E7%AD%89%E6%95%B0%E5%AD%A6-%E4%B8%80%E5%85%83%E5%BE%AE%E7%A7%AF%E5%88%86-%E8%84%89%E7%BB%9C/>高等数学-一元微积分-脉络</a></li><li><a href=/post/%E6%95%B0%E5%AD%A6%E6%80%BB%E7%BB%93/%E6%95%B0%E5%AD%A6%E5%88%86%E6%9E%90%E5%92%8C%E9%AB%98%E7%AD%89%E6%95%B0%E5%AD%A6%E6%80%BB%E7%BB%93/>高等数学与数学分析</a></li><li><a href=/post/%E6%95%B0%E5%AD%A6%E6%80%BB%E7%BB%93/%E5%9F%BA%E7%A1%80%E6%95%B0%E5%AD%A6-%E4%B8%89%E8%A7%92%E5%87%BD%E6%95%B0/>基础数学-三角函数</a></li><li><a href=/post/%E6%95%B0%E5%AD%A6%E6%80%BB%E7%BB%93/%E5%9F%BA%E7%A1%80%E6%95%B0%E5%AD%A6-%E4%BB%A3%E6%95%B0/>基础数学-代数</a></li><li><a href=/post/%E6%95%B0%E5%AD%A6%E6%80%BB%E7%BB%93/%E5%9F%BA%E7%A1%80%E6%95%B0%E5%AD%A6-%E5%87%A0%E4%BD%95/>基础数学-几何</a></li></ul></li><li><a href=https://ole12138.gitee.io//categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95><span class=doc-list-category>数据结构与算法</span></a><ul><li><a href=/post/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%E6%80%BB%E7%BB%93/pat%E4%B9%A0%E9%A2%98/>PAT甲级习题</a></li><li><a href=/post/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%E6%80%BB%E7%BB%93/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E6%A0%88%E5%92%8C%E9%98%9F%E5%88%97%E4%BB%A5%E5%8F%8A%E6%95%B0%E7%BB%84/>数据结构-栈和队列</a></li><li><a href=/post/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%E6%80%BB%E7%BB%93/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E7%BA%BF%E6%80%A7%E8%A1%A8/>数据结构-线性表</a></li><li><a href=/post/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%E6%80%BB%E7%BB%93/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%92%8C%E7%AE%97%E6%B3%95%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/>数据结构与算法的基本概念</a></li><li><a href=/post/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%E6%80%BB%E7%BB%93/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E6%80%BB%E7%BB%93/>数据结构总结</a></li><li><a href=/post/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%E6%80%BB%E7%BB%93/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E6%A0%91%E5%92%8C%E4%BA%8C%E5%8F%89%E6%A0%91/>树和二叉树</a></li><li><a href=/post/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%E6%80%BB%E7%BB%93/%E7%AE%97%E6%B3%95%E6%80%BB%E7%BB%93/>算法总结</a></li></ul></li><li><a href=https://ole12138.gitee.io//categories/%E7%89%A9%E7%90%86><span class=doc-list-category>物理</span></a><ul><li><a href=/post/%E6%95%B0%E5%AD%A6%E6%80%BB%E7%BB%93/%E6%95%B0%E5%AD%A6%E7%89%A9%E7%90%86%E6%96%B9%E6%B3%95%E6%80%BB%E7%BB%93/>数学物理方法总结</a></li></ul></li></ul></div><div class=sidebar-module><h4 class=sidebar-heading>Tags</h4><div class=tag-box><a class=tag-item href=https://ole12138.gitee.io//tags/annotation>annotation</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/authorization>authorization</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/controller%E6%96%B9%E6%B3%95%E8%BF%94%E5%9B%9E%E5%80%BC>controller方法返回值</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/cookie-session%E7%99%BB%E5%BD%95>cookie-session登录</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/http>http</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/http1.1>http1.1</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/http2>http2</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/httpclient>httpclient</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/https>https</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/httpsurlconnection>httpsurlconnection</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/httpurlconnection>httpurlconnection</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/jar%E5%8C%85>jar包</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/java>java</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/java%E5%8F%91%E8%B5%B7http%E8%AF%B7%E6%B1%82>java发起http请求</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/java%E5%AE%9E%E7%8E%B0http%E8%AF%B7%E6%B1%82>java实现http请求</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/java%E6%9E%84%E5%BB%BA%E5%B7%A5%E5%85%B7>java构建工具</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/java%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F>java设计模式</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/jdk%E4%BB%A3%E7%90%86>jdk代理</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/jdk%E7%89%88%E6%9C%AC%E7%9A%84%E5%88%87%E6%8D%A2>jdk版本的切换</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/json%E7%9A%84%E4%BC%A0%E8%BE%93>json的传输</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/jsp%E6%95%B0%E6%8D%AE%E5%9B%9E%E6%98%BE>jsp数据回显</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/maven>maven</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/np%E5%AE%8C%E5%A4%87%E7%90%86%E8%AE%BA>np完备理论</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/n%E7%BB%B4%E6%AD%A3%E6%80%81%E5%88%86%E5%B8%83>n维正态分布</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/pat>pat</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/restfulwebservice>restfulwebservice</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/restful%E6%9E%B6%E6%9E%84>restful架构</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/resttemplate>resttemplate</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/servlet>servlet</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/spring>spring</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/spring-aop>spring-aop</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/springboot>springboot</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/springmvc>springmvc</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/springmvc%E5%88%9D%E5%A7%8B%E5%8C%96%E8%BF%87%E7%A8%8B>springmvc初始化过程</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/springmvc%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B>springmvc工作流程</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/springmvc%E6%B3%A8%E8%A7%A3>springmvc注解</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/springmvc%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90>springmvc源码分析</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/springmvc%E7%BB%84%E4%BB%B6>springmvc组件</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/springmvc%E8%AF%B7%E6%B1%82%E5%A4%84%E7%90%86%E8%BF%87%E7%A8%8B>springmvc请求处理过程</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/spring%E4%B8%AD%E6%96%87%E6%96%87%E6%A1%A3>spring中文文档</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/spring%E6%BA%90%E7%A0%81>spring源码</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/spring%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E7%9A%84xsd%E5%BC%95%E7%94%A8%E9%97%AE%E9%A2%98>spring配置文件的xsd引用问题</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/ssl>ssl</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/tls>tls</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E4%B8%80%E5%85%83%E5%BE%AE%E5%88%86%E5%AD%A6>一元微分学</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E4%B8%80%E5%85%83%E5%BE%AE%E7%A7%AF%E5%88%86>一元微积分</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E4%B8%80%E5%85%83%E7%A7%AF%E5%88%86%E5%AD%A6>一元积分学</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E4%B8%89%E8%A7%92%E5%87%BD%E6%95%B0>三角函数</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E4%B8%89%E8%A7%92%E7%BA%A7%E6%95%B0>三角级数</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E4%B8%8D%E5%AE%9A%E7%A7%AF%E5%88%86>不定积分</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E4%B8%AD%E5%BF%83%E6%9E%81%E9%99%90%E5%AE%9A%E7%90%86>中心极限定理</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E4%B9%A0%E9%A2%98>习题</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E4%BA%8C%E5%8F%89%E6%8E%92%E5%BA%8F%E6%A0%91>二叉排序树</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E4%BA%8C%E5%8F%89%E6%A0%91>二叉树</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E4%BA%8C%E5%8F%89%E6%A0%91%E7%9A%84%E9%81%8D%E5%8E%86>二叉树的遍历</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E4%BA%8C%E6%AC%A1%E5%9E%8B>二次型</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E4%BA%8C%E6%AC%A1%E5%9E%8B%E5%8C%96%E4%B8%BA%E6%A0%87%E5%87%86%E5%9E%8B>二次型化为标准型</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E4%BB%A3%E6%95%B0>代数</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E4%BB%A3%E6%95%B0%E5%BA%94%E7%94%A8>代数应用</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E4%BB%A3%E7%90%86%E6%A8%A1%E5%BC%8F>代理模式</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E4%BC%BD%E9%A9%AC%E5%87%BD%E6%95%B0>伽马函数</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E4%BE%9D%E8%B5%96%E7%AE%A1%E7%90%86>依赖管理</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E5%81%87%E8%AE%BE%E6%A3%80%E9%AA%8C>假设检验</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E5%82%85%E9%87%8C%E5%8F%B6%E5%8F%98%E6%8D%A2>傅里叶变换</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E5%82%85%E9%87%8C%E5%8F%B6%E7%BA%A7%E6%95%B0>傅里叶级数</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E5%85%8B%E6%8B%89%E9%BB%98%E6%B3%95%E5%88%99>克拉默法则</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E5%85%A8%E5%B1%80%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86>全局异常处理</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E5%85%B3%E9%97%AD%E8%B5%84%E6%BA%90>关闭资源</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E5%87%A0%E4%BD%95>几何</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E5%87%BD%E6%95%B0>函数</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E5%87%BD%E6%95%B0%E5%BC%8F%E7%BC%96%E7%A8%8B>函数式编程</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E5%87%BD%E6%95%B0%E6%9E%81%E9%99%90%E7%90%86%E8%AE%BA>函数极限理论</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E5%87%BD%E6%95%B0%E7%A9%BA%E9%97%B4>函数空间</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E5%87%BD%E6%95%B0%E9%A1%B9%E7%BA%A7%E6%95%B0>函数项级数</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E5%88%86%E5%9D%97%E7%9F%A9%E9%98%B5>分块矩阵</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E5%88%86%E5%B8%83%E7%B1%BB%E5%9E%8B%E7%9A%84%E5%81%87%E8%AE%BE>分布类型的假设</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E5%88%86%E7%B1%BB>分类</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E5%88%87%E6%AF%94%E9%9B%AA%E5%A4%AB%E4%B8%8D%E7%AD%89%E5%BC%8F>切比雪夫不等式</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E5%89%8D%E5%90%8E%E7%AB%AF%E5%88%86%E7%A6%BB>前后端分离</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92>动态规划</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92%E7%9A%84%E6%80%9D%E6%83%B3>动态规划的思想</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E5%8C%BA%E9%97%B4%E4%BC%B0%E8%AE%A1>区间估计</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E5%8D%8F%E6%96%B9%E5%B7%AE>协方差</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E5%8D%8F%E6%96%B9%E5%B7%AE%E7%9F%A9%E9%98%B5>协方差矩阵</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E5%8D%95%E8%B0%83%E6%80%A7>单调性</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1>参数估计</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E5%8F%82%E6%95%B0%E7%9A%84%E5%81%87%E8%AE%BE%E6%A3%80%E9%AA%8C>参数的假设检验</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E5%8F%82%E6%95%B0%E7%BB%91%E5%AE%9A>参数绑定</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E5%8F%8C%E7%AB%AF%E9%98%9F%E5%88%97>双端队列</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E5%8F%8D%E5%B0%84>反射</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E5%8F%8D%E5%B8%B8%E7%A7%AF%E5%88%86>反常积分</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E5%8F%AF%E5%AF%BC%E5%87%BD%E6%95%B0%E7%9A%84%E4%B8%AD%E5%80%BC%E5%AE%9A%E7%90%86>可导函数的中值定理</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E5%90%91%E9%87%8F>向量</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E5%90%91%E9%87%8F%E4%BB%A3%E6%95%B0>向量代数</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E5%90%91%E9%87%8F%E5%80%BC%E5%87%BD%E6%95%B0>向量值函数</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E5%90%91%E9%87%8F%E5%86%85%E7%A7%AF>向量内积</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E5%90%91%E9%87%8F%E5%88%86%E6%9E%90>向量分析</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E5%90%91%E9%87%8F%E7%9A%84%E6%AD%A3%E4%BA%A4%E6%80%A7>向量的正交性</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E5%90%91%E9%87%8F%E7%A9%BA%E9%97%B4>向量空间</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E5%90%91%E9%87%8F%E7%BB%84>向量组</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E5%90%91%E9%87%8F%E7%BB%84%E7%9A%84%E7%A7%A9>向量组的秩</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E5%90%91%E9%87%8F%E7%BB%84%E7%9A%84%E7%BA%BF%E6%80%A7%E7%9B%B8%E5%85%B3%E6%80%A7>向量组的线性相关性</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E5%90%91%E9%87%8F%E7%BB%84%E7%9A%84%E7%BA%BF%E6%80%A7%E7%BB%84%E5%90%88>向量组的线性组合</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E5%90%91%E9%87%8F%E9%95%BF%E5%BA%A6>向量长度</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E5%93%88%E5%A4%AB%E6%9B%BC%E6%A0%91>哈夫曼树</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E5%9B%9E%E5%BD%92%E5%88%86%E6%9E%90>回归分析</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E5%9B%BE>图</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E5%9B%BE%E7%9A%84%E9%81%8D%E5%8E%86>图的遍历</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E5%9C%A8%E5%8F%8D%E5%B0%84%E4%B8%AD%E4%BD%BF%E7%94%A8annotation>在反射中使用annotation</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E5%9D%87%E5%80%BC>均值</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E5%9F%BA%E7%A1%80%E6%95%B0%E5%AD%A6>基础数学</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E5%A4%8D%E6%95%B0%E9%A1%B9%E7%BA%A7%E6%95%B0>复数项级数</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E5%A4%9A%E5%85%83%E5%87%BD%E6%95%B0%E7%9A%84%E6%9E%81%E5%80%BC%E4%B8%8E%E6%9C%80%E5%80%BC>多元函数的极值与最值</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E5%A4%9A%E5%85%83%E5%BE%AE%E5%88%86%E5%AD%A6>多元微分学</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E5%A4%9A%E5%85%83%E5%BE%AE%E7%A7%AF%E5%88%86>多元微积分</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E5%A4%9A%E5%85%83%E7%A7%AF%E5%88%86%E5%AD%A6>多元积分学</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E5%A4%A7%E6%95%B0%E5%AE%9A%E5%BE%8B>大数定律</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E5%A7%94%E6%B4%BE%E6%A8%A1%E5%BC%8F>委派模式</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E5%AE%9A%E7%A7%AF%E5%88%86>定积分</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E5%AE%9A%E7%A7%AF%E5%88%86%E7%9A%84%E5%BA%94%E7%94%A8>定积分的应用</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E5%AF%B9%E7%A7%B0%E7%9F%A9%E9%98%B5%E5%AF%B9%E8%A7%92%E5%8C%96>对称矩阵对角化</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E5%AF%B9%E8%B1%A1%E9%80%82%E9%85%8D%E5%99%A8%E6%A8%A1%E5%BC%8F>对象适配器模式</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E5%AF%BC%E6%95%B0>导数</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E5%AF%BC%E6%95%B0%E7%9A%84%E5%BA%94%E7%94%A8>导数的应用</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E5%B8%B8%E6%95%B0%E9%A1%B9%E7%BA%A7%E6%95%B0>常数项级数</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E5%B9%82%E7%BA%A7%E6%95%B0>幂级数</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E5%B9%B3%E8%A1%A1%E4%BA%8C%E5%8F%89%E6%A0%91>平衡二叉树</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E5%B9%B6%E6%9F%A5%E9%9B%86>并查集</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E5%BC%A7%E5%BE%AE%E5%88%86>弧微分</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E5%BE%AE%E5%88%86>微分</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E5%BE%AE%E5%88%86%E6%96%B9%E7%A8%8B>微分方程</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E6%80%BB%E4%BD%93%E4%B8%8E%E4%B8%AA%E4%BD%93>总体与个体</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E6%8A%BD%E6%A0%B7%E5%88%86%E5%B8%83>抽样分布</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E6%8B%A6%E6%88%AA%E5%99%A8>拦截器</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E6%8E%92%E5%BA%8F>排序</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E6%95%A3%E5%88%97>散列</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E6%95%B0%E5%AD%A6>数学</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E6%95%B0%E5%AD%A6%E5%88%86%E6%94%AF>数学分支</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E6%95%B0%E5%AD%A6%E5%88%86%E6%9E%90>数学分析</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E6%95%B0%E5%AD%A6%E6%9C%9F%E6%9C%9B>数学期望</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5>数据结构的基本概念</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1>数理统计</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E6%95%B0%E7%BB%84>数组</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E6%95%B4%E6%95%B0%E4%BC%98%E5%8C%96>整数优化</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E6%96%87%E4%BB%B6%E4%B8%8A%E4%BC%A0>文件上传</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E6%96%B9%E5%B7%AE>方差</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E6%96%B9%E5%B7%AE%E5%88%86%E6%9E%90>方差分析</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E6%96%B9%E9%98%B5%E7%9A%84%E7%89%B9%E5%BE%81%E5%80%BC>方阵的特征值</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E6%96%B9%E9%98%B5%E7%9A%84%E7%89%B9%E5%BE%81%E5%90%91%E9%87%8F>方阵的特征向量</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E6%96%B9%E9%98%B5%E7%9A%84%E8%A1%8C%E5%88%97%E5%BC%8F>方阵的行列式</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E6%97%A0%E5%81%8F%E4%BC%B0%E8%AE%A1>无偏估计</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E6%98%A0%E5%B0%84>映射</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E6%9B%B2%E7%8E%87>曲率</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E6%9B%B2%E7%BA%BF%E7%A7%AF%E5%88%86>曲线积分</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E6%9B%B2%E9%9D%A2%E7%A7%AF%E5%88%86>曲面积分</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E6%9C%80%E4%BC%98%E5%8C%96%E9%97%AE%E9%A2%98>最优化问题</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E6%9C%80%E7%9F%AD%E8%B7%AF%E5%BE%84>最短路径</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E6%9C%89%E6%95%88%E4%BC%B0%E8%AE%A1>有效估计</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E6%9C%8D%E5%8A%A1%E7%AB%AF%E6%95%B0%E6%8D%AE%E6%A0%A1%E9%AA%8C>服务端数据校验</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E6%9E%81%E5%80%BC>极值</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E6%9E%81%E9%99%90>极限</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E6%A0%87%E5%87%86%E5%9E%8B>标准型</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E6%A0%88>栈</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E6%A0%91>树</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E6%A0%91%E7%8A%B6%E6%95%B0%E7%BB%84>树状数组</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E6%A0%91%E7%9A%84%E9%81%8D%E5%8E%86>树的遍历</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E6%A0%B7%E6%9C%AC>样本</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E6%A3%AE%E6%9E%97%E4%B8%8E%E4%BA%8C%E5%8F%89%E6%A0%91%E7%9A%84%E8%BD%AC%E6%8D%A2>森林与二叉树的转换</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E6%A6%82%E5%BF%B5%E4%B8%8E%E6%80%A7%E8%B4%A8>概念与性质</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E6%A6%82%E7%8E%87%E8%AE%BA>概率论</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1>概率论与数理统计</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E6%A6%82%E8%BF%B0>概述</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E6%AD%A3%E5%AE%9A%E7%9F%A9%E9%98%B5>正定矩阵</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E6%B3%8A%E6%9D%BE%E7%A7%AF%E5%88%86>泊松积分</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E6%B3%8A%E6%9D%BE%E7%A7%AF%E5%88%86%E7%9A%84%E6%A6%82%E7%8E%87%E8%AE%BA%E5%BA%94%E7%94%A8>泊松积分的概率论应用</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E7%82%B9%E4%BC%B0%E8%AE%A1>点估计</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E7%89%A9%E7%90%86>物理</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E7%89%B9%E5%BE%81%E5%87%BD%E6%95%B0>特征函数</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E7%99%BB%E5%BD%95%E8%AE%A4%E8%AF%81>登录认证</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E7%9B%B8%E4%BC%BC%E5%AF%B9%E8%A7%92%E5%8C%96>相似对角化</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E7%9B%B8%E4%BC%BC%E7%9F%A9%E9%98%B5>相似矩阵</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E7%9B%B8%E5%85%B3%E7%B3%BB%E6%95%B0>相关系数</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E7%9F%A9>矩</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E7%9F%A9%E9%98%B5>矩阵</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E7%9F%A9%E9%98%B5%E5%90%88%E5%90%8C>矩阵合同</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E7%9F%A9%E9%98%B5%E6%B1%82%E9%80%86>矩阵求逆</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E7%9F%A9%E9%98%B5%E7%9A%84%E5%88%9D%E7%AD%89%E5%8F%98%E6%8D%A2>矩阵的初等变换</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E7%9F%A9%E9%98%B5%E7%9A%84%E5%8E%8B%E7%BC%A9%E5%AD%98%E5%82%A8>矩阵的压缩存储</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E7%9F%A9%E9%98%B5%E7%9A%84%E7%A7%A9>矩阵的秩</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E7%9F%A9%E9%98%B5%E7%9A%84%E8%BF%90%E7%AE%97>矩阵的运算</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E7%A6%BB%E6%95%A3%E6%9C%80%E4%BC%98%E5%8C%96>离散最优化</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E7%A9%BA%E9%97%B4>空间</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E7%A9%BA%E9%97%B4%E8%A7%A3%E6%9E%90%E5%87%A0%E4%BD%95>空间解析几何</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E7%AE%80%E5%8D%95%E7%99%BB%E5%BD%95%E9%AA%8C%E8%AF%81>简单登录验证</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E7%AE%97%E6%B3%95%E5%88%86%E7%B1%BB>算法分类</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E7%AE%97%E6%B3%95%E6%80%9D%E6%83%B3>算法思想</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E7%AE%97%E6%B3%95%E8%AF%84%E4%BB%B7%E6%96%B9%E6%B3%95>算法评价方法</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E7%B1%BB%E9%80%82%E9%85%8D%E5%99%A8%E6%A8%A1%E5%BC%8F>类适配器模式</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E7%B3%BB%E7%BB%9F%E8%AF%AF%E5%B7%AE>系统误差</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E7%BA%A7%E6%95%B0>级数</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0>线性代数</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E7%BA%BF%E6%80%A7%E6%96%B9%E7%A8%8B%E7%BB%84>线性方程组</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E7%BA%BF%E6%80%A7%E6%96%B9%E7%A8%8B%E7%BB%84%E7%9A%84%E8%A7%A3>线性方程组的解</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E7%BA%BF%E6%80%A7%E6%96%B9%E7%A8%8B%E7%BB%84%E8%A7%A3%E7%9A%84%E7%BB%93%E6%9E%84>线性方程组解的结构</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E7%BA%BF%E6%80%A7%E8%A1%A8>线性表</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E7%BA%BF%E6%80%A7%E8%A1%A8%E7%9A%84%E9%93%BE%E5%BC%8F%E8%A1%A8%E7%A4%BA>线性表的链式表示</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E7%BA%BF%E6%80%A7%E8%A1%A8%E7%9A%84%E9%A1%BA%E5%BA%8F%E8%A1%A8%E7%A4%BA>线性表的顺序表示</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E7%BA%BF%E7%B4%A2%E4%BA%8C%E5%8F%89%E6%A0%91>线索二叉树</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E7%BB%84%E5%90%88%E4%BC%98%E5%8C%96>组合优化</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E7%BB%9F%E8%AE%A1%E6%8E%A8%E6%96%AD>统计推断</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E7%BB%9F%E8%AE%A1%E9%87%8F>统计量</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E7%BC%BA%E7%9C%81%E9%80%82%E9%85%8D%E5%99%A8%E6%A8%A1%E5%BC%8F>缺省适配器模式</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E7%BD%AE%E4%BF%A1%E5%8C%BA%E9%97%B4>置信区间</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E7%BD%AE%E4%BF%A1%E5%BA%A6>置信度</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E8%84%89%E7%BB%9C>脉络</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E8%A1%8C%E5%88%97%E5%BC%8F>行列式</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E8%A1%8C%E5%88%97%E5%BC%8F%E5%B1%95%E5%BC%80%E5%85%AC%E5%BC%8F>行列式展开公式</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E8%A1%8C%E5%88%97%E5%BC%8F%E8%A7%A3%E6%96%B9%E7%A8%8B%E7%BB%84%E5%BA%94%E7%94%A8>行列式解方程组应用</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E8%A7%82%E5%AF%9F%E8%80%85%E6%A8%A1%E5%BC%8F>观察者模式</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E8%BA%AB%E4%BB%BD%E8%AE%A4%E8%AF%81>身份认证</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E8%BE%A8%E6%9E%90>辨析</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E8%BF%9E%E7%BB%AD%E6%80%A7>连续性</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E9%80%92%E5%BD%92%E4%B8%8E%E9%9D%9E%E9%80%92%E5%BD%92%E8%BD%AC%E6%8D%A2>递归与非递归转换</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E9%80%92%E5%BD%92%E5%BE%AA%E7%8E%AF%E8%BF%AD%E4%BB%A3%E9%81%8D%E5%8E%86>递归循环迭代遍历</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E9%80%92%E5%BD%92%E7%9A%84%E6%80%9D%E6%83%B3>递归的思想</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E9%87%8D%E7%A7%AF%E5%88%86>重积分</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E9%98%9F%E5%88%97>队列</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E9%9A%8F%E6%9C%BA%E4%BA%8B%E4%BB%B6>随机事件</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E9%9A%8F%E6%9C%BA%E4%BA%8B%E4%BB%B6%E7%9A%84%E6%A6%82%E7%8E%87>随机事件的概率</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F>随机变量</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E7%9A%84%E5%88%86%E5%B8%83>随机变量的分布</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E7%9A%84%E6%95%B0%E5%AD%97%E7%89%B9%E5%BE%81>随机变量的数字特征</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E9%9D%99%E6%80%81%E4%BB%A3%E7%90%86>静态代理</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E9%9D%99%E6%80%81%E8%B5%84%E6%BA%90%E8%AE%BF%E9%97%AE>静态资源访问</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E9%AB%98%E6%96%AF%E7%A7%AF%E5%88%86>高斯积分</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E9%AB%98%E7%AD%89%E6%95%B0%E5%AD%A6>高等数学</a></div></div></div></div></div><style>code.has-jax{font:inherit;font-size:100%;background:inherit;border:inherit;color:#515151}</style><script>MathJax={tex:{inlineMath:[['$','$'],['\\(','\\)']],displayMath:[['$$','$$'],['\\[','\\]']],processEscapes:!0,processEnvironments:!0},options:{skipHtmlTags:['script','noscript','style','textarea','pre']}},window.addEventListener('load',a=>{document.querySelectorAll("mjx-container").forEach(function(a){a.parentElement.classList+=' has-jax'})})</script><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script><script type=text/javascript id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script><hr><div class=row><div class=col-sm-8><p class=doc-footer-em><a href=# onclick=resetSidebarPos()>Back to TOP</a></p></div></div></div><footer class=doc-footer><p class=doc-footer-em>Browse <strong><a href=https://github.com/ole12138/ole12138.github.io>Repository</a></strong></p><p>Copyright (c) 2020, Jingmin; All rights reserved.</p><p>Powered by <strong><a href=https://github.com/progrhyme/hugo-theme-bootie-docs>Bootie Docs</a></strong> - theme for <a href=http://gohugo.io/>Hugo</a> by <a href=https://github.com/progrhyme/>progrhyme</a>.</p></footer><script src=https://ole12138.gitee.io//js/jquery.min.js></script><script src=https://ole12138.gitee.io//js/bootstrap.min.js></script><script src=https://ole12138.gitee.io//js/highlight.pack.js></script><script>hljs.initHighlightingOnLoad()</script><script src=https://ole12138.gitee.io//js/ie10-viewport-bug-workaround.js></script><script src=https://ole12138.gitee.io//js/bootie-docs.js></script></body></html>