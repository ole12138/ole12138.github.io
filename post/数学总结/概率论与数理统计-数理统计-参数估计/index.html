<!doctype html><html lang=en><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><link rel=alternate href=/index.xml type=application/rss+xml title="Jingmin's blog"><link rel=icon href=https://ole12138.gitee.io//favicon.ico><title>概率论与数理统计-数理统计-参数估计 - Jingmin's blog</title><link rel=stylesheet href=https://ole12138.gitee.io//css/highlight/github.css><link rel=stylesheet href=https://ole12138.gitee.io//css/bootstrap.min.css><link rel=stylesheet href=https://ole12138.gitee.io//css/bootstrap-theme.min.css><link rel=stylesheet href=https://ole12138.gitee.io//css/theme.css><link rel=stylesheet href=https://ole12138.gitee.io//css/bootie-docs.css><link rel=stylesheet href=https://ole12138.gitee.io//css/site.css></head><body role=document><nav class="navbar navbar-inverse navbar-fixed-top"><div class=container><div class=navbar-header><button type=button class="navbar-toggle collapsed" data-toggle=collapse data-target=#navbar aria-expanded=false aria-controls=navbar>
<span class=sr-only>Toggle navigation</span>
<span class=icon-bar></span><span class=icon-bar></span><span class=icon-bar></span></button>
<a class=navbar-brand href=https://ole12138.gitee.io//>Jingmin's blog</a></div><div id=navbar class="navbar-collapse collapse"><ul class="nav navbar-nav"><li><a href=https://ole12138.gitee.io//>Home</a></li><li><a href=/post>All posts</a></li><li><a href=/tags>Tags</a></li><li><a href=/series>Series</a></li><li><a href=/categories>Categories</a></li><li><a href=/about>About</a></li></ul></div></div></nav><div class=container><div class=row><div class="col-sm-8 doc-main"><main role=main><article><a id=title></a><h1 class=doc-entry-title>概率论与数理统计-数理统计-参数估计</h1><div class=doc-entry-meta><span><time datetime=2020-12-17>December 17, 2020</time></span></div><section><h1 id=概率论与数理统计-数理统计-参数估计>概率论与数理统计-数理统计-参数估计</h1><p>统计推断的基本问题可以分为两大类，一类是<strong>估计问题</strong>，另一类是<strong>假设检验问题</strong>。本章讨论总体参数的点估计和区间估计.</p><h2 id=点估计>点估计</h2><p>设总体X的分布函数的形式已知，但它的一个或多个参数未知，借助于总体X的一个样本来估计总体未知参数的值的问题称为参数的<strong>点估计问题</strong></p><p><strong>点估计问题的一般提法</strong>如下: 设总体 <span class="math inline">\(X\)</span> 的分布函数 <span class="math inline">\(F(x ; \theta)\)</span> 的形式为已知, $ $ 是待估参数. <span class="math inline">\(X_{1}, X_{2}, \cdots, X_{n}\)</span> 是 <span class="math inline">\(X\)</span> 的一个样本 <span class="math inline">\(, x_{1}, x_{2}, \cdots, x_{n}\)</span> 是相应的一个样本值. 点估计间题就是要构造一个适当的统计量 <span class="math inline">\(\hat{\theta}\left(X_{1}, X_{2}, \cdots, X_{n}\right),\)</span> 用它的观察值 <span class="math inline">\(\hat{\theta}\left(x_{1}, x_{2}, \cdots, x_{n}\right)\)</span> 作为未知参数 <span class="math inline">\(\theta\)</span> 的近似值. 我们称 <span class="math inline">\(\hat{\theta}\left(X_{1}, X_{2}, \cdots, X_{n}\right)\)</span> 为 <span class="math inline">\(\theta\)</span> 的估计量,称 <span class="math inline">\(\hat{\theta}\left(x_{1}, x_{2}, \cdots, x_{n}\right)\)</span> 为 <span class="math inline">\(\theta\)</span> 的估计值. 在不致混淆的情况下统称估计量和估计值为估计。</p><p>注意：由于估计量是样本的函数. 因此对于不同的样本值， <span class="math inline">\(\theta\)</span> 的估计值一般是不相同的.</p><h3 id=矩估计法>矩估计法</h3><p>设 <span class="math inline">\(X\)</span> 为连续型随机变量,其概率密度为 <span class="math inline">\(f\left(x ; \theta_{1}, \theta_{2}, \cdots, \theta_{k}\right),\)</span> 或 <span class="math inline">\(X\)</span> 为离散型随机变量,其分布律为 <span class="math inline">\(P\{X=x\}=p\left(x ; \theta_{1}, \theta_{2}, \cdots, \theta_{k}\right),\)</span> 其中 <span class="math inline">\(\theta_{1}, \theta_{2}, \cdots, \theta_{k}\)</span> 为待估参数 <span class="math inline">\(, X_{1}, X_{2}, \cdots, X_{n}\)</span> 是来自 <span class="math inline">\(X\)</span> 的样本. 假设总体 <span class="math inline">\(X\)</span> 的前 <span class="math inline">\(k\)</span> 阶矩（<span class="math inline">\(l=1,2, \cdots, k\)</span>）： <span class="math display">\[
\mu_{l}=E\left(X^{l}\right)=\int_{-\infty}^{\infty} x^{l} f\left(x ; \theta_{1}, \theta_{2}, \cdots, \theta_{k}\right) \mathrm{d} x \quad(X \text { 连续型 })
\]</span> 或者： <span class="math display">\[
\mu_{l}=E\left(X^{l}\right)=\sum_{x \in R_{X}} x^{\prime} p\left(x ; \theta_{1}, \theta_{2}, \cdots, \theta_{k}\right) \quad(X \text { 离散型 })
\]</span> （其中 <span class="math inline">\(R_{X}\)</span> 是 <span class="math inline">\(X\)</span> 可能取值的范围） 一般来说,它们(总体 <span class="math inline">\(X\)</span> 的前 <span class="math inline">\(k\)</span> 阶矩)是 <span class="math inline">\(\theta_{1}, \theta_{2}, \cdots, \theta_{k}\)</span> 的函数.</p><p>对于<span class="math inline">\((l=1,2, \cdots, k)\)</span>,<a href=../概率论与数理统计-数理统计-基本概念/#样本矩与统计量的性质>样本矩<span class="math inline">\(A_{l}=\frac{1}{n} \sum_{i=1}^{n} X_{i}^{l}\)</span>依概率收敛于相应的总体矩<span class="math inline">\(\mu_{l}\)</span>, 样本矩的连续函数依概率收敛于相应的总体矩的连续函数</a>。</p><p>这样我们就用样本矩作为相应总体矩的估计量，而以样本矩的连续函数作为相应的总体矩的连续函数的估计量。这种估计方法称为<strong>矩估计法</strong>。</p><p>矩估计法的具体做法： 设总体的各阶矩（总体分布已知的情况下，各阶矩显然是参数的函数）： <span class="math inline">\(\left\{\begin{aligned} \mu_{1} &=\mu_{1}\left(\theta_{1}, \theta_{2}, \cdots, \theta_{k}\right) \\ \mu_{2} &=\mu_{2}\left(\theta_{1}, \theta_{2}, \cdots, \theta_{k}\right) \\ & \vdots \\ \mu_{k} &=\mu_{k}\left(\theta_{1}, \theta_{2}, \cdots, \theta_{k}\right) \end{aligned}\right.\)</span> 这是一个包含 <span class="math inline">\(k\)</span> 个未知参数 <span class="math inline">\(\theta_{1}, \theta_{2}, \cdots, \theta_{k}\)</span> 的联立方程组.一般来说,可以从中解 出 <span class="math inline">\(\theta_{1}, \theta_{2}, \cdots, \theta_{k},\)</span> 得到： <span class="math inline">\(\left\{\begin{aligned} \theta_{1} &=\theta_{1}\left(\mu_{1}, \mu_{2}, \cdots, \mu_{k}\right) \\ \theta_{2} &=\theta_{2}\left(\mu_{1}, \mu_{2}, \cdots, \mu_{k}\right) \\ & \vdots \\ \theta_{k} &=\theta_{k}\left(\mu_{1}, \mu_{2}, \cdots, \mu_{k}\right) \end{aligned}\right.\)</span> 然后以样本的各阶矩<span class="math inline">\(A_{i}\)</span>替换上面总体的各阶矩<span class="math inline">\(\mu_i\)</span>, 即将<span class="math inline">\(\hat{\theta}_{i}=\theta_{i}\left(A_{1}, A_{2}, \cdots, A_{k}\right), i=1,2, \cdots, k\)</span>作为<span class="math inline">\(\theta_{i}, i=1,2, \cdots, k\)</span> 的估计量,这种估计量称为<strong>矩估计量</strong>。矩估计量的观察值称为<strong>矩估计值</strong>。</p><blockquote><p>例子： 设总体 <span class="math inline">\(X\)</span> 在 <span class="math inline">\([a, b]\)</span> 上服从均匀分布 <span class="math inline">\(, a, b\)</span> 未知 <span class="math inline">\(. X_{1}, X_{2}, \cdots, X_{n}\)</span> 是来自<span class="math inline">\(X\)</span> 的样本,试求 <span class="math inline">\(a, b\)</span> 的矩估计量. <span class="math inline">\(\begin{aligned} \mu_{1} &=E(X)=(a+b) / 2 \\ \mu_{2} &=E\left(X^{2}\right)=D(X)+[E(X)]^{2} \\ &=(b-a)^{2} / 12+(a+b)^{2} / 4 \end{aligned}\)</span> <span class="math inline">\(\left\{\begin{array}{l}a+b=2 \mu_{1} \\ b-a=\sqrt{12\left(\mu_{2}-\mu_{1}^{2}\right)}\end{array}\right.\)</span> 解得<span class="math inline">\(a=\mu_{1}-\sqrt{3\left(\mu_{2}-\mu_{1}^{2}\right)}, \quad b=\mu_{1}+\sqrt{3\left(\mu_{2}-\mu_{1}^{2}\right)}\)</span> 然后以<span class="math inline">\(A_{1}, A_{2}\)</span> 代替 <span class="math inline">\(\mu_{1}, \mu_{2},\)</span> 得到 <span class="math inline">\(a, b\)</span> 的矩估计量： <span class="math inline">\(\hat{a}=A_{1}-\sqrt{3\left(A_{2}-A_{1}^{2}\right)}=\bar{X}-\sqrt{\frac{3}{n} \sum_{i=1}^{n}\left(X_{i}-\bar{X}\right)^{2}}\)</span> <span class="math inline">\(\hat{b}=A_{1}+\sqrt{3\left(A_{2}-A_{1}^{2}\right)}=\bar{X}+\sqrt{\frac{3}{n} \sum_{i=1}^{n}\left(X_{i}-\bar{X}\right)^{2}}\)</span> （注意到<span class="math inline">\(\frac{1}{n} \sum_{i=1}^{n} X_{i}^{2}-\bar{X}^{2}=\)</span><span class="math inline">\(\frac{1}{n} \sum_{i=1}^{n}\left(X_{i}-\bar{X}\right)^{2}\)</span>）</p></blockquote><h3 id=极大似然估计法>极大似然估计法</h3><p>极大似然估计法是英国统计学家费希尔(R.A.Fisher)于1922年提出的。它是建立在极大似然原理的基础上的一种估计方法。</p><h4 id=极大似然原理>极大似然原理</h4><p><strong>极大似然原理</strong>是人们从长期的生活实践中提炼出来的，其内容可以简单叙述为： 若一个随机试验由若干可能结果：<span class="math inline">\(A_1,A_2,\cdots\)</span>,如果在<strong>一次试验中，结果<span class="math inline">\(A_1\)</span>发生了，那么就说明试验的条件对事件<span class="math inline">\(A_1\)</span>最有利，即认为事件<span class="math inline">\(A_1\)</span>发生的概率最大</strong>。 比如两个箱子：甲箱放了99白球和1黑球，乙箱子放了99黑球和1白球，从两箱子任选一箱子，取出一球， 结果取到了黑球，就认为当前情况下很可能取到黑球的概率最大（对取到黑球最有利），即最有可能是从乙箱子取出的，这也是“极大似然”之意。</p><h4 id=似然函数>似然函数</h4><p>我们从极大似然原理出发，对离散型和连续型总体量汇总情形来阐述极大似然法的具体实现途径。为此我们先介绍似然函数的概念。</p><p><strong>若总体 <span class="math inline">\(X\)</span> 属离散型</strong>,其分布律 <span class="math inline">\(P\{X=x\}=p(x ; \theta), \theta \in \Theta\)</span> 的形式为已知, <span class="math inline">\(\theta\)</span>为待估参数, <span class="math inline">\(\Theta\)</span> 是 <span class="math inline">\(\theta\)</span> 可能取值的范围. 设 <span class="math inline">\(X_{1}, X_{2}, \cdots, X_{n}\)</span> 是来自 <span class="math inline">\(X\)</span> 的样本,则 <span class="math inline">\(X_{1}\)</span>,<span class="math inline">\(X_{2}, \cdots, X_{n}\)</span> 的联合分布律为<span class="math inline">\(\prod_{i=1}^{n} p\left(x_{i} ; \theta\right)\)</span>， 又设 <span class="math inline">\(x_{1}, x_{2}, \cdots, x_{n}\)</span> 是相应于样本 <span class="math inline">\(X_{1}, X_{2}, \cdots, X_{n}\)</span> 的一个样本值. 易知样本 <span class="math inline">\(X_{1},X_{2}, \cdots, X_{n}\)</span> 取到观察值 <span class="math inline">\(x_{1}, x_{2}, \cdots, x_{n}\)</span> 的<strong>概率</strong>（即事件 <span class="math inline">\(\left\{X_{1}=x_{1}, X_{2}=x_{2}, \cdots, X_{n}\right.\)</span> <span class="math inline">\(\left.=x_{n}\right\}\)</span> 发生的概率）为： <span class="math inline">\(L(\theta)=L\left(x_{1}, x_{2}, \cdots, x_{n} ; \theta\right)=\prod_{i=1}^{n} p\left(x_{i} ; \theta\right), \theta \in \Theta\)</span>，<span class="math inline">\(L(\theta)\)</span> ， 称为<strong>样本的似然函数</strong>。</p><p>注意：这里的<span class="math inline">\(x_{1}, x_{2}, \cdots, x_{n}\)</span> 是已知的样本值，它们都是常数。</p><p><strong>若总体 <span class="math inline">\(X\)</span> 属连续型</strong>,其概率密度 <span class="math inline">\(f(x ; \theta), \theta \in \Theta\)</span> 的形式已知, <span class="math inline">\(\theta\)</span> 为待估参数，<span class="math inline">\(\Theta\)</span> 是 <span class="math inline">\(\theta\)</span> 可能取值的范围. 设 <span class="math inline">\(X_{1}, X_{2}, \cdots, X_{n}\)</span> 是来自 <span class="math inline">\(X\)</span> 的样本,则 <span class="math inline">\(X_{1}, X_{2}, \cdots, X_{n}\)</span> 的联合密度为<span class="math inline">\(\prod_{i=1}^{n} f\left(x_{i}, \theta\right)\)</span>， 又设 <span class="math inline">\(x_{1}, x_{2}, \cdots, x_{n}\)</span> 是相应于样本 <span class="math inline">\(X_{1}, X_{2}, \cdots, X_{n}\)</span> 的一个样本值. 则随机点<span class="math inline">\((X_{1}, X_{2}, \cdots, X_{n})\)</span> 落在点 <span class="math inline">\(\left(x_{1}, x_{2}, \cdots, x_{n}\right)\)</span> 的邻域 <span class="math inline">\(\left(\right.\)</span> 边长分别为 <span class="math inline">\(\mathrm{d} x_{1}, \mathrm{~d} x_{2}, \cdots, \mathrm{d} x_{n}\)</span> 的 <span class="math inline">\(n\)</span> 维立方体内的概率近似为<span class="math inline">\(\prod_{i=1}^{n} f\left(x_{i} ; \theta\right) \mathrm{d} x_{i}\)</span>， 又因为因子 <span class="math inline">\(\prod_{i=1}^{n} \mathrm{~d} x_{i}\)</span> 不随 <span class="math inline">\(\theta\)</span> 而变,故将联合密度函数： <span class="math inline">\(L(\theta)=L\left(x_{1}, x_{2}, \cdots, x_{n} ; \theta\right)=\prod_{i=1}^{n} f\left(x_{i} ; \theta\right)\)</span>， 称为<strong>样本的似然函数</strong>。</p><h4 id=参数theta的极大似然估计>参数<span class="math inline">\(\theta\)</span>的极大似然估计</h4><p>关于最大似然估计原理,我们有直观想法: 现在已经取到样本值 <span class="math inline">\(x_{1}\)</span> ，<span class="math inline">\(x_{2}, \cdots, x_{n}\)</span> 了,这表明取到这一样本值的概率 <span class="math inline">\(L(\theta(x_{1}, x_{2}, \cdots, x_{n}))\)</span> 比较大。也即在$ <span class="math inline">\(的范围内，找到一个\)</span><span class="math inline">\(，使取得样本值\)</span>x_{1}, x_{2}, , x_{n}<span class="math inline">\(的概率\)</span>L()$最大。</p><p>设<span class="math inline">\(L(\theta) = L\left(x_{1}, x_{2}, \cdots, x_{n} ; \theta\right)\)</span>为似然函数，若存在<span class="math inline">\(\hat{\theta}\left(x_{1}, x_{2}, \cdots, x_{n}\right)\)</span>，使得<span class="math inline">\(L(\hat{\theta})=\max _{\theta \in \Theta} L(\theta)\)</span>，则称<span class="math inline">\(\hat{\theta}\left(x_{1}, x_{2}, \cdots, x_{n}\right)\)</span>为未知<strong>参数<span class="math inline">\(\theta\)</span>的极大似然估计值</strong>，<span class="math inline">\(\hat{\theta}\left(X_{1}, X_{2}, \cdots, X_{n}\right)\)</span>为未知<strong>参数<span class="math inline">\(\theta\)</span>的极大似然估计值</strong>。</p><p>这样，<strong>确定最大似然估计量的问题就归结为微分学中的求最大值的问题</strong>了。</p><h5 id=若似然函数可微>若似然函数可微</h5><p>在很多情形下 <span class="math inline">\(, p(x ; \theta)\)</span> 和 <span class="math inline">\(f(x ; \theta)\)</span> 关于 <span class="math inline">\(\theta\)</span> <strong>可微</strong>, 这时 <span class="math inline">\(\hat{\theta}\)</span> 常可从方程<span class="math inline">\(\frac{\mathrm{d}}{\mathrm{d} \theta} L(\theta)=0\)</span>解得，该方程也称<strong>似然方程</strong>。 又因 <span class="math inline">\(L(\theta)\)</span> 与 <span class="math inline">\(\ln L(\theta)\)</span> 在同一 <span class="math inline">\(\theta\)</span> 处取到极值，因此 <span class="math inline">\(, \theta\)</span> 的最大似然估计 <span class="math inline">\(\theta\)</span> 也可从方程<span class="math inline">\(\frac{\mathrm{d}}{\mathrm{d} \theta} \ln L(\theta)=0\)</span>，该方程称为<strong>对数似然方程</strong>。 函数取对数可以将连乘化为加法，后一方程求解往往比较方便。</p><blockquote><p>例子： 设 <span class="math inline">\(X \sim b(1, p) . X_{1}, X_{2}, \cdots, X_{n}\)</span> 是来自 <span class="math inline">\(X\)</span> 的一个样本,试求参数 <span class="math inline">\(p\)</span> 的极大似然估计量。 设 <span class="math inline">\(x_{1}, x_{2}, \cdots, x_{n}\)</span> 是相应于样本 <span class="math inline">\(X_{1}, X_{2}, \cdots, X_{n}\)</span> 的一个样本值. <span class="math inline">\(X\)</span> 的分布律为<span class="math inline">\(P\{X=x\}=p^{x}(1-p)^{1-x}, \quad x=0,1\)</span>。 故似然函数为<span class="math inline">\(L(p)=\prod_{i=1}^{n} p^{x_{i}}(1-p)^{1-x_{i}}=p^{\sum_{i=1}^{n} x_{i}}(1-p)^{n-\sum_{i=1}^{n} x_{i}}\)</span> 对数似然函数为<span class="math inline">\(\ln L(p)=\left(\sum_{i=1}^{n} x_{i}\right) \ln p+\left(n-\sum_{i=1}^{n} x_{i}\right) \ln (1-p)\)</span> 令<span class="math inline">\(\frac{\mathrm{d}}{\mathrm{d} p} \ln L(p)=\frac{\sum_{i=1}^{n} x_{i}}{p}-\frac{n-\sum_{i=1}^{n} x_{i}}{1-p}=0\)</span> 解得p的极大似然估计值<span class="math inline">\(\hat{p}=\frac{1}{n} \sum_{i=1}^{n} x_{i}=\bar{x}\)</span>， p的极大似然估计量为<span class="math inline">\(\hat{p}=\frac{1}{n} \sum_{i=1}^{n} X_{i}=\bar{X}\)</span></p></blockquote><h5 id=若似然函数不可微>若似然函数不可微</h5><p>除了一些简单的情况外,似然方程往往没有有限函数形式的解,这就需要用<strong>数值方法求近似解</strong> .常用算法是<a href=https://zh.wikipedia.org/wiki/%E7%89%9B%E9%A1%BF%E6%B3%95>牛顿一拉弗森（Newton-Raphson）算法</a>。</p><h4 id=多个参数的情况>多个参数的情况</h4><h5 id=若似然函数可微-1>若似然函数可微</h5><p>最大似然估计法也适用于分布中含多个未知参数 <span class="math inline">\(\theta_{1}, \theta_{2}, \cdots, \theta_{k}\)</span> 的情况. 这时,似然函数 <span class="math inline">\(L\)</span> 是这些未知参数的函数. 分别令：<span class="math inline">\(\frac{\partial}{\partial \theta_{i}} L=0, i=1,2, \cdots, k\)</span> 或者令：<span class="math inline">\(\frac{\partial}{\partial \theta_{i}} \ln L=0, i=1,2, \cdots, k\)</span> 解上述由 <span class="math inline">\(k\)</span> 个方程组成的方程组,即可得到各未知参数 <span class="math inline">\(\theta_{i}(i=1,2, \cdots, k)\)</span> 的最大似然估计值<span class="math inline">\(\hat{\theta}_{i}\)</span>。</p><h5 id=若似然函数不可微-1>若似然函数不可微</h5><p>似然方程组没有有限函数形式的解,这就需要用<strong>数值方法求近似解</strong> .常用拟牛顿法等最优化方法。</p><p>进一步阅读：https://kangcai.github.io/2018/12/17/ml-overall-9-algorithm-QNM/ 进一步阅读：最优化问题总结</p><h4 id=基于截尾样本的最大似然估计>基于截尾样本的最大似然估计</h4><p>在研究产品的可靠性时，需要研究产品寿命T的各种特征。产品寿命T是一个随机变量，它的分布称为寿命分布，为了对寿命分布进行统计推断，就需要通过产品的寿命试验，以取得寿命数据。 一种典型的寿命试验是,将随机抽取的 <span class="math inline">\(n\)</span> 个产品在时间 <span class="math inline">\(t=0\)</span> 时,同时投入试验,直到每个产品都失效。记录每一个产品的失效时间，这样得到的样本 (即 由所有产品的失效时间 <span class="math inline">\(0 \leqslant t_{1} \leqslant t_{2} \leqslant \cdots \leqslant t_{n}\)</span> 所组成的样本) 叫<strong>完全样本</strong>。 然而产品的寿命往往较长,由于时间和财力的限制，我们不可能得到完全样本,于是就考虑<strong>截尾寿命试验</strong>。截尾寿命试验常用的有两种 : 一种是<strong>定时截尾寿命试验</strong>。假设将随机抽取的 <span class="math inline">\(n\)</span> 个产品在时间 <span class="math inline">\(t=0\)</span> 时同时投入试验,试验进行到事先规定的截尾时间 <span class="math inline">\(t_{0}\)</span> 停止。如试验截止时共有 <span class="math inline">\(m\)</span> 个产品失效,它们的失效时间分别为<span class="math inline">\(0 \leqslant t_{1} \leqslant t_{2} \leqslant \cdots \leqslant t_{m} \leqslant t_{0}\)</span>，此时 <span class="math inline">\(m\)</span> 是一个随机变量,所得的样本 <span class="math inline">\(t_{1}, t_{2}, \cdots, t_{m}\)</span> 称为<strong>定时截尾样本</strong> 。 另一种是<strong>定数截尾寿命试验</strong>。假设将随机抽取的 <span class="math inline">\(n\)</span> 个产品在 <span class="math inline">\(t=0\)</span> 时同时投入试验。试验进行到有 <span class="math inline">\(m\)</span> 个 <span class="math inline">\((m\)</span> 是事先规定的 <span class="math inline">\(, m&lt;n)\)</span> 产品失效时停止， <span class="math inline">\(m\)</span> 个失效产品的失效时间分别为<span class="math inline">\(0 \leqslant t_{1} \leqslant t_{2} \leqslant \cdots \leqslant t_{m}\)</span>，这里 <span class="math inline">\(t_{m}\)</span> 是第 <span class="math inline">\(m\)</span> 个产品的失效时间 <span class="math inline">\(, t_{m}\)</span> 是随机变量。所得的样本 <span class="math inline">\(t_{1}, t_{2}, \cdots, t_{m}\)</span> 称为<strong>定数截尾样本</strong>。</p><p>用截尾样本来进行统计推断是可靠性研究中常见的问题 .</p><p><strong>设产品的寿命服从指数分布</strong>， 其概率密度为<span class="math inline">\(f(t)=\left\{\begin{array}{l}\frac{1}{\theta} \mathrm{e}^{-t / \theta}, t>0 \\ 0, \quad t \leqslant 0\end{array}\right.\)</span> <span class="math inline">\(\theta>0\)</span> 未知 <span class="math inline">\(.\)</span> 设有 <span class="math inline">\(n\)</span> 个产品投入<strong>定数截尾试验</strong>,截尾数为 <span class="math inline">\(m,\)</span> 得<strong>定数截尾样本</strong> <span class="math inline">\(0 \leqslant t_{1} \leqslant t_{2} \leqslant \cdots \leqslant t_{m},\)</span> 现在要利用这一样本来估计未知参数 <span class="math inline">\(\theta\)</span> (即产品的平均寿命). 在时间区间 <span class="math inline">\(\left[0, t_{m}\right]\)</span> 有 <span class="math inline">\(m\)</span> 个产品失效,而有 <span class="math inline">\(n-m\)</span> 个产品在 <span class="math inline">\(t_{m}\)</span> 时尚未失效,即有 <span class="math inline">\(n-m\)</span> 个产品的寿命超过 <span class="math inline">\(t_{m} .\)</span> 我们用最大似然估计法来估计 <span class="math inline">\(\theta,\)</span> 为了确定似然函数,需要知道上述观察结果出现的概率 . 我们知道一个产品在 <span class="math inline">\(\left(t_{i}, t_{i}+\mathrm{d} t_{i}\right]\)</span> 失效的概率近似地为 <span class="math inline">\(f\left(t_{i}\right) \mathrm{d} t_{i}=\frac{1}{\theta} \mathrm{e}^{-t_{i} / \theta} \mathrm{d} t_{i}, i=1,2, \cdots, m,\)</span> 其余 <span class="math inline">\(n-m\)</span> 个产品寿命超过 <span class="math inline">\(t_{m}\)</span> 的概率为 <span class="math inline">\(\left(\int_{t_{m}}^{\infty} \frac{1}{\theta} \mathrm{e}^{-t / \theta} \mathrm{d} t\right)^{n-m}=\left(\mathrm{e}^{-t_{m} / \theta}\right)^{n-m},\)</span> 故上述观察结果出现的概率近似为： <span class="math inline">\(\left(\begin{array}{l}n \\ m\end{array}\right)\left(\frac{1}{\theta} \mathrm{e}^{-t_{1} / \theta} \mathrm{d} t_{1}\right)\left(\frac{1}{\theta} \mathrm{e}^{-t_{2} / \theta} \mathrm{d} t_{2}\right) \cdots\left(\frac{1}{\theta} \mathrm{e}^{-t_{m} / \theta} \mathrm{d} t_{m}\right)\left(\mathrm{e}^{-t_{m} / \theta}\right)^{n-m}\)</span> <span class="math inline">\(\quad=\left(\begin{array}{l}n \\ m\end{array}\right) \frac{1}{\theta^{m}} \mathrm{e}^{-\frac{1}{\theta}\left[t_{1}+t_{2}+\cdots+t_{m}+(n-m) t_{m}\right]} \mathrm{d} t_{1} \mathrm{~d} t_{2} \cdots \mathrm{d} t_{m}\)</span> 其中<span class="math inline">\(\mathrm{d} t_{1}, \cdots, \mathrm{d} t_{m}\)</span>为常数。因忽略一个常数因子不影响θ的最大似然估计， 故可取似然函数为<span class="math inline">\(L(\theta)=\frac{1}{\theta^{m}} \mathrm{e}^{-\frac{1}{\theta}\left[t_{1}+t_{2}+\cdots+t_{m}+(n-m) t_{m}\right]}\)</span> 对数似然函数为<span class="math inline">\(\ln L(\theta)=-m \ln \theta-\frac{1}{\theta}\left[t_{1}+t_{2}+\cdots+t_{m}+(n-m) t_{m}\right]\)</span> 令<span class="math inline">\(\frac{\mathrm{d}}{\mathrm{d} \theta} \ln L(\theta)=-\frac{m}{\theta}+\frac{1}{\theta^{2}}\left[t_{1}+t_{2}+\cdots+t_{m}+(n-m) t_{m}\right]=0\)</span> 于是得到<span class="math inline">\(\theta\)</span> 的最大似然估计为<span class="math inline">\(\hat{\theta}=\frac{s\left(t_{m}\right)}{m}\)</span>，其中<span class="math inline">\(s\left(t_{m}\right)=t_{1}+t_{2}+\cdots+t_{m}+(n-m) t_{m}\)</span> 称为总试验时间 <span class="math inline">\(,\)</span> 它表示直至时刻 <span class="math inline">\(t_{m}\)</span> 为止n个产品的试验时间的总和。</p><p>对于<strong>定时截尾样本</strong><span class="math inline">\(0 \leqslant t_{1} \leqslant t_{2} \leqslant \cdots \leqslant t_{m} \leqslant t_{0}\)</span>（其中 <span class="math inline">\(t_{0}\)</span> 是截尾时间 <span class="math inline">\()\)</span>, 与上面的讨论类似， 可得似然函数为<span class="math inline">\(L(\theta)=\frac{1}{\theta^{m}} \mathrm{e}^{-\frac{1}{\theta}\left[t_{1}+t_{2}+\cdots+t_{m}+(n-m) t_{0}\right]}\)</span> <span class="math inline">\(\theta\)</span> 的最大似然估计为<span class="math inline">\(\hat{\theta}=\frac{s\left(t_{0}\right)}{m}\)</span>，其中<span class="math inline">\(s\left(t_{0}\right)=t_{1}+t_{2}+\cdots+t_{m}+(n-m) t_{0}\)</span> 称为总试验时间, 它表示直至时刻 <span class="math inline">\(t_{0}\)</span> 为止n个产品的试验时间的总和。</p><h2 id=估计量的评选标准>估计量的评选标准</h2><p>自前一节可以看到，对于同一参数，用<strong>不同的估计方法求出的估计量可能不相同</strong>.而且，很明显，<strong>原则上任何统计量都可以作为未知参数的估计量</strong>。我们自然会问，采用哪一个估计量为好呢？这就涉及用什么样的标准来评价估计量的问题。下面介绍几个常用的标准。</p><h3 id=无偏性>无偏性</h3><p>设 <span class="math inline">\(X_{1}, X_{2}, \cdots, X_{n}\)</span> 是总体 <span class="math inline">\(X\)</span> 的一个样本 <span class="math inline">\(, \theta \in \Theta\)</span> 是包含在总体 <span class="math inline">\(X\)</span> 的分布中的 待估参数,这里 <span class="math inline">\(\Theta\)</span> 是 <span class="math inline">\(\theta\)</span> 的取值范围.</p><p><strong>无偏性</strong>： 若估计量 <span class="math inline">\(\hat{\theta}=\hat{\theta}\left(X_{1}, X_{2}, \cdots, X_{n}\right)\)</span> 的数学期望 <span class="math inline">\(E(\hat{\theta})\)</span> 存在,且对于任意 <span class="math inline">\(\theta \in \Theta\)</span> 有<span class="math inline">\(E(\hat{\theta})=\theta\)</span>，则称<span class="math inline">\(\hat{\theta}\)</span>是 <span class="math inline">\(\theta\)</span> 的<strong>无偏估计量</strong>。</p><p>估计量的无偏性是说对于某些样本值,由这一估计量得到的估计值相对于真值来说偏大,有些则偏小. 反复将这一估计量使用多次,就“平均”来说其偏差 为零. 在科学技术中 <span class="math inline">\(E(\hat{\theta})-\theta\)</span> 称为以含作为 <span class="math inline">\(\theta\)</span> 的估计的<strong>系统误差</strong>. 无偏估计的实际意义就是无系统误差.</p><blockquote><p>例子： 设总体 <span class="math inline">\(X\)</span> 的均值为 <span class="math inline">\(\mu,\)</span> 方差 <span class="math inline">\(\sigma^{2}>0\)</span> 均未知， 前面已经计算过<span class="math inline">\(E(\bar{X})=\mu, \quad E\left(S^{2}\right)=\sigma^{2}\)</span>， 则不论总体服从什么分布,样本均值 <span class="math inline">\(\bar{X}\)</span> 是总体均值 <span class="math inline">\(\mu\)</span> 的无偏估计； 样本方差<span class="math inline">\(S^{2}=\frac{1}{n-1} \sum_{i=1}^{n}\left(X_{i}-\bar{X}\right)^{2}\)</span> 是总体方差的无偏估计，而估计量<span class="math inline">\(\frac{1}{n} \sum_{i=1}^{n}\left(X_{i}-\right.\)</span><span class="math inline">\(\bar{X})^{2}\)</span> 却不是 <span class="math inline">\(\sigma^{2}\)</span> 的无偏估计,因此我们一般取 <span class="math inline">\(S^{2}\)</span> 作为 <span class="math inline">\(\sigma^{2}\)</span> 的估计量。</p></blockquote><h3 id=有效性>有效性</h3><p>现在来比较参数 <span class="math inline">\(\theta\)</span> 的两个无偏估计量 <span class="math inline">\(\hat{\theta}_{1}\)</span> 和 <span class="math inline">\(\hat{\theta}_{2},\)</span> 如果在样本容量 <span class="math inline">\(n\)</span> 相同的情况下, <span class="math inline">\(\hat{\theta}_{1}\)</span> 的观察值较 <span class="math inline">\(\hat{\theta}_{2}\)</span> 更密集在真值 <span class="math inline">\(\theta\)</span> 的附近,我们就认为 <span class="math inline">\(\hat{\theta}_{1}\)</span> 较 <span class="math inline">\(\hat{\theta}_{2}\)</span> 为理想. 由于方差是随机变量取值与其数学期望(无偏估计的数学期望 <span class="math inline">\(\left.E\left(\hat{\theta}_{1}\right)=E\left(\hat{\theta}_{2}\right)=\theta\right)\)</span> 的偏离程度的度量,所以无偏估计以方差小者为好. 这就引出了估计量的有效性这一概念.</p><p><strong>有效性</strong>：设 <span class="math inline">\(\hat{\theta}_{1}=\hat{\theta}_{1}\left(X_{1}, X_{2}, \cdots, X_{n}\right)\)</span> 与 <span class="math inline">\(\hat{\theta}_{2}=\hat{\theta}_{2}\left(X_{1}, X_{2}, \cdots, X_{n}\right)\)</span> 都是 <span class="math inline">\(\theta\)</span> 的无偏估计量,若对于任意 <span class="math inline">\(\theta \in \Theta\)</span>,有<span class="math inline">\(D\left(\hat{\theta}_{1}\right) \leqslant D\left(\hat{\theta}_{2}\right)\)</span>，且至少对于某一个 <span class="math inline">\(\theta \in \Theta\)</span> 上式中的不等号成立,则称 <span class="math inline">\(\hat{\theta}_{1}\)</span> 较 <span class="math inline">\(\hat{\theta}_{2}\)</span> 有效.</p><h3 id=相合性>相合性</h3><p>前面讲的无偏性与有效性都是在样本容量n固定的前提下提出的。我们自然希望随着样本容量的增大，一个估计量的值稳定于待估参数的真值。这样，对估计量又有下述相合性的要求。</p><p><strong>相合性</strong> ： 设 <span class="math inline">\(\hat{\theta}\left(X_{1}, X_{2}, \cdots, X_{n}\right)\)</span> 为参数 <span class="math inline">\(\theta\)</span> 的估计量, 若对于任意 <span class="math inline">\(\theta \in \Theta,\)</span> 当 <span class="math inline">\(n \rightarrow \infty\)</span>时 <span class="math inline">\(\hat{\theta}\left(X_{1}, X_{2}, \cdots, X_{n}\right)\)</span> 依概率收敛于 <span class="math inline">\(\theta,\)</span> 则称 <span class="math inline">\(\hat{\theta}\)</span> 为 <span class="math inline">\(\theta\)</span> 的<strong>相合估计量</strong>. 即,若对于任意 <span class="math inline">\(\theta \in \Theta\)</span> 都满足 : 对于任意 <span class="math inline">\(\varepsilon>0,\)</span> 有<span class="math inline">\(\lim _{n \rightarrow \infty} P\{|\hat{\theta}-\theta|&lt;\varepsilon\}=1\)</span>，则称 <span class="math inline">\(\hat{\theta}\)</span> 是 <span class="math inline">\(\theta\)</span> 的<strong>相合估计量</strong>。</p><p>在矩估计法中，我们知道样本 <span class="math inline">\(k(k \geqslant 1)\)</span> 阶矩是总体 <span class="math inline">\(X\)</span> 的 <span class="math inline">\(k\)</span> 阶矩 <span class="math inline">\(\mu_{k}=E\left(X^{k}\right)\)</span> 的相合估计量（样本矩依概率收敛于对应总体矩），进而若待估参数 <span class="math inline">\(\theta=g\left(\mu_{1}, \mu_{2}, \cdots, \mu_{k}\right),\)</span> 其中 <span class="math inline">\(g\)</span> 为连续函数,则 <span class="math inline">\(\theta\)</span> 的矩估计量 <span class="math inline">\(\hat{\theta}=g\left(\hat{\mu}_{1}, \hat{\mu}_{2}, \cdots, \hat{\mu}_{k}\right)=g\left(A_{1}, A_{2}, \cdots, A_{k}\right)\)</span> 是 <span class="math inline">\(\theta\)</span> 的相合估计量（样本矩的连续函数依概率收敛于对应总体矩的连续函数）</p><p>极大似然估计法得到的估计量, 在一定条件下也具有相合性. 其详细讨论已超出本书范围,从略.</p><p>上述无偏性、有效性、相合性是评价估计量的一些基本标准，其他的标准这里就不讲了。</p><h2 id=区间估计>区间估计</h2><p>对于一个未知量,人们在测量或计算时,常不以<strong>得到近似值</strong>为满足,<strong>还需估计误差</strong>,即要求知道近似值的精确程度(亦即所求真值所在的范围). 类似地,对 于未知参数 <span class="math inline">\(\theta,\)</span> 除了求出它的点估计 <span class="math inline">\(\hat{\theta}\)</span> 外,<strong>我们还希望估计出一个范围,并希望知道这个范围包含参数 <span class="math inline">\(\theta\)</span> 真值的可信程度.</strong> 这样的范围通常以区间的形式给出,同 时还给出此区间包含参数 <span class="math inline">\(\theta\)</span> 真值的可信程度. 这种形式的估计称为区间估计,这 样的区间即所谓置信区间. 现在我们引人置信区间的定义.</p><h3 id=置信区间>置信区间</h3><p>设总体 <span class="math inline">\(X\)</span> 的分布函数 <span class="math inline">\(F(x ; \theta)\)</span> 含有一个未知参数 <span class="math inline">\(\theta, \theta \in \Theta(\Theta\)</span> 是 <span class="math inline">\(\theta\)</span> 可能取值的范围 <span class="math inline">\()\)</span>, 对于给定值 <span class="math inline">\(\alpha(0&lt;\alpha&lt;1),\)</span> 若由来自 <span class="math inline">\(X\)</span> 的样本 <span class="math inline">\(X_{1}, X_{2}, \cdots,\)</span> <span class="math inline">\(X_{n}\)</span> 确定的两个统计量 <span class="math inline">\(\theta=\underline{\theta}\left(X_{1}, X_{2}, \cdots, X_{n}\right)\)</span> 和 <span class="math inline">\(\bar{\theta}=\bar{\theta}\left(X_{1}, X_{2}, \cdots, X_{n}\right)(\theta&lt;\bar{\theta}),\)</span> 对于任意 <span class="math inline">\(\theta \in \Theta\)</span> 满足<span class="math inline">\(P\left\{\underline{\theta}\left(X_{1}, X_{2}, \cdots, X_{n}\right)&lt;\theta&lt;\bar{\theta}\left(X_{1}, X_{2}, \cdots, X_{n}\right)\right\} \geqslant 1-\alpha\)</span>， 则称随机区间 <span class="math inline">\((\theta, \bar{\theta})\)</span> 是 <span class="math inline">\(\theta\)</span> 的置信水平为 <span class="math inline">\(1-\alpha\)</span> 的<strong>置信区间</strong> <span class="math inline">\(, \theta\)</span> 和 <span class="math inline">\(\bar{\theta}\)</span> 分别称为置信水 平为 <span class="math inline">\(1-\alpha\)</span> 的<strong>双侧置信区间</strong>的<strong>置信下限</strong>和<strong>置信上限</strong>, <span class="math inline">\(1-\alpha\)</span> 称为<strong>置信水平</strong>.</p><blockquote><p><span class="math inline">\(P\left\{\underline{\theta}\left(X_{1}, X_{2}, \cdots, X_{n}\right)&lt;\theta&lt;\bar{\theta}\left(X_{1}, X_{2}, \cdots, X_{n}\right)\right\} \geqslant 1-\alpha\)</span>的含义： 若反复抽样多次(各次得到的样本的容量相等,都是 <span class="math inline">\(n\)</span> ). 每个样本值确定一个区间 <span class="math inline">\((\theta, \bar{\theta})\)</span>,每个这样的区间要么包含 <span class="math inline">\(\theta\)</span> 的真值,要么不 包含 <span class="math inline">\(\theta\)</span> 的真值. 按伯努利大数定理,在这么多的区间中,包含 <span class="math inline">\(\theta\)</span> 真 值的约占 <span class="math inline">\(100(1-\alpha) \%\)</span>,不包含 <span class="math inline">\(\theta\)</span> 真值的约仅占 <span class="math inline">\(100 \alpha \% .\)</span> 例如,若 <span class="math inline">\(\alpha=0.01,\)</span> 反复 抽样 1000 次,则得到的 1000 个区间中不包含 <span class="math inline">\(\theta\)</span> 真值的约仅为 10 个.</p></blockquote><p>当 <span class="math inline">\(X\)</span> 是连续型随机变量时,对于给定的 <span class="math inline">\(\alpha,\)</span> 按 <span class="math inline">\(P\{\theta&lt;\theta&lt;\bar{\theta}\}\)</span> <span class="math inline">\(=1-\alpha\)</span> 求置信区间 <span class="math inline">\(.\)</span> 而当 <span class="math inline">\(X\)</span> 是离散型随机变量时,对于给定的 <span class="math inline">\(\alpha,\)</span> 可能找不到 <span class="math inline">\(P\{\theta&lt;\theta&lt;\bar{\theta}\}\)</span> 恰为 <span class="math inline">\(1-\alpha\)</span>的区间 <span class="math inline">\((\theta, \bar{\theta})\)</span> ，则取 <span class="math inline">\(P\{\theta&lt;\theta&lt;\bar{\theta}\}\)</span>至少为 <span class="math inline">\(1-\alpha,\)</span> 且尽可能地接近 <span class="math inline">\(1-\alpha\)</span>区间 <span class="math inline">\((\theta, \bar{\theta})\)</span> （向外取近似区间）</p><blockquote><p>例子 设总体 <span class="math inline">\(X \sim N\left(\mu, \sigma^{2}\right), \sigma^{2}\)</span> 为已知 <span class="math inline">\(, \mu\)</span> 为未知,设 <span class="math inline">\(X_{1}, X_{2}, \cdots, X_{n}\)</span> 是来自<span class="math inline">\(X\)</span> 的样本,求 <span class="math inline">\(\mu\)</span> 的置信水平为 <span class="math inline">\(1-\alpha\)</span> 的置信区间. 我们知道 <span class="math inline">\(\bar{X}\)</span> 是 <span class="math inline">\(\mu\)</span> 的无偏估计. 且有<span class="math inline">\(\frac{\bar{X}-\mu}{\sigma / \sqrt{n}} \sim N(0,1)\)</span>， <span class="math inline">\(\frac{\bar{X}-\mu}{\sigma / \sqrt{n}}\)</span> 所服从的分布 <span class="math inline">\(N(0,1)\)</span> 不依赖于任何未知参数. 按标准正态分布的上 <span class="math inline">\(\alpha\)</span> 分位点的定义，有： <span class="math inline">\(P\left\{\left|\frac{\bar{X}-\mu}{\sigma / \sqrt{n}}\right|&lt;z_{\alpha / 2}\right\}=1-\alpha\)</span> 即<span class="math inline">\(P\left\{\bar{X}-\frac{\sigma}{\sqrt{n}} z_{a / 2}&lt;\mu&lt;\bar{X}+\frac{\sigma}{\sqrt{n}} z_{a / 2}\right\}=1-\alpha\)</span> 这样,我们就得到了 <span class="math inline">\(\mu\)</span> 的一个置信水平为 <span class="math inline">\(1-\alpha\)</span> 的置信区间： <span class="math inline">\(\left(\bar{X}-\frac{\sigma}{\sqrt{n}} z_{\alpha / 2}, \quad \bar{X}+\frac{\sigma}{\sqrt{n}} z_{\alpha / 2}\right)\)</span> 这样的置信区间常写成<span class="math inline">\(\left(\bar{X} \pm \frac{\sigma}{\sqrt{n}} z_{\alpha / 2}\right)\)</span> <img src=https://picgo12138.oss-cn-hangzhou.aliyuncs.com/md/image-20201218190425146.png alt=image-20201218190425146> 若取<span class="math inline">\(1-\alpha=0.95,\)</span> 即 <span class="math inline">\(\alpha=0.05,\)</span> 又若 <span class="math inline">\(\sigma=1, n=16,\)</span> 查表得 $z_{/ 2}=z_{0.025}=1.96 <span class="math inline">\(。 于是我们得到一个置信水平为 0.95 的置信区间\)</span>({X} ), $ 即 <span class="math inline">\((\bar{X} \pm 0.49)\)</span> 再者,若由一个样本值算得样本均值的观察值 <span class="math inline">\(\bar{x}=5.20,\)</span> 则得到一个区间<span class="math inline">\((5.20 \pm 0.49),\)</span> 即 <span class="math inline">\(\quad(4.71,5.69) .\)</span> 注意,这已经不是随机区间了.但我们仍称它为置信水平为 0.95 的置信区间. 含义:若反复抽样多次,每个样本值 <span class="math inline">\((n=16)\)</span> 按置信区间定义确定一个区间,按上面 的解释,在这么多的区间中,包含 <span class="math inline">\(\mu\)</span> 的约占 <span class="math inline">\(95 \%\)</span>,不包含 <span class="math inline">\(\mu\)</span> 的约仅占 <span class="math inline">\(5 \% .\)</span> 现在抽 样得到区间 <span class="math inline">\((4.71,5.69),\)</span> 则该区间属于那些包含 <span class="math inline">\(\mu\)</span> 的区间的可信程度为 <span class="math inline">\(95 \%\)</span>, 或“该区间包含 <span class="math inline">\(\mu\)</span>”这一陈述的可信程度为 <span class="math inline">\(95 \%\)</span>.</p></blockquote><p>置信水平为 <span class="math inline">\(1-\alpha\)</span> 的置信区间并不是唯一的. 以上面的例子来说,若给定 <span class="math inline">\(\alpha=0.05\)</span>则又有 <span class="math inline">\(P\left\{-z_{0.04}&lt;\frac{\bar{X}-\mu}{\sigma / \sqrt{n}}&lt;z_{0.01}\right\}=0.95\)</span>， 即<span class="math inline">\(P\left\{\bar{X}-\frac{\sigma}{\sqrt{n}} z_{0.01}&lt;\mu&lt;\bar{X}+\frac{\sigma}{\sqrt{n}} z_{0.04}\right\}=0.95\)</span>， 即<span class="math inline">\(\left(\bar{X}-\frac{\sigma}{\sqrt{n}} z_{0.01}, \bar{X}+\frac{\sigma}{\sqrt{n}} z_{0.04}\right)\)</span> 与之前得到的置信区间比较可以得到：使用<span class="math inline">\(z_{\alpha/2}\)</span>的区间更小，区间小则精度高。 易知，像 <span class="math inline">\(N(0,1)\)</span> 分布那样其概率密度的图形是单峰且对称的情况,当 <span class="math inline">\(n\)</span> 固定时，使用<span class="math inline">\(z_{\alpha/2}\)</span>的区间其长度为最短,我们自然选用它.</p><p>寻求未知参数 <span class="math inline">\(\theta\)</span> 的置信区间的具体做法如下： 1） 寻求一个样本 <span class="math inline">\(X_{1}, X_{2}, \cdots, X_{n}\)</span> 和 <span class="math inline">\(\theta\)</span> 的函数 <span class="math inline">\(W=W\left(X_{1}, X_{2}, \cdots, X_{n} ; \theta\right),\)</span> 使得 <span class="math inline">\(W\)</span> 的分布不依赖于 <span class="math inline">\(\theta\)</span> 以及其他未知参数,称具有这种性质的函数 <span class="math inline">\(W\)</span> 为<strong>枢轴量</strong>. 2）对于给定的置信水平 <span class="math inline">\(1-\alpha,\)</span> 定出两个常数 <span class="math inline">\(a, b\)</span> 使得<span class="math inline">\(P\left\{a&lt;W\left(X_{1}, X_{2}, \cdots, X_{n} ; \theta\right)&lt;b\right\}=1-\alpha\)</span>， 若能从 <span class="math inline">\(a&lt;W\left(X_{1}, X_{2}, \cdots, X_{n} ; \theta\right)&lt;b\)</span> 得到与之等价的 <span class="math inline">\(\theta\)</span> 的不等式 <span class="math inline">\(\underline{\theta}&lt;\theta&lt;\bar{\theta},\)</span> 其中<span class="math inline">\(\theta=\underline{\theta}\left(X_{1}, X_{2}, \cdots, X_{n}\right), \bar{\theta}=\bar{\theta}\left(X_{1}, X_{2}, \cdots, X_{n}\right)\)</span> 都是统计量.那么 <span class="math inline">\((\underline{\theta}, \bar{\theta})\)</span> 就是 <span class="math inline">\(\theta\)</span> 的一个置信水平为 <span class="math inline">\(1-\alpha\)</span> 的置信区间.</p><p>函数 <span class="math inline">\(W\left(X_{1}, X_{2}, \cdots, X_{n} ; \theta\right)\)</span> 的构造,通常可以从 <span class="math inline">\(\theta\)</span> 的点估计着手考虑.常用的正 态总体的参数的置信区间可以用上述步骤推得.</p><h3 id=正态总体均值与方差的区间估计>正态总体均值与方差的区间估计</h3><p>设已给定置信水平为 <span class="math inline">\(1-\alpha\)</span>,并设 <span class="math inline">\(X_{1}, X_{2}, \cdots, X_{n}\)</span> 为总体 <span class="math inline">\(N\left(\mu, \sigma^{2}\right)\)</span> 的样本. <span class="math inline">\(\bar{X}\)</span>, <span class="math inline">\(S^{2}\)</span> 分别是样本均值和样本方差.</p><h4 id=单个总体-nleftmu-sigma2right-的情况>单个总体 <span class="math inline">\(N\left(\mu, \sigma^{2}\right)\)</span> 的情况</h4><h5 id=均值-mu-的置信区间>均值 <span class="math inline">\(\mu\)</span> 的置信区间</h5><h6 id=sigma2-为已知><span class="math inline">\(\sigma^{2}\)</span> 为已知</h6><blockquote><p><span class="math inline">\(\frac{\bar{X}-\mu}{\sigma / \sqrt{n}} \sim N(0,1)\)</span>，且 <span class="math inline">\(\frac{\bar{X}-\mu}{\sigma / \sqrt{n}}\)</span>是枢轴量， 上面置信区间的例子中已得到 <span class="math inline">\(\mu\)</span> 的一个置信水平为 <span class="math inline">\(1-\alpha\)</span> 的置信区间为<span class="math inline">\(\left(\bar{X} \pm \frac{\sigma}{\sqrt{n}} z_{\alpha / 2}\right)\)</span></p></blockquote><h6 id=sigma2-为未知><span class="math inline">\(\sigma^{2}\)</span> 为未知</h6><p>在实际问题中,总体方差 <span class="math inline">\(\sigma^{2}\)</span> 未知的情况居多。因此不能使用上面给出的置信区间,因其中含未知参数 <span class="math inline">\(\sigma .\)</span></p><blockquote><p>考虑到到 <span class="math inline">\(S^{2}\)</span> 是 <span class="math inline">\(\sigma^{2}\)</span> 的无偏估计,将<span class="math inline">\(\frac{\bar{X}-\mu}{\sigma / \sqrt{n}} \sim N(0,1)\)</span>中的 <span class="math inline">\(\sigma\)</span> 换成 <span class="math inline">\(S=\sqrt{S^{2}}\)</span>， 再根据t分布的性质<span class="math inline">\(\frac{\bar{X}-\mu}{S / \sqrt{n}} \sim t(n-1)\)</span> 即<span class="math inline">\(\frac{\bar{X}-\mu}{S / \sqrt{n}}\)</span>是枢轴量。 可得<span class="math inline">\(P\left\{-t_{\alpha / 2}(n-1)&lt;\frac{\bar{X}-\mu}{S / \sqrt{n}}&lt;t_{a / 2}(n-1)\right\}=1-\alpha\)</span>，<span class="math inline">\(P\left\{\bar{X}-\frac{S}{\sqrt{n}} t_{\alpha / 2}(n-1)&lt;\mu&lt;\bar{X}+\frac{S}{\sqrt{n}} t_{\alpha / 2}(n-1)\right\}=1-\alpha\)</span></p><p><img src=https://picgo12138.oss-cn-hangzhou.aliyuncs.com/md/image-20201219000309976.png alt=image-20201219000309976> 于是得 <span class="math inline">\(\mu\)</span> 的一个置信水平为 <span class="math inline">\(1-\alpha\)</span> 的置信区间<span class="math inline">\(\left(\bar{X} \pm \frac{S}{\sqrt{n}} t_{a / 2}(n-1)\right)\)</span></p></blockquote><h5 id=方差-sigma2-的置信区间>方差 <span class="math inline">\(\sigma^{2}\)</span> 的置信区间</h5><h6 id=mu-已知的情况><span class="math inline">\(\mu\)</span> 已知的情况</h6><blockquote><p>由于样本各 <span class="math inline">\(X_{i}\)</span> 相互独立,且与总体 <span class="math inline">\(X\)</span> 同分布, 故每个 <span class="math inline">\(\frac{X_{i}-\mu}{\sigma} \sim N(0,1)\)</span>且相互独立， 则<span class="math inline">\(\frac{1}{\sigma^{2}} \sum_{i=1}^{n}\left(X_{i}-\mu\right)^{2}=\sum_{i=1}^{n}\left(\frac{X_{i}-\mu}{\sigma}\right)^{2} \sim \chi^{2}(n)\)</span>， 且该分布不依赖于任何未知参数，故此样本函数可作为枢轴量。 由<span class="math inline">\(\chi^2\)</span>分布上的<span class="math inline">\(\alpha\)</span>分位点的定义，有<span class="math inline">\(P\left(\chi_{1-\frac{\alpha}{2}}^{2}(n)&lt;\frac{1}{\sigma^{2}} \sum_{i=1}^{n}\left(X_{i}-\mu\right)^{2}&lt;\chi_{\frac{\alpha}{2}}^{2}(n)\right)=1-\alpha\)</span> 即<span class="math inline">\(P\left(\frac{\sum_{i=1}^{n}\left(X_{i}-\mu\right)^{2}}{\chi_{\frac{\alpha}{2}}^{2}(n)}&lt;\sigma^{2}&lt;\frac{\sum_{i=1}^{n}\left(X_{i}-\mu\right)^{2}}{\chi_{1-\frac{\alpha}{2}}^{2}(n)}\right)=1-\alpha\)</span> 由此得到方差<span class="math inline">\(\sigma^2\)</span>的一个置信度为<span class="math inline">\(1-\alpha\)</span>的置信区间： <span class="math inline">\(\left(\frac{\sum_{i=1}^{n}\left(X_{i}-\mu\right)^{2}}{\chi_{\frac{\alpha}{2}}^{2}(n)}, \frac{\sum_{i=1}^{n}\left(X_{i}-\mu\right)^{2}}{\chi_{1-\frac{\alpha}{2}}^{2}(n)}\right)\)</span></p></blockquote><h6 id=mu-未知的情况><span class="math inline">\(\mu\)</span> 未知的情况</h6><p>实际问题的需要,一般是 <span class="math inline">\(\mu\)</span> 未知的情况.</p><blockquote><p><span class="math inline">\(\sigma^{2}\)</span> 的无偏估计为 <span class="math inline">\(S^{2},\)</span> 再根据<a href=../概率论与数理统计-数理统计-基本概念#$\chi%5E%7B2%7D$分布>卡方分布的性质</a>以及<a href=../概率论与数理统计-数理统计-基本概念#正态总体的抽样分布>正态总体的抽样分布</a>：<span class="math inline">\(\frac{(n-1) S^{2}}{\sigma^{2}} \sim \chi^{2}(n-1)\)</span>,</p><p>且上式右端的分布不依赖于任何未知参数， 取 <span class="math inline">\(\frac{(n-1) S^{2}}{\sigma^{2}}\)</span> 作为枢轴量, 得<span class="math inline">\(P\left\{\chi_{1-\alpha / 2}^{2}(n-1)&lt;\frac{(n-1) S^{2}}{\sigma^{2}}&lt;\chi_{a / 2}^{2}(n-1)\right\}=1-\alpha\)</span>， 即<span class="math inline">\(P\left\{\frac{(n-1) S^{2}}{\chi_{a / 2}^{2}(n-1)}&lt;\sigma^{2}&lt;\frac{(n-1) S^{2}}{\chi_{1}^{2}-\alpha / 2(n-1)}\right\}=1-\alpha\)</span>， 这就得到方差 <span class="math inline">\(\sigma^{2}\)</span> 的一个置信水平为 <span class="math inline">\(1-\alpha\)</span> 的貴信区间： <span class="math inline">\(\left(\frac{(n-1) S^{2}}{\chi_{\alpha / 2}^{2}(n-1)}, \frac{(n-1) S^{2}}{\chi_{1-\alpha / 2}^{2}(n-1)}\right)\)</span> 注意：在密度函数不对称时,如 <span class="math inline">\(\chi^{2}\)</span> 分布和 <span class="math inline">\(F\)</span> 分布,<strong>习惯上</strong>仍是取对称的分位点来确定置信区间的.（如上面取了分位点 <span class="math inline">\(\chi_{1-a / 2}^{2}(n-1)\)</span> 与 <span class="math inline">\(\chi_{\alpha / 2}^{2}(n-1)\)</span> ）。</p></blockquote><h4 id=两个总体-nleftmu_1-sigma_12right-nleftmu_2-sigma_22right-的情况>两个总体 <span class="math inline">\(N\left(\mu_{1}, \sigma_{1}^{2}\right), N\left(\mu_{2}, \sigma_{2}^{2}\right)\)</span> 的情况</h4><p>在实际中常遇到下面的问题 : 已知产品的某一质量指标服从正态分布,但由 于原料、设备条件、操作人员不同,或工艺过程的改变等因素,引起总体均值、总 体方差有所改变. 我们需要知道这些变化有多大,这就需要考虑两个正态总体均 值差或方差比的估计问题.</p><p>设已给定置信水平为 <span class="math inline">\(1-\alpha\)</span>,并设 <span class="math inline">\(X_{1}, X_{2}, \cdots, X_{n_{1}}\)</span> 是来自第一个总体的样本 <span class="math inline">\(Y_{1}, Y_{2}, \cdots, Y_{n_{2}}\)</span> 是来自第二个总体的样本,这两个样本相互独立. 且设 <span class="math inline">\(\bar{X}, \bar{Y}\)</span> 分别 为第一、第二个总体的样本均值, <span class="math inline">\(S_{1}^{2}, S_{2}^{2}\)</span> 分别是第一、第二个总体的样本方差.</p><h5 id=两个总体均值差-mu_1-mu_2-的置信区间>两个总体均值差 <span class="math inline">\(\mu_{1}-\mu_{2}\)</span> 的置信区间</h5><h6 id=sigma_12-sigma_22-均为已知><span class="math inline">\(\sigma_{1}^{2}, \sigma_{2}^{2}\)</span> 均为已知</h6><blockquote><p>因 <span class="math inline">\(\bar{X}, \bar{Y}\)</span> 分别为 <span class="math inline">\(\mu_{1}, \mu_{2}\)</span> 的无偏估计,故 <span class="math inline">\(\bar{X}-\bar{Y}\)</span> 是 <span class="math inline">\(\mu_{1}-\mu_{2}\)</span>的无偏估计. 由 <span class="math inline">\(\bar{X}, \bar{Y}\)</span> 的独立性以及 <span class="math inline">\(\bar{X} \sim N\left(\mu_{1}, \sigma_{1}^{2} / n_{1}\right), \bar{Y} \sim N\left(\mu_{2}, \sigma_{2}^{2} / n_{2}\right)\)</span> 得<span class="math inline">\(\bar{X}-\bar{Y} \sim N\left(\mu_{1}-\mu_{2}, \frac{\sigma_{1}^{2}}{n_{1}}+\frac{\sigma_{2}^{2}}{n_{2}}\right)\)</span>， 得<span class="math inline">\(\frac{(\bar{X}-\bar{Y})-\left(\mu_{1}-\mu_{2}\right)}{\sqrt{\frac{\sigma_{1}^{2}}{n_{1}}+\frac{\sigma_{2}^{2}}{n_{2}}}} \sim N(0,1)\)</span> 取左边的函数为枢轴量,即得 <span class="math inline">\(\mu_{1}-\mu_{2}\)</span> 的一个置信水平为 <span class="math inline">\(1-\alpha\)</span> 的置信区间： <span class="math inline">\(\left(\bar{X}-\bar{Y} \pm z_{a / 2} \sqrt{\frac{\sigma_{1}^{2}}{n_{1}}+\frac{\sigma_{2}^{2}}{n_{2}}}\right)\)</span></p></blockquote><h6 id=sigma_12sigma_22sigma2-但-sigma2-为未知><span class="math inline">\(\sigma_{1}^{2}=\sigma_{2}^{2}=\sigma^{2},\)</span> 但 <span class="math inline">\(\sigma^{2}\)</span> 为未知</h6><blockquote><p>根据<a href=../概率论与数理统计-数理统计-基本概念#正态总体的抽样分布>正态总体的抽样分布</a>有：<span class="math inline">\(\frac{(\bar{X}-\bar{Y})-\left(\mu_{1}-\mu_{2}\right)}{S_{w} \sqrt{\frac{1}{n_{1}}+\frac{1}{n_{2}}}} \sim t\left(n_{1}+n_{2}-2\right)\)</span>， 取左边的函数为枢轴量， 可得 <span class="math inline">\(\mu_{1}-\mu_{2}\)</span> 的一个置信水平为 <span class="math inline">\(1-\alpha\)</span> 的置信区间为： <span class="math inline">\(\left(\bar{X}-\bar{Y} \pm t_{a / 2}\left(n_{1}+n_{2}-2\right) S_{w} \sqrt{\frac{1}{n_{1}}+\frac{1}{n_{2}}}\right)\)</span> 这里<span class="math inline">\(S_{w}^{2}=\frac{\left(n_{1}-1\right) S_{1}^{2}+\left(n_{2}-1\right) S_{2}^{2}}{n_{1}+n_{2}-2}, S_{w}=\sqrt{S_{w}^{2}}\)</span></p></blockquote><h5 id=两个总体方差比-sigma_12-sigma_22-的置信区间>两个总体方差比 <span class="math inline">\(\sigma_{1}^{2} / \sigma_{2}^{2}\)</span> 的置信区间</h5><p>我们仅讨论总体均值 <span class="math inline">\(\mu_{1}, \mu_{2}\)</span> 均为未知的情况。</p><blockquote><p>根据<a href=../概率论与数理统计-数理统计-基本概念#正态总体的抽样分布>正态总体的抽样分布</a>有：<span class="math inline">\(\frac{S_{1}^{2} / S_{2}^{2}}{\sigma_{1}^{2} / \sigma_{2}^{2}} \sim F\left(n_{1}-1, n_{2}-1\right)\)</span>， 并且分布 <span class="math inline">\(F\left(n_{1}-1, n_{2}-1\right)\)</span> 不依赖任何未知参数. 取 <span class="math inline">\(\frac{S_{1}^{2} / S_{2}^{2}}{\sigma_{1}^{2} / \sigma_{2}^{2}}\)</span> 为枢轴量， 得<span class="math inline">\(P\left\{F_{1-\alpha / 2}\left(n_{1}-1, n_{2}-1\right)&lt;\frac{S_{1}^{2} / S_{2}^{2}}{\sigma_{1}^{2} / \sigma_{2}^{2}}&lt;F_{a / 2}\left(n_{1}-1, n_{2}-1\right)\right\}=1-\alpha\)</span> 即<span class="math inline">\(P\left(\frac{S_{1}^{2}}{S_{2}^{2}} \frac{1}{F_{a / 2}\left(n_{1}-1, n_{2}-1\right)}&lt;\frac{\sigma_{1}^{2}}{\sigma_{2}^{2}}&lt;\frac{S_{1}^{2}}{S_{2}^{2}} \frac{1}{F_{1-\alpha / 2}\left(n_{1}-1, n_{2}-1\right)}\right\}=1-\alpha\)</span> 于是得 <span class="math inline">\(\sigma_{1}^{2} / \sigma_{2}^{2}\)</span> 的一个置信水平为 <span class="math inline">\(1-\alpha\)</span> 的置信区间为： <span class="math inline">\(\left(\frac{S_{1}^{2}}{S_{2}^{2}} \frac{1}{F_{a / 2}\left(n_{1}-1, n_{2}-1\right)}, \frac{S_{1}^{2}}{S_{2}^{2}} \frac{1}{F_{1-a / 2}\left(n_{1}-1, n_{2}-1\right)}\right)\)</span></p></blockquote><p>若 <span class="math inline">\(\sigma_{1}^{2} / \sigma_{2}^{2}\)</span> 的置信区间包含 1 ,在实际中我们就认为 <span class="math inline">\(\sigma_{1}^{2}, \sigma_{2}^{2}\)</span> 两者没有显著差别。</p><h4 id=正态总体的区间估计汇总>正态总体的区间估计汇总</h4><script>window.onload=function(){var current=0;document.getElementById('#pic1').onclick=function(){current=(current+90)%360;this.style.transform='rotate('+current+'deg)';}};</script><figure><img src=https://picgo12138.oss-cn-hangzhou.aliyuncs.com/md/2020-12-20-pic1.jpg alt><figcaption>pic1</figcaption></figure><h3 id=非正态整体参数的区间估计>非正态整体参数的区间估计</h3><p>前面我们主要介绍了关于正态总体参数的区间估计问题，但再很多的实际问题中，有时我们无法判断总体是否服从正态分布。这时，只要样本容量n很大(<span class="math inline">\(n\leqslant 50\)</span>)时，可用中心极限定理求得其近似的置信区间。</p><p>对于总体 <span class="math inline">\(X,\)</span> 设 <span class="math inline">\(E(X)=\mu, D(X)=\sigma^{2}(\)</span> 已知 <span class="math inline">\()\)</span> 均存在, <span class="math inline">\(\mu\)</span> 是未知参数. 设 <span class="math inline">\(X_{1}, X_{2}, \cdots, X_{n}\)</span> 是来自 <span class="math inline">\(X\)</span> 的一组样本, 根据中心极限定理, 对充分大的 <span class="math inline">\(n,\)</span> 近似地有<span class="math inline">\(\frac{\sum_{i=1}^{n} X_{i}-n \mu}{\sqrt{n} \sigma} \sim N(0,1)\)</span> 即<span class="math inline">\(\frac{\bar{X}-\mu}{\sigma / \sqrt{n}} \sim N(0,1)\)</span>， 因此，当样本容量n充分大时， 若总体方差<span class="math inline">\(\sigma^2\)</span>已知，可得总体均值<span class="math inline">\(\mu\)</span>的置信度为<span class="math inline">\(1-\alpha\)</span>的一个近似区间<span class="math inline">\(\begin{equation} \left(\bar{X} \pm \frac{\sigma}{\sqrt{n}} z_{\frac{\alpha}{2}}\right) \end{equation}\)</span> 若总体方差<span class="math inline">\(\sigma^2\)</span>未知，用<span class="math inline">\(\sigma\)</span>的估计无偏估计<span class="math inline">\(S\)</span>来替代，总体均值<span class="math inline">\(\mu\)</span>的置信度为<span class="math inline">\(1-\alpha\)</span>的一个近似区间<span class="math inline">\(\left(\bar{X} \pm \frac{S}{\sqrt{n}} z_{\frac{\alpha}{2}}\right)\)</span></p><p>可以看到，当样本容量n充分大时，非正态总体均值<span class="math inline">\(\mu\)</span>的置信区间于正态总体区间估计一致。</p><h4 id=分布参数的区间估计><span class="math inline">\((0-1)\)</span> 分布参数的区间估计</h4><p>设有一容量 <span class="math inline">\(n>50\)</span> 的大样本,它来自 <span class="math inline">\((0-1)\)</span> 分布的总体 <span class="math inline">\(X\)</span>, <span class="math inline">\(X\)</span> 的分布律为<span class="math inline">\(f(x ; p)=p^{x}(1-p)^{1-x}, x=0,1\)</span> 已知 <span class="math inline">\((0-1)\)</span> 分布的均值和方差分别为<span class="math inline">\(\mu=p, \quad \sigma^{2}=p(1-p)\)</span>, 设 <span class="math inline">\(X_{1}, X_{2}, \cdots, X_{n}\)</span> 是一个样本. 因样本容量 <span class="math inline">\(n\)</span> 较大,由中心极限定理, 知<span class="math inline">\(\frac{\sum_{i=1}^{n} X_{i}-n p}{\sqrt{n p(1-p)}}=\frac{n \bar{X}-n p}{\sqrt{n p(1-p)}}\)</span>近似地服从 <span class="math inline">\(N\)</span> (0,1)分布, 于是有<span class="math inline">\(P\left\{-z_{a / 2}&lt;\frac{n \bar{X}-n p}{\sqrt{n p(1-p)}}&lt;z_{a / 2}\right\} \approx 1-\alpha\)</span> 而不等式<span class="math inline">\(-z_{\alpha / 2}&lt;\frac{n \bar{X}-n p}{\sqrt{n p(1-p)}}&lt;z_{a / 2}\)</span>等价于<span class="math inline">\(\left(n+z_{\alpha / 2}^{2}\right) p^{2}-\left(2 n \bar{X}+z_{\alpha / 2}^{2}\right) p+n \bar{X}^{2}&lt;0\)</span> 记：<span class="math inline">\(p_{1}=\frac{1}{2 a}\left(-b-\sqrt{b^{2}-4 a c}\right)\)</span> <span class="math inline">\(p_{2}=\frac{1}{2 a}\left(-b+\sqrt{b^{2}-4 a c}\right),\)</span> 其中<span class="math inline">\(a=n+z_{\alpha / 2}^{2}, b=-\left(2 n \bar{X}+z_{\alpha / 2}^{2}\right), c=n \bar{X}^{2}\)</span> 于是得得 <span class="math inline">\(p\)</span> 的一个近似的置信水平为 <span class="math inline">\(1-\alpha\)</span> 的置信区间为<span class="math inline">\(\left(p_{1}, p_{2}\right)\)</span></p><h3 id=单侧置信区间>单侧置信区间</h3><p>前面讨论中,对于未知参数 <span class="math inline">\(\theta,\)</span> 我们给出两个统计量 <span class="math inline">\(\theta, \bar{\theta},\)</span> 得到 <span class="math inline">\(\theta\)</span> 的双侧置信区间 <span class="math inline">\((\underline{\theta}, \bar{\theta}) .\)</span> 但在某些实际问题中,例如，对于设备、元件的寿命来说,平均寿命 长是我们所希望的,我们关心的是平均寿命 <span class="math inline">\(\theta\)</span> 的“下限”;与之相反,在考虑化学 药品中杂质含量的均值 <span class="math inline">\(\mu\)</span> 时,我们常关心参数 <span class="math inline">\(\mu\)</span> 的“上限”。 这就引出了单侧置信区间的概念.</p><p>对于给定值 <span class="math inline">\(\alpha(0&lt;\alpha&lt;1),\)</span> 若由样本 <span class="math inline">\(X_{1}, X_{2}, \cdots, X_{n}\)</span> 确定的统计量 <span class="math inline">\(\theta=\underline\theta\left(X_{1},\right.\left.X_{2}, \cdots, X_{n}\right),\)</span> 对于任意 <span class="math inline">\(\theta \in \Theta\)</span> 满足<span class="math inline">\(P\{\theta>\theta\} \geqslant 1-\alpha\)</span>， 称随机区间 <span class="math inline">\((\underline\theta, \infty)\)</span> 是 <span class="math inline">\(\theta\)</span> 的置信水平为 <span class="math inline">\(1-\alpha\)</span> 的<strong>单侧置信区间</strong> <span class="math inline">\(, \underline\theta\)</span> 称为 <span class="math inline">\(\theta\)</span> 的置信水平为 <span class="math inline">\(1-\alpha\)</span> 的<strong>单侧置信下限</strong>.</p><p>对于给定值 <span class="math inline">\(\alpha(0&lt;\alpha&lt;1),\)</span> 又若统计量 <span class="math inline">\(\bar{\theta}=\bar{\theta}\left(X_{1}, X_{2}, \cdots, X_{n}\right),\)</span> 对于任意 <span class="math inline">\(\theta \in \Theta\)</span> 满足<span class="math inline">\(P\{\theta&lt;\bar{\theta}\} \geqslant 1-\alpha\)</span>， 称随机区间 <span class="math inline">\((-\infty, \bar{\theta})\)</span> 是 <span class="math inline">\(\theta\)</span> 的置信水平为 <span class="math inline">\(1-\alpha\)</span> 的<strong>单侧置信区间</strong> <span class="math inline">\(, \bar{\theta}\)</span> 称为 <span class="math inline">\(\theta\)</span> 的置信 水平为 <span class="math inline">\(1-\alpha\)</span> 的<strong>单侧置信上限</strong>.</p><blockquote><p>例子 例如对于正态总体 <span class="math inline">\(X,\)</span> 若均值 <span class="math inline">\(\mu,\)</span> 方差 <span class="math inline">\(\sigma^{2}\)</span> 均为未知, 设 <span class="math inline">\(X_{1}, X_{2}, \cdots, X_{n}\)</span> 是一 个样本, 由<span class="math inline">\(\frac{\bar{X}-\mu}{S / \sqrt{n}} \sim t(n-1)\)</span> 有<span class="math inline">\(P\left\{\frac{\bar{X}-\mu}{S / \sqrt{n}}&lt;t_{a}(n-1)\right\}=1-\alpha\)</span> 即<span class="math inline">\(P\left\{\mu>\bar{X}-\frac{S}{\sqrt{n}} t_{a}(n-1)\right\}=1-\alpha\)</span>， 于是得到 <span class="math inline">\(\mu\)</span> 的一个置信水平为 <span class="math inline">\(1-\alpha\)</span> 的单侧置信区间<span class="math inline">\(\left(\bar{X}-\frac{S}{\sqrt{n}} t_{a}(n-1), \infty\right)\)</span> <span class="math inline">\(\mu\)</span> 的置信水平为 <span class="math inline">\(1-\alpha\)</span> 的单侧置信下限为<span class="math inline">\(\mu=\bar{X}-\frac{S}{\sqrt{n}} t_{\alpha}(n-1)\)</span> <img src=https://picgo12138.oss-cn-hangzhou.aliyuncs.com/md/image-20201219163310568.png alt=image-20201219163310568></p></blockquote><blockquote><p>例子2 <span class="math inline">\(\frac{(n-1) S^{2}}{\sigma^{2}} \sim \chi^{2}(n-1)\)</span> 有<span class="math inline">\(P\left\{\frac{(n-1) S^{2}}{\sigma^{2}}>\chi_{1-\alpha}^{2}(n-1)\right\}=1-\alpha\)</span> 即<span class="math inline">\(P\left\{\sigma^{2}&lt;\frac{(n-1) S^{2}}{\chi_{1-a}^{2}(n-1)}\right\}=1-\alpha\)</span> 于是得 <span class="math inline">\(\sigma^{2}\)</span> 的置信水平为 <span class="math inline">\(1-\alpha\)</span> 的单侧置信区间<span class="math inline">\(\left(0, \frac{(n-1) S^{2}}{\chi_{1-\alpha}^{2}(n-1)}\right)\)</span> <span class="math inline">\(\sigma^{2}\)</span> 的置信水平为 <span class="math inline">\(1-\alpha\)</span> 的单侧置信上限为<span class="math inline">\(\bar{\sigma}^{2}=\frac{(n-1) S^{2}}{\chi_{1}^{2}-\alpha}\)</span> <img src=https://picgo12138.oss-cn-hangzhou.aliyuncs.com/md/image-20201219163649704.png alt=image-20201219163649704></p></blockquote><p>相同条件下，同一置信度的单侧置信上/下限与双侧置信区间的上下限，对比发现，只是<span class="math inline">\(\alpha\)</span>与<span class="math inline">\(\frac{\alpha}{2}\)</span>的区别。 这种规律对前面介绍的各种条件下的正态总体都适用，即值序将双侧置信区间的上（或下）限中的<span class="math inline">\(\frac{\alpha}{2}\)</span>换成<span class="math inline">\(\alpha\)</span>，就是相同条件下相同参数的同一置信度的单侧置信上（或下）限。</p></section></article></main></div><div class="col-sm-3 col-sm-offset-1 doc-sidebar"><div id=sidebar><div class=sidebar-module><div class=sidebar-toc><h4 class=sidebar-heading>Table of Contents</h4><ul><li><strong><a href=#title>概率论与数理统计-数理统计-参数估计</a></strong></li></ul></div></div><div class=sidebar-module><h4 class=sidebar-heading>Pages in Categories</h4><ul class=sidebar-category-list><li><a href=https://ole12138.gitee.io//categories/http><span class=doc-list-category>Http</span></a><ul><li><a href=/post/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%8A%80%E6%9C%AF/http%E5%8D%8F%E8%AE%AE%E4%B8%8E%E6%8A%A5%E6%96%87/>转载：HTTP协议入门</a></li><li><a href=/post/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%8A%80%E6%9C%AF/%E8%BD%AC%E8%BD%BD%E5%8F%91%E8%B5%B7http%E8%AF%B7%E6%B1%82spring%E4%B8%ADresttempalate%E8%AE%BE%E7%BD%AE%E8%AF%B7%E6%B1%82%E5%A4%B4/>转载：发起HTTP请求：Spring中RestTemplate设置与携带请求头</a></li><li><a href=/post/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%8A%80%E6%9C%AF/%E8%BD%AC%E8%BD%BD%E5%8F%91%E8%B5%B7http%E8%AF%B7%E6%B1%82spring%E4%B8%AD%E7%9A%84resttempalate%E7%9A%84%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8/>转载：发起HTTP请求：Spring中的RestTempalate的基本使用</a></li><li><a href=/post/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%8A%80%E6%9C%AF/java%E5%AE%9E%E7%8E%B0http%E8%AF%B7%E6%B1%82/>Java发起HTTP请求的几种方法</a></li></ul></li><li><a href=https://ole12138.gitee.io//categories/java><span class=doc-list-category>Java</span></a><ul><li><a href=/post/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%8A%80%E6%9C%AF/%E9%9A%8F%E7%AC%94-java%E4%B8%AD%E8%B5%84%E6%BA%90%E7%9A%84%E5%85%B3%E9%97%AD/>Java中资源的关闭</a></li><li><a href=/post/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%8A%80%E6%9C%AF/java%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E4%BB%A3%E7%90%86%E6%A8%A1%E5%BC%8F/>Java设计模式之代理模式</a></li><li><a href=/post/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%8A%80%E6%9C%AF/%E8%BD%AC%E8%BD%BD%E5%8F%91%E8%B5%B7http%E8%AF%B7%E6%B1%82spring%E4%B8%ADresttempalate%E8%AE%BE%E7%BD%AE%E8%AF%B7%E6%B1%82%E5%A4%B4/>转载：发起HTTP请求：Spring中RestTemplate设置与携带请求头</a></li><li><a href=/post/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%8A%80%E6%9C%AF/%E8%BD%AC%E8%BD%BD%E5%8F%91%E8%B5%B7http%E8%AF%B7%E6%B1%82spring%E4%B8%AD%E7%9A%84resttempalate%E7%9A%84%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8/>转载：发起HTTP请求：Spring中的RestTempalate的基本使用</a></li><li><a href=/post/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%8A%80%E6%9C%AF/java%E5%AE%9E%E7%8E%B0http%E8%AF%B7%E6%B1%82/>Java发起HTTP请求的几种方法</a></li><li><a href=/post/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%8A%80%E6%9C%AF/%E8%BD%AC%E8%BD%BDjava8%E5%87%BD%E6%95%B0%E5%BC%8F%E7%BC%96%E7%A8%8B%E5%85%A5%E9%97%A8/>转载：Java8函数式编程入门</a></li><li><a href=/post/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%8A%80%E6%9C%AF/%E8%BD%AC%E8%BD%BDjava%E6%B3%A8%E8%A7%A3annotation/>转载：Java Annotation认知</a></li></ul></li><li><a href=https://ole12138.gitee.io//categories/spring><span class=doc-list-category>Spring</span></a><ul><li><a href=/post/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%8A%80%E6%9C%AF/springboot%E6%9E%84%E5%BB%BArestfulwebservice/>Spring构建restfulWebService</a></li></ul></li><li><a href=https://ole12138.gitee.io//categories/%E5%89%8D%E5%90%8E%E7%AB%AF%E5%88%86%E7%A6%BB><span class=doc-list-category>前后端分离</span></a><ul><li><a href=/post/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%8A%80%E6%9C%AF/%E8%BD%AC%E8%BD%BDweb%E5%89%8D%E5%90%8E%E7%AB%AF%E5%88%86%E7%A6%BB%E7%9A%84%E5%AE%9E%E7%8E%B0%E6%96%B9%E5%BC%8F/>Web前后端分离的实现方式</a></li></ul></li><li><a href=https://ole12138.gitee.io//categories/%E5%B7%A5%E5%85%B7><span class=doc-list-category>工具</span></a><ul><li><a href=/post/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%8A%80%E6%9C%AF/%E8%BD%AC%E8%BD%BDmaven%E4%BD%BF%E7%94%A8/>转载：Maven pom.xml中的元素modules、parent、properties以及import</a></li></ul></li><li><a href=https://ole12138.gitee.io//categories/%E6%95%B0%E5%AD%A6><span class=doc-list-category>数学</span></a><ul><li><a href=/post/%E6%95%B0%E5%AD%A6%E6%80%BB%E7%BB%93/%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1-%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1-%E5%81%87%E8%AE%BE%E6%A3%80%E9%AA%8C/>概率论与数理统计-数理统计-假设检验</a></li><li><span class=active>概率论与数理统计-数理统计-参数估计</span></li><li><a href=/post/%E6%95%B0%E5%AD%A6%E6%80%BB%E7%BB%93/%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1-%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1-%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/>概率论与数理统计-数理统计-基本概念</a></li><li><a href=/post/%E6%95%B0%E5%AD%A6%E6%80%BB%E7%BB%93/%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1-%E6%A6%82%E7%8E%87%E8%AE%BA-%E5%A4%A7%E6%95%B0%E5%AE%9A%E5%BE%8B%E4%B8%8E%E4%B8%AD%E5%BF%83%E6%9E%81%E9%99%90%E5%AE%9A%E7%90%86/>概率论与数理统计-概率论-大数定律与中心极限定理</a></li><li><a href=/post/%E6%95%B0%E5%AD%A6%E6%80%BB%E7%BB%93/%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1-%E6%A6%82%E7%8E%87%E8%AE%BA-%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E7%9A%84%E6%95%B0%E5%AD%97%E7%89%B9%E5%BE%81/>概率论与数理统计-概率论-随机变量的数字特征</a></li><li><a href=/post/%E6%95%B0%E5%AD%A6%E6%80%BB%E7%BB%93/%E6%95%B0%E5%AD%A6%E5%88%86%E6%94%AF%E7%9A%84%E6%80%BB%E7%BB%93/>数学分支的总结</a></li><li><a href=/post/%E6%95%B0%E5%AD%A6%E6%80%BB%E7%BB%93/%E6%95%B0%E5%AD%A6%E7%89%A9%E7%90%86%E6%96%B9%E6%B3%95%E6%80%BB%E7%BB%93/>数学物理方法总结</a></li><li><a href=/post/%E6%95%B0%E5%AD%A6%E6%80%BB%E7%BB%93/%E6%9C%80%E4%BC%98%E5%8C%96%E9%97%AE%E9%A2%98%E6%80%BB%E7%BB%93/>最优化问题总结</a></li><li><a href=/post/%E6%95%B0%E5%AD%A6%E6%80%BB%E7%BB%93/%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1-%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1-%E6%96%B9%E5%B7%AE%E5%88%86%E6%9E%90%E4%B8%8E%E5%9B%9E%E5%BD%92%E5%88%86%E6%9E%90/>概率论与数理统计-数理统计-方差分析与回归分析</a></li><li><a href=/post/%E6%95%B0%E5%AD%A6%E6%80%BB%E7%BB%93/%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1-%E6%A6%82%E7%8E%87%E8%AE%BA-%E9%9A%8F%E6%9C%BA%E4%BA%8B%E4%BB%B6%E4%B8%8E%E6%A6%82%E7%8E%87/>概率论与数理统计-概率论-随机事件与概率</a></li><li><a href=/post/%E6%95%B0%E5%AD%A6%E6%80%BB%E7%BB%93/%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1-%E6%A6%82%E7%8E%87%E8%AE%BA-%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E5%8F%8A%E5%85%B6%E6%A6%82%E7%8E%87%E5%88%86%E5%B8%83/>概率论与数理统计-概率论-随机变量及其分布</a></li><li><a href=/post/%E6%95%B0%E5%AD%A6%E6%80%BB%E7%BB%93/%E6%B3%9B%E5%87%BD%E5%88%86%E6%9E%90%E6%80%BB%E7%BB%93/>泛函分析</a></li><li><a href=/post/%E6%95%B0%E5%AD%A6%E6%80%BB%E7%BB%93/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0-%E7%9B%B8%E4%BC%BC%E7%9F%A9%E9%98%B5%E4%B8%8E%E4%BA%8C%E6%AC%A1%E5%9E%8B/>线性代数-相似矩阵与二次型</a></li><li><a href=/post/%E6%95%B0%E5%AD%A6%E6%80%BB%E7%BB%93/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0-%E7%9B%B8%E4%BC%BC%E7%9F%A9%E9%98%B5%E4%B8%8E%E4%BA%8C%E6%AC%A1%E5%9E%8B%E4%B9%A0%E9%A2%98/>线性代数-相似矩阵与二次型习题</a></li><li><a href=/post/%E6%95%B0%E5%AD%A6%E6%80%BB%E7%BB%93/%E9%AB%98%E7%AD%89%E6%95%B0%E5%AD%A6-%E7%BA%A7%E6%95%B0/>高等数学-级数</a></li><li><a href=/post/%E6%95%B0%E5%AD%A6%E6%80%BB%E7%BB%93/%E9%AB%98%E7%AD%89%E6%95%B0%E5%AD%A6-%E7%BA%A7%E6%95%B0%E4%B9%A0%E9%A2%98/>高等数学-级数习题</a></li><li><a href=/post/%E6%95%B0%E5%AD%A6%E6%80%BB%E7%BB%93/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0-%E5%90%91%E9%87%8F%E7%BB%84%E7%9A%84%E7%BA%BF%E6%80%A7%E7%9B%B8%E5%85%B3%E6%80%A7/>线性代数-向量组的线性相关性</a></li><li><a href=/post/%E6%95%B0%E5%AD%A6%E6%80%BB%E7%BB%93/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0-%E5%90%91%E9%87%8F%E7%BB%84%E7%9A%84%E7%BA%BF%E6%80%A7%E7%9B%B8%E5%85%B3%E6%80%A7%E4%B9%A0%E9%A2%98/>线性代数-向量组的线性相关性习题</a></li><li><a href=/post/%E6%95%B0%E5%AD%A6%E6%80%BB%E7%BB%93/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0-%E7%9F%A9%E9%98%B52%E7%9F%A9%E9%98%B5%E5%88%9D%E7%AD%89%E5%8F%98%E6%8D%A2%E4%B8%8E%E7%BA%BF%E6%80%A7%E6%96%B9%E7%A8%8B%E7%BB%84%E4%B9%A0%E9%A2%98/>线性代数-矩阵初等变换与线性方程组习题</a></li><li><a href=/post/%E6%95%B0%E5%AD%A6%E6%80%BB%E7%BB%93/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0-%E7%9F%A9%E9%98%B52%E7%9F%A9%E9%98%B5%E5%88%9D%E7%AD%89%E5%8F%98%E6%8D%A2%E4%B8%8E%E7%BA%BF%E6%80%A7%E6%96%B9%E7%A8%8B%E7%BB%84/>线性代数-矩阵初等变换与线性方程组习题</a></li><li><a href=/post/%E6%95%B0%E5%AD%A6%E6%80%BB%E7%BB%93/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0-%E7%9F%A9%E9%98%B51/>线性代数-矩阵1</a></li><li><a href=/post/%E6%95%B0%E5%AD%A6%E6%80%BB%E7%BB%93/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0-%E7%9F%A9%E9%98%B51%E4%B9%A0%E9%A2%98/>线性代数-矩阵1习题</a></li><li><a href=/post/%E6%95%B0%E5%AD%A6%E6%80%BB%E7%BB%93/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0-%E8%A1%8C%E5%88%97%E5%BC%8F/>线性代数-行列式</a></li><li><a href=/post/%E6%95%B0%E5%AD%A6%E6%80%BB%E7%BB%93/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0-%E8%A1%8C%E5%88%97%E5%BC%8F%E4%B9%A0%E9%A2%98/>线性代数-行列式习题</a></li><li><a href=/post/%E6%95%B0%E5%AD%A6%E6%80%BB%E7%BB%93/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E6%80%BB%E7%BB%93/>线性代数总结</a></li><li><a href=/post/%E6%95%B0%E5%AD%A6%E6%80%BB%E7%BB%93/%E9%AB%98%E7%AD%89%E6%95%B0%E5%AD%A6-%E5%A4%9A%E5%85%83%E5%BE%AE%E7%A7%AF%E5%88%86-%E5%A4%9A%E5%85%83%E7%A7%AF%E5%88%86%E5%AD%A6-%E6%9B%B2%E7%BA%BF%E7%A7%AF%E5%88%86%E4%B8%8E%E6%9B%B2%E9%9D%A2%E7%A7%AF%E5%88%86%E4%B9%A0%E9%A2%98/>高等数学-多元微积分-曲线积分与曲面积分习题</a></li><li><a href=/post/%E6%95%B0%E5%AD%A6%E6%80%BB%E7%BB%93/%E9%AB%98%E7%AD%89%E6%95%B0%E5%AD%A6-%E5%A4%9A%E5%85%83%E5%BE%AE%E7%A7%AF%E5%88%86-%E5%A4%9A%E5%85%83%E7%A7%AF%E5%88%86%E5%AD%A6-%E6%9B%B2%E7%BA%BF%E7%A7%AF%E5%88%86%E4%B8%8E%E6%9B%B2%E9%9D%A2%E7%A7%AF%E5%88%86/>高等数学-多元微积分-曲线积分与曲面积分</a></li><li><a href=/post/%E6%95%B0%E5%AD%A6%E6%80%BB%E7%BB%93/%E9%AB%98%E7%AD%89%E6%95%B0%E5%AD%A6-%E5%A4%9A%E5%85%83%E5%BE%AE%E7%A7%AF%E5%88%86-%E5%A4%9A%E5%85%83%E7%A7%AF%E5%88%86%E5%AD%A6-%E9%87%8D%E7%A7%AF%E5%88%86%E4%B9%A0%E9%A2%98/>高等数学-多元积分学-重积分习题</a></li><li><a href=/post/%E6%95%B0%E5%AD%A6%E6%80%BB%E7%BB%93/%E9%AB%98%E7%AD%89%E6%95%B0%E5%AD%A6-%E5%A4%9A%E5%85%83%E5%BE%AE%E7%A7%AF%E5%88%86-%E5%A4%9A%E5%85%83%E7%A7%AF%E5%88%86%E5%AD%A6-%E9%87%8D%E7%A7%AF%E5%88%86/>高等数学-多元积分学-重积分</a></li><li><a href=/post/%E6%95%B0%E5%AD%A6%E6%80%BB%E7%BB%93/%E9%AB%98%E7%AD%89%E6%95%B0%E5%AD%A6-%E5%A4%9A%E5%85%83%E5%BE%AE%E7%A7%AF%E5%88%86-%E5%A4%9A%E5%85%83%E5%BE%AE%E5%88%86%E5%AD%A6%E4%B9%A0%E9%A2%98/>高等数学-多元微分学习题</a></li><li><a href=/post/%E6%95%B0%E5%AD%A6%E6%80%BB%E7%BB%93/%E9%AB%98%E7%AD%89%E6%95%B0%E5%AD%A6-%E5%A4%9A%E5%85%83%E5%BE%AE%E7%A7%AF%E5%88%86-%E5%A4%9A%E5%85%83%E5%BE%AE%E5%88%86%E5%AD%A6-%E5%87%A0%E4%BD%95%E5%BA%94%E7%94%A8%E5%90%91%E9%87%8F%E5%80%BC%E5%87%BD%E6%95%B0%E4%B8%8E%E5%90%91%E9%87%8F%E5%88%86%E6%9E%90/>高等数学-多元微积分-多元微分学-向量值函数和向量分析</a></li><li><a href=/post/%E6%95%B0%E5%AD%A6%E6%80%BB%E7%BB%93/%E9%AB%98%E7%AD%89%E6%95%B0%E5%AD%A6-%E5%A4%9A%E5%85%83%E5%BE%AE%E7%A7%AF%E5%88%86-%E5%A4%9A%E5%85%83%E5%BE%AE%E5%88%86%E5%AD%A6-%E4%BB%A3%E6%95%B0%E5%BA%94%E7%94%A8%E6%9E%81%E5%80%BC%E4%B8%8E%E6%9C%80%E5%80%BC/>高等数学-多元微分学-代数应用：多元函数的极值</a></li><li><a href=/post/%E6%95%B0%E5%AD%A6%E6%80%BB%E7%BB%93/%E9%AB%98%E7%AD%89%E6%95%B0%E5%AD%A6-%E5%A4%9A%E5%85%83%E5%BE%AE%E7%A7%AF%E5%88%86-%E5%A4%9A%E5%85%83%E5%BE%AE%E5%88%86%E5%AD%A6-%E6%A6%82%E5%BF%B5%E4%B8%8E%E6%80%A7%E8%B4%A8/>高等数学-多元微分学</a></li><li><a href=/post/%E6%95%B0%E5%AD%A6%E6%80%BB%E7%BB%93/%E9%AB%98%E7%AD%89%E6%95%B0%E5%AD%A6-%E5%A4%9A%E5%85%83%E5%BE%AE%E7%A7%AF%E5%88%86-%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%8C%83%E5%9B%B4/>高等数学-多元微积分概述</a></li><li><a href=/post/%E6%95%B0%E5%AD%A6%E6%80%BB%E7%BB%93/%E9%AB%98%E7%AD%89%E6%95%B0%E5%AD%A6-%E5%90%91%E9%87%8F%E4%BB%A3%E6%95%B0%E4%B8%8E%E7%A9%BA%E9%97%B4%E8%A7%A3%E6%9E%90%E5%87%A0%E4%BD%95/>高等数学-向量代数与空间解析几何</a></li><li><a href=/post/%E6%95%B0%E5%AD%A6%E6%80%BB%E7%BB%93/%E9%AB%98%E7%AD%89%E6%95%B0%E5%AD%A6-%E5%90%91%E9%87%8F%E4%BB%A3%E6%95%B0%E4%B8%8E%E7%A9%BA%E9%97%B4%E8%A7%A3%E6%9E%90%E5%87%A0%E4%BD%95%E4%B9%A0%E9%A2%98/>高等数学-向量代数与空间解析几何习题</a></li><li><a href=/post/%E6%95%B0%E5%AD%A6%E6%80%BB%E7%BB%93/%E9%AB%98%E7%AD%89%E6%95%B0%E5%AD%A6-%E5%BE%AE%E5%88%86%E6%96%B9%E7%A8%8B/>高等数学-微分方程</a></li><li><a href=/post/%E6%95%B0%E5%AD%A6%E6%80%BB%E7%BB%93/%E9%AB%98%E7%AD%89%E6%95%B0%E5%AD%A6-%E5%BE%AE%E5%88%86%E6%96%B9%E7%A8%8B%E4%B9%A0%E9%A2%98/>高等数学-微分方程习题</a></li><li><a href=/post/%E6%95%B0%E5%AD%A6%E6%80%BB%E7%BB%93/%E9%AB%98%E7%AD%89%E6%95%B0%E5%AD%A6-%E4%B8%80%E5%85%83%E5%BE%AE%E7%A7%AF%E5%88%86-%E4%B8%80%E5%85%83%E7%A7%AF%E5%88%86%E5%AD%A6-%E5%AE%9A%E7%A7%AF%E5%88%86%E7%9A%84%E5%BA%94%E7%94%A8/>高等数学-一元积分学-定积分的应用</a></li><li><a href=/post/%E6%95%B0%E5%AD%A6%E6%80%BB%E7%BB%93/%E9%AB%98%E7%AD%89%E6%95%B0%E5%AD%A6-%E4%B8%80%E5%85%83%E5%BE%AE%E7%A7%AF%E5%88%86-%E4%B8%80%E5%85%83%E7%A7%AF%E5%88%86%E5%AD%A6-%E5%AE%9A%E7%A7%AF%E5%88%86%E7%9A%84%E5%BA%94%E7%94%A8%E4%B9%A0%E9%A2%98/>高等数学-一元积分学-定积分的应用</a></li><li><a href=/post/%E6%95%B0%E5%AD%A6%E6%80%BB%E7%BB%93/%E9%AB%98%E7%AD%89%E6%95%B0%E5%AD%A6-%E4%B8%80%E5%85%83%E5%BE%AE%E7%A7%AF%E5%88%86-%E4%B8%80%E5%85%83%E7%A7%AF%E5%88%86%E5%AD%A6-%E5%AE%9A%E7%A7%AF%E5%88%86%E4%B8%8E%E5%B9%BF%E4%B9%89%E7%A7%AF%E5%88%86/>高等数学-一元积分学-定积分与反常积分</a></li><li><a href=/post/%E6%95%B0%E5%AD%A6%E6%80%BB%E7%BB%93/%E9%AB%98%E7%AD%89%E6%95%B0%E5%AD%A6-%E4%B8%80%E5%85%83%E5%BE%AE%E7%A7%AF%E5%88%86-%E4%B8%80%E5%85%83%E7%A7%AF%E5%88%86%E5%AD%A6-%E5%AE%9A%E7%A7%AF%E5%88%86%E4%B8%8E%E5%B9%BF%E4%B9%89%E7%A7%AF%E5%88%86%E4%B9%A0%E9%A2%98/>高等数学-一元积分学-定积分与反常积分</a></li><li><a href=/post/%E6%95%B0%E5%AD%A6%E6%80%BB%E7%BB%93/%E9%AB%98%E7%AD%89%E6%95%B0%E5%AD%A6-%E4%B8%80%E5%85%83%E5%BE%AE%E7%A7%AF%E5%88%86-%E4%B8%80%E5%85%83%E7%A7%AF%E5%88%86%E5%AD%A6-%E4%B8%8D%E5%AE%9A%E7%A7%AF%E5%88%86/>高等数学-一元积分学-不定积分</a></li><li><a href=/post/%E6%95%B0%E5%AD%A6%E6%80%BB%E7%BB%93/%E9%AB%98%E7%AD%89%E6%95%B0%E5%AD%A6-%E4%B8%80%E5%85%83%E5%BE%AE%E7%A7%AF%E5%88%86-%E4%B8%80%E5%85%83%E7%A7%AF%E5%88%86%E5%AD%A6-%E4%B8%8D%E5%AE%9A%E7%A7%AF%E5%88%86%E4%B9%A0%E9%A2%98/>高等数学-一元积分学-不定积分</a></li><li><a href=/post/%E6%95%B0%E5%AD%A6%E6%80%BB%E7%BB%93/%E9%AB%98%E7%AD%89%E6%95%B0%E5%AD%A6-%E4%B8%80%E5%85%83%E5%BE%AE%E7%A7%AF%E5%88%86-%E4%B8%80%E5%85%83%E5%BE%AE%E5%88%86%E5%AD%A6-%E5%BA%94%E7%94%A8-%E5%BC%A7%E5%BE%AE%E5%88%86%E4%B8%8E%E6%9B%B2%E7%8E%87%E4%B9%A0%E9%A2%98/>高等数学-一元微分学-一元微分学的应用-弧微分与曲率</a></li><li><a href=/post/%E6%95%B0%E5%AD%A6%E6%80%BB%E7%BB%93/%E9%AB%98%E7%AD%89%E6%95%B0%E5%AD%A6-%E4%B8%80%E5%85%83%E5%BE%AE%E7%A7%AF%E5%88%86-%E4%B8%80%E5%85%83%E5%BE%AE%E5%88%86%E5%AD%A6-%E5%BA%94%E7%94%A8-%E5%BC%A7%E5%BE%AE%E5%88%86%E4%B8%8E%E6%9B%B2%E7%8E%87/>高等数学-一元微分学-导数的应用</a></li><li><a href=/post/%E6%95%B0%E5%AD%A6%E6%80%BB%E7%BB%93/%E9%AB%98%E7%AD%89%E6%95%B0%E5%AD%A6-%E4%B8%80%E5%85%83%E5%BE%AE%E7%A7%AF%E5%88%86-%E4%B8%80%E5%85%83%E5%BE%AE%E5%88%86%E5%AD%A6-%E5%AF%BC%E6%95%B0%E4%B8%8E%E5%BE%AE%E5%88%86%E4%B9%A0%E9%A2%98/>高等数学-一元函数微分学-单调性与极值</a></li><li><a href=/post/%E6%95%B0%E5%AD%A6%E6%80%BB%E7%BB%93/%E9%AB%98%E7%AD%89%E6%95%B0%E5%AD%A6-%E4%B8%80%E5%85%83%E5%BE%AE%E7%A7%AF%E5%88%86-%E4%B8%80%E5%85%83%E5%BE%AE%E5%88%86%E5%AD%A6-%E5%BA%94%E7%94%A8-%E5%8D%95%E8%B0%83%E6%80%A7%E4%B8%8E%E6%9E%81%E5%80%BC/>高等数学-一元函数微分学-单调性与极值</a></li><li><a href=/post/%E6%95%B0%E5%AD%A6%E6%80%BB%E7%BB%93/%E9%AB%98%E7%AD%89%E6%95%B0%E5%AD%A6-%E4%B8%80%E5%85%83%E5%BE%AE%E7%A7%AF%E5%88%86-%E4%B8%80%E5%85%83%E5%BE%AE%E5%88%86%E5%AD%A6-%E5%BA%94%E7%94%A8-%E4%B8%AD%E5%80%BC%E5%AE%9A%E7%90%86/>高等数学-一元微分学-可导函数的中值定理</a></li><li><a href=/post/%E6%95%B0%E5%AD%A6%E6%80%BB%E7%BB%93/%E9%AB%98%E7%AD%89%E6%95%B0%E5%AD%A6-%E4%B8%80%E5%85%83%E5%BE%AE%E7%A7%AF%E5%88%86-%E4%B8%80%E5%85%83%E5%BE%AE%E5%88%86%E5%AD%A6-%E5%BA%94%E7%94%A8-%E4%B8%AD%E5%80%BC%E5%AE%9A%E7%90%86%E4%B9%A0%E9%A2%98/>高等数学-一元微分学-可导函数的中值定理习题</a></li><li><a href=/post/%E6%95%B0%E5%AD%A6%E6%80%BB%E7%BB%93/%E9%AB%98%E7%AD%89%E6%95%B0%E5%AD%A6-%E4%B8%80%E5%85%83%E5%BE%AE%E7%A7%AF%E5%88%86-%E4%B8%80%E5%85%83%E5%BE%AE%E5%88%86%E5%AD%A6-%E5%BA%94%E7%94%A8-%E5%8D%95%E8%B0%83%E6%80%A7%E4%B8%8E%E6%9E%81%E5%80%BC%E4%B9%A0%E9%A2%98/>高等数学-一元微分学-导数的应用-单调性与极值</a></li><li><a href=/post/%E6%95%B0%E5%AD%A6%E6%80%BB%E7%BB%93/%E9%AB%98%E7%AD%89%E6%95%B0%E5%AD%A6-%E4%B8%80%E5%85%83%E5%BE%AE%E7%A7%AF%E5%88%86-%E4%B8%80%E5%85%83%E5%BE%AE%E5%88%86%E5%AD%A6-%E5%AF%BC%E6%95%B0%E5%92%8C%E5%BE%AE%E5%88%86/>高等数学-一元微分学-导数和微分</a></li><li><a href=/post/%E6%95%B0%E5%AD%A6%E6%80%BB%E7%BB%93/%E9%AB%98%E7%AD%89%E6%95%B0%E5%AD%A6-%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5-%E5%87%BD%E6%95%B0%E4%B8%8E%E6%9E%81%E9%99%90/>高等数学-基础概念-函数与极限</a></li><li><a href=/post/%E6%95%B0%E5%AD%A6%E6%80%BB%E7%BB%93/%E9%AB%98%E7%AD%89%E6%95%B0%E5%AD%A6-%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5-%E5%87%BD%E6%95%B0%E4%B8%8E%E6%9E%81%E9%99%90%E4%B9%A0%E9%A2%98/>高等数学-基础概念-函数与极限习题</a></li><li><a href=/post/%E6%95%B0%E5%AD%A6%E6%80%BB%E7%BB%93/%E9%AB%98%E7%AD%89%E6%95%B0%E5%AD%A6-%E4%B8%80%E5%85%83%E5%BE%AE%E7%A7%AF%E5%88%86-%E8%84%89%E7%BB%9C/>高等数学-一元微积分-脉络</a></li><li><a href=/post/%E6%95%B0%E5%AD%A6%E6%80%BB%E7%BB%93/%E6%95%B0%E5%AD%A6%E5%88%86%E6%9E%90%E5%92%8C%E9%AB%98%E7%AD%89%E6%95%B0%E5%AD%A6%E6%80%BB%E7%BB%93/>高等数学与数学分析</a></li><li><a href=/post/%E6%95%B0%E5%AD%A6%E6%80%BB%E7%BB%93/%E5%9F%BA%E7%A1%80%E6%95%B0%E5%AD%A6-%E4%B8%89%E8%A7%92%E5%87%BD%E6%95%B0/>基础数学-三角函数</a></li><li><a href=/post/%E6%95%B0%E5%AD%A6%E6%80%BB%E7%BB%93/%E5%9F%BA%E7%A1%80%E6%95%B0%E5%AD%A6-%E4%BB%A3%E6%95%B0/>基础数学-代数</a></li><li><a href=/post/%E6%95%B0%E5%AD%A6%E6%80%BB%E7%BB%93/%E5%9F%BA%E7%A1%80%E6%95%B0%E5%AD%A6-%E5%87%A0%E4%BD%95/>基础数学-几何</a></li></ul></li><li><a href=https://ole12138.gitee.io//categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95><span class=doc-list-category>数据结构与算法</span></a><ul><li><a href=/post/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%E6%80%BB%E7%BB%93/pat%E4%B9%A0%E9%A2%98/>PAT甲级习题</a></li><li><a href=/post/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%E6%80%BB%E7%BB%93/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E6%A0%88%E5%92%8C%E9%98%9F%E5%88%97%E4%BB%A5%E5%8F%8A%E6%95%B0%E7%BB%84/>数据结构-栈和队列</a></li><li><a href=/post/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%E6%80%BB%E7%BB%93/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E7%BA%BF%E6%80%A7%E8%A1%A8/>数据结构-线性表</a></li><li><a href=/post/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%E6%80%BB%E7%BB%93/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%92%8C%E7%AE%97%E6%B3%95%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/>数据结构与算法的基本概念</a></li><li><a href=/post/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%E6%80%BB%E7%BB%93/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E6%80%BB%E7%BB%93/>数据结构总结</a></li><li><a href=/post/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%E6%80%BB%E7%BB%93/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E6%A0%91%E5%92%8C%E4%BA%8C%E5%8F%89%E6%A0%91/>树和二叉树</a></li><li><a href=/post/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%E6%80%BB%E7%BB%93/%E7%AE%97%E6%B3%95%E6%80%BB%E7%BB%93/>算法总结</a></li></ul></li><li><a href=https://ole12138.gitee.io//categories/%E7%89%A9%E7%90%86><span class=doc-list-category>物理</span></a><ul><li><a href=/post/%E6%95%B0%E5%AD%A6%E6%80%BB%E7%BB%93/%E6%95%B0%E5%AD%A6%E7%89%A9%E7%90%86%E6%96%B9%E6%B3%95%E6%80%BB%E7%BB%93/>数学物理方法总结</a></li></ul></li><li><a href=https://ole12138.gitee.io//categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%8A%80%E6%9C%AF><span class=doc-list-category>计算机技术</span></a><ul><li><a href=/post/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%8A%80%E6%9C%AF/java%E5%BC%80%E5%8F%91%E6%8A%80%E8%83%BD%E9%9C%80%E6%B1%82%E4%B8%8E%E5%AD%A6%E4%B9%A0/>Java开发技能需求</a></li></ul></li></ul></div><div class=sidebar-module><h4 class=sidebar-heading>Tags</h4><div class=tag-box><a class=tag-item href=https://ole12138.gitee.io//tags/annotation>annotation</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/http>http</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/http1.1>http1.1</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/http2>http2</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/java>java</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/java%E5%AE%9E%E7%8E%B0http%E8%AF%B7%E6%B1%82>java实现http请求</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/java%E6%9E%84%E5%BB%BA%E5%B7%A5%E5%85%B7>java构建工具</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/java%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F>java设计模式</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/jdk%E4%BB%A3%E7%90%86>jdk代理</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/maven>maven</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/np%E5%AE%8C%E5%A4%87%E7%90%86%E8%AE%BA>np完备理论</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/n%E7%BB%B4%E6%AD%A3%E6%80%81%E5%88%86%E5%B8%83>n维正态分布</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/pat>pat</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/restfulwebservice>restfulwebservice</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/resttemplate>resttemplate</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/spring>spring</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/springboot>springboot</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E4%B8%80%E5%85%83%E5%BE%AE%E5%88%86%E5%AD%A6>一元微分学</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E4%B8%80%E5%85%83%E5%BE%AE%E7%A7%AF%E5%88%86>一元微积分</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E4%B8%80%E5%85%83%E7%A7%AF%E5%88%86%E5%AD%A6>一元积分学</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E4%B8%89%E8%A7%92%E5%87%BD%E6%95%B0>三角函数</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E4%B8%89%E8%A7%92%E7%BA%A7%E6%95%B0>三角级数</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E4%B8%8D%E5%AE%9A%E7%A7%AF%E5%88%86>不定积分</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E4%B8%AD%E5%BF%83%E6%9E%81%E9%99%90%E5%AE%9A%E7%90%86>中心极限定理</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E4%B9%A0%E9%A2%98>习题</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E4%BA%8C%E5%8F%89%E6%8E%92%E5%BA%8F%E6%A0%91>二叉排序树</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E4%BA%8C%E5%8F%89%E6%A0%91>二叉树</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E4%BA%8C%E5%8F%89%E6%A0%91%E7%9A%84%E9%81%8D%E5%8E%86>二叉树的遍历</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E4%BA%8C%E6%AC%A1%E5%9E%8B>二次型</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E4%BA%8C%E6%AC%A1%E5%9E%8B%E5%8C%96%E4%B8%BA%E6%A0%87%E5%87%86%E5%9E%8B>二次型化为标准型</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E4%BB%A3%E6%95%B0>代数</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E4%BB%A3%E6%95%B0%E5%BA%94%E7%94%A8>代数应用</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E4%BB%A3%E7%90%86%E6%A8%A1%E5%BC%8F>代理模式</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E4%BC%BD%E9%A9%AC%E5%87%BD%E6%95%B0>伽马函数</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E4%BE%9D%E8%B5%96%E7%AE%A1%E7%90%86>依赖管理</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E5%81%87%E8%AE%BE%E6%A3%80%E9%AA%8C>假设检验</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E5%82%85%E9%87%8C%E5%8F%B6%E5%8F%98%E6%8D%A2>傅里叶变换</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E5%82%85%E9%87%8C%E5%8F%B6%E7%BA%A7%E6%95%B0>傅里叶级数</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E5%85%8B%E6%8B%89%E9%BB%98%E6%B3%95%E5%88%99>克拉默法则</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E5%85%B3%E9%97%AD%E8%B5%84%E6%BA%90>关闭资源</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E5%87%A0%E4%BD%95>几何</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E5%87%BD%E6%95%B0>函数</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E5%87%BD%E6%95%B0%E5%BC%8F%E7%BC%96%E7%A8%8B>函数式编程</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E5%87%BD%E6%95%B0%E6%9E%81%E9%99%90%E7%90%86%E8%AE%BA>函数极限理论</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E5%87%BD%E6%95%B0%E7%A9%BA%E9%97%B4>函数空间</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E5%87%BD%E6%95%B0%E9%A1%B9%E7%BA%A7%E6%95%B0>函数项级数</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E5%88%86%E5%9D%97%E7%9F%A9%E9%98%B5>分块矩阵</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E5%88%86%E5%B8%83%E7%B1%BB%E5%9E%8B%E7%9A%84%E5%81%87%E8%AE%BE>分布类型的假设</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E5%88%86%E7%B1%BB>分类</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E5%88%87%E6%AF%94%E9%9B%AA%E5%A4%AB%E4%B8%8D%E7%AD%89%E5%BC%8F>切比雪夫不等式</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E5%89%8D%E5%90%8E%E7%AB%AF%E5%88%86%E7%A6%BB>前后端分离</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92>动态规划</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92%E7%9A%84%E6%80%9D%E6%83%B3>动态规划的思想</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E5%8C%BA%E9%97%B4%E4%BC%B0%E8%AE%A1>区间估计</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E5%8D%8F%E6%96%B9%E5%B7%AE>协方差</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E5%8D%8F%E6%96%B9%E5%B7%AE%E7%9F%A9%E9%98%B5>协方差矩阵</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E5%8D%95%E8%B0%83%E6%80%A7>单调性</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1>参数估计</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E5%8F%82%E6%95%B0%E7%9A%84%E5%81%87%E8%AE%BE%E6%A3%80%E9%AA%8C>参数的假设检验</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E5%8F%8C%E7%AB%AF%E9%98%9F%E5%88%97>双端队列</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E5%8F%8D%E5%B0%84>反射</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E5%8F%8D%E5%B8%B8%E7%A7%AF%E5%88%86>反常积分</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E5%8F%AF%E5%AF%BC%E5%87%BD%E6%95%B0%E7%9A%84%E4%B8%AD%E5%80%BC%E5%AE%9A%E7%90%86>可导函数的中值定理</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E5%90%91%E9%87%8F>向量</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E5%90%91%E9%87%8F%E4%BB%A3%E6%95%B0>向量代数</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E5%90%91%E9%87%8F%E5%80%BC%E5%87%BD%E6%95%B0>向量值函数</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E5%90%91%E9%87%8F%E5%86%85%E7%A7%AF>向量内积</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E5%90%91%E9%87%8F%E5%88%86%E6%9E%90>向量分析</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E5%90%91%E9%87%8F%E7%9A%84%E6%AD%A3%E4%BA%A4%E6%80%A7>向量的正交性</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E5%90%91%E9%87%8F%E7%A9%BA%E9%97%B4>向量空间</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E5%90%91%E9%87%8F%E7%BB%84>向量组</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E5%90%91%E9%87%8F%E7%BB%84%E7%9A%84%E7%A7%A9>向量组的秩</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E5%90%91%E9%87%8F%E7%BB%84%E7%9A%84%E7%BA%BF%E6%80%A7%E7%9B%B8%E5%85%B3%E6%80%A7>向量组的线性相关性</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E5%90%91%E9%87%8F%E7%BB%84%E7%9A%84%E7%BA%BF%E6%80%A7%E7%BB%84%E5%90%88>向量组的线性组合</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E5%90%91%E9%87%8F%E9%95%BF%E5%BA%A6>向量长度</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E5%93%88%E5%A4%AB%E6%9B%BC%E6%A0%91>哈夫曼树</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E5%9B%9E%E5%BD%92%E5%88%86%E6%9E%90>回归分析</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E5%9B%BE>图</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E5%9B%BE%E7%9A%84%E9%81%8D%E5%8E%86>图的遍历</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E5%9C%A8%E5%8F%8D%E5%B0%84%E4%B8%AD%E4%BD%BF%E7%94%A8annotation>在反射中使用annotation</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E5%9D%87%E5%80%BC>均值</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E5%9F%BA%E7%A1%80%E6%95%B0%E5%AD%A6>基础数学</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E5%A4%8D%E6%95%B0%E9%A1%B9%E7%BA%A7%E6%95%B0>复数项级数</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E5%A4%9A%E5%85%83%E5%87%BD%E6%95%B0%E7%9A%84%E6%9E%81%E5%80%BC%E4%B8%8E%E6%9C%80%E5%80%BC>多元函数的极值与最值</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E5%A4%9A%E5%85%83%E5%BE%AE%E5%88%86%E5%AD%A6>多元微分学</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E5%A4%9A%E5%85%83%E5%BE%AE%E7%A7%AF%E5%88%86>多元微积分</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E5%A4%9A%E5%85%83%E7%A7%AF%E5%88%86%E5%AD%A6>多元积分学</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E5%A4%A7%E6%95%B0%E5%AE%9A%E5%BE%8B>大数定律</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E5%AE%9A%E7%A7%AF%E5%88%86>定积分</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E5%AE%9A%E7%A7%AF%E5%88%86%E7%9A%84%E5%BA%94%E7%94%A8>定积分的应用</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E5%AF%B9%E7%A7%B0%E7%9F%A9%E9%98%B5%E5%AF%B9%E8%A7%92%E5%8C%96>对称矩阵对角化</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E5%AF%BC%E6%95%B0>导数</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E5%AF%BC%E6%95%B0%E7%9A%84%E5%BA%94%E7%94%A8>导数的应用</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E5%B8%B8%E6%95%B0%E9%A1%B9%E7%BA%A7%E6%95%B0>常数项级数</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E5%B9%82%E7%BA%A7%E6%95%B0>幂级数</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E5%B9%B3%E8%A1%A1%E4%BA%8C%E5%8F%89%E6%A0%91>平衡二叉树</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E5%B9%B6%E6%9F%A5%E9%9B%86>并查集</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E5%BC%A7%E5%BE%AE%E5%88%86>弧微分</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E5%BE%AE%E5%88%86>微分</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E5%BE%AE%E5%88%86%E6%96%B9%E7%A8%8B>微分方程</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E6%80%BB%E4%BD%93%E4%B8%8E%E4%B8%AA%E4%BD%93>总体与个体</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E6%8A%BD%E6%A0%B7%E5%88%86%E5%B8%83>抽样分布</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E6%8E%92%E5%BA%8F>排序</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E6%95%A3%E5%88%97>散列</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E6%95%B0%E5%AD%A6>数学</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E6%95%B0%E5%AD%A6%E5%88%86%E6%94%AF>数学分支</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E6%95%B0%E5%AD%A6%E5%88%86%E6%9E%90>数学分析</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E6%95%B0%E5%AD%A6%E6%9C%9F%E6%9C%9B>数学期望</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5>数据结构的基本概念</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1>数理统计</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E6%95%B0%E7%BB%84>数组</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E6%95%B4%E6%95%B0%E4%BC%98%E5%8C%96>整数优化</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E6%96%B9%E5%B7%AE>方差</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E6%96%B9%E5%B7%AE%E5%88%86%E6%9E%90>方差分析</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E6%96%B9%E9%98%B5%E7%9A%84%E7%89%B9%E5%BE%81%E5%80%BC>方阵的特征值</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E6%96%B9%E9%98%B5%E7%9A%84%E7%89%B9%E5%BE%81%E5%90%91%E9%87%8F>方阵的特征向量</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E6%96%B9%E9%98%B5%E7%9A%84%E8%A1%8C%E5%88%97%E5%BC%8F>方阵的行列式</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E6%97%A0%E5%81%8F%E4%BC%B0%E8%AE%A1>无偏估计</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E6%98%A0%E5%B0%84>映射</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E6%9B%B2%E7%8E%87>曲率</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E6%9B%B2%E7%BA%BF%E7%A7%AF%E5%88%86>曲线积分</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E6%9B%B2%E9%9D%A2%E7%A7%AF%E5%88%86>曲面积分</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E6%9C%80%E4%BC%98%E5%8C%96%E9%97%AE%E9%A2%98>最优化问题</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E6%9C%80%E7%9F%AD%E8%B7%AF%E5%BE%84>最短路径</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E6%9C%89%E6%95%88%E4%BC%B0%E8%AE%A1>有效估计</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E6%9E%81%E5%80%BC>极值</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E6%9E%81%E9%99%90>极限</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E6%A0%87%E5%87%86%E5%9E%8B>标准型</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E6%A0%88>栈</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E6%A0%91>树</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E6%A0%91%E7%8A%B6%E6%95%B0%E7%BB%84>树状数组</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E6%A0%91%E7%9A%84%E9%81%8D%E5%8E%86>树的遍历</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E6%A0%B7%E6%9C%AC>样本</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E6%A3%AE%E6%9E%97%E4%B8%8E%E4%BA%8C%E5%8F%89%E6%A0%91%E7%9A%84%E8%BD%AC%E6%8D%A2>森林与二叉树的转换</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E6%A6%82%E5%BF%B5%E4%B8%8E%E6%80%A7%E8%B4%A8>概念与性质</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E6%A6%82%E7%8E%87%E8%AE%BA>概率论</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1>概率论与数理统计</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E6%A6%82%E8%BF%B0>概述</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E6%AD%A3%E5%AE%9A%E7%9F%A9%E9%98%B5>正定矩阵</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E6%B3%8A%E6%9D%BE%E7%A7%AF%E5%88%86>泊松积分</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E6%B3%8A%E6%9D%BE%E7%A7%AF%E5%88%86%E7%9A%84%E6%A6%82%E7%8E%87%E8%AE%BA%E5%BA%94%E7%94%A8>泊松积分的概率论应用</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E7%82%B9%E4%BC%B0%E8%AE%A1>点估计</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E7%89%A9%E7%90%86>物理</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E7%89%B9%E5%BE%81%E5%87%BD%E6%95%B0>特征函数</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E7%9B%B8%E4%BC%BC%E5%AF%B9%E8%A7%92%E5%8C%96>相似对角化</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E7%9B%B8%E4%BC%BC%E7%9F%A9%E9%98%B5>相似矩阵</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E7%9B%B8%E5%85%B3%E7%B3%BB%E6%95%B0>相关系数</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E7%9F%A9>矩</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E7%9F%A9%E9%98%B5>矩阵</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E7%9F%A9%E9%98%B5%E5%90%88%E5%90%8C>矩阵合同</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E7%9F%A9%E9%98%B5%E6%B1%82%E9%80%86>矩阵求逆</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E7%9F%A9%E9%98%B5%E7%9A%84%E5%88%9D%E7%AD%89%E5%8F%98%E6%8D%A2>矩阵的初等变换</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E7%9F%A9%E9%98%B5%E7%9A%84%E5%8E%8B%E7%BC%A9%E5%AD%98%E5%82%A8>矩阵的压缩存储</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E7%9F%A9%E9%98%B5%E7%9A%84%E7%A7%A9>矩阵的秩</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E7%9F%A9%E9%98%B5%E7%9A%84%E8%BF%90%E7%AE%97>矩阵的运算</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E7%A6%BB%E6%95%A3%E6%9C%80%E4%BC%98%E5%8C%96>离散最优化</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E7%A9%BA%E9%97%B4>空间</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E7%A9%BA%E9%97%B4%E8%A7%A3%E6%9E%90%E5%87%A0%E4%BD%95>空间解析几何</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E7%AE%97%E6%B3%95%E5%88%86%E7%B1%BB>算法分类</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E7%AE%97%E6%B3%95%E6%80%9D%E6%83%B3>算法思想</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E7%AE%97%E6%B3%95%E8%AF%84%E4%BB%B7%E6%96%B9%E6%B3%95>算法评价方法</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E7%B3%BB%E7%BB%9F%E8%AF%AF%E5%B7%AE>系统误差</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E7%BA%A7%E6%95%B0>级数</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0>线性代数</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E7%BA%BF%E6%80%A7%E6%96%B9%E7%A8%8B%E7%BB%84>线性方程组</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E7%BA%BF%E6%80%A7%E6%96%B9%E7%A8%8B%E7%BB%84%E7%9A%84%E8%A7%A3>线性方程组的解</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E7%BA%BF%E6%80%A7%E6%96%B9%E7%A8%8B%E7%BB%84%E8%A7%A3%E7%9A%84%E7%BB%93%E6%9E%84>线性方程组解的结构</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E7%BA%BF%E6%80%A7%E8%A1%A8>线性表</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E7%BA%BF%E6%80%A7%E8%A1%A8%E7%9A%84%E9%93%BE%E5%BC%8F%E8%A1%A8%E7%A4%BA>线性表的链式表示</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E7%BA%BF%E6%80%A7%E8%A1%A8%E7%9A%84%E9%A1%BA%E5%BA%8F%E8%A1%A8%E7%A4%BA>线性表的顺序表示</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E7%BA%BF%E7%B4%A2%E4%BA%8C%E5%8F%89%E6%A0%91>线索二叉树</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E7%BB%84%E5%90%88%E4%BC%98%E5%8C%96>组合优化</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E7%BB%9F%E8%AE%A1%E6%8E%A8%E6%96%AD>统计推断</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E7%BB%9F%E8%AE%A1%E9%87%8F>统计量</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E7%BD%AE%E4%BF%A1%E5%8C%BA%E9%97%B4>置信区间</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E7%BD%AE%E4%BF%A1%E5%BA%A6>置信度</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E8%84%89%E7%BB%9C>脉络</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E8%A1%8C%E5%88%97%E5%BC%8F>行列式</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E8%A1%8C%E5%88%97%E5%BC%8F%E5%B1%95%E5%BC%80%E5%85%AC%E5%BC%8F>行列式展开公式</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E8%A1%8C%E5%88%97%E5%BC%8F%E8%A7%A3%E6%96%B9%E7%A8%8B%E7%BB%84%E5%BA%94%E7%94%A8>行列式解方程组应用</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E8%BE%A8%E6%9E%90>辨析</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E8%BF%9E%E7%BB%AD%E6%80%A7>连续性</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E9%80%92%E5%BD%92%E4%B8%8E%E9%9D%9E%E9%80%92%E5%BD%92%E8%BD%AC%E6%8D%A2>递归与非递归转换</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E9%80%92%E5%BD%92%E5%BE%AA%E7%8E%AF%E8%BF%AD%E4%BB%A3%E9%81%8D%E5%8E%86>递归循环迭代遍历</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E9%80%92%E5%BD%92%E7%9A%84%E6%80%9D%E6%83%B3>递归的思想</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E9%87%8D%E7%A7%AF%E5%88%86>重积分</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E9%98%9F%E5%88%97>队列</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E9%9A%8F%E6%9C%BA%E4%BA%8B%E4%BB%B6>随机事件</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E9%9A%8F%E6%9C%BA%E4%BA%8B%E4%BB%B6%E7%9A%84%E6%A6%82%E7%8E%87>随机事件的概率</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F>随机变量</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E7%9A%84%E5%88%86%E5%B8%83>随机变量的分布</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E7%9A%84%E6%95%B0%E5%AD%97%E7%89%B9%E5%BE%81>随机变量的数字特征</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E9%9D%99%E6%80%81%E4%BB%A3%E7%90%86>静态代理</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E9%AB%98%E6%96%AF%E7%A7%AF%E5%88%86>高斯积分</a>
<a class=tag-item href=https://ole12138.gitee.io//tags/%E9%AB%98%E7%AD%89%E6%95%B0%E5%AD%A6>高等数学</a></div></div></div></div></div><style>code.has-jax{font:inherit;font-size:100%;background:inherit;border:inherit;color:#515151}</style><script>MathJax={tex:{inlineMath:[['$','$'],['\\(','\\)']],displayMath:[['$$','$$'],['\\[','\\]']],processEscapes:true,processEnvironments:true},options:{skipHtmlTags:['script','noscript','style','textarea','pre']}};window.addEventListener('load',(event)=>{document.querySelectorAll("mjx-container").forEach(function(x){x.parentElement.classList+=' has-jax'})});</script><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script><script type=text/javascript id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script><hr><div class=row><div class=col-sm-8><p class=doc-footer-em><a href=# onclick=resetSidebarPos()>Back to TOP</a></p></div></div></div><footer class=doc-footer><p class=doc-footer-em>Browse <strong><a href=https://github.com/ole12138/ole12138.github.io>Repository</a></strong></p><p>Copyright (c) 2020, Jingmin; All rights reserved.</p><p>Powered by <strong><a href=https://github.com/progrhyme/hugo-theme-bootie-docs>Bootie Docs</a></strong> - theme for <a href=http://gohugo.io/>Hugo</a> by <a href=https://github.com/progrhyme/>progrhyme</a>.</p></footer><script src=https://ole12138.gitee.io//js/jquery.min.js></script><script src=https://ole12138.gitee.io//js/bootstrap.min.js></script><script src=https://ole12138.gitee.io//js/highlight.pack.js></script><script>hljs.initHighlightingOnLoad();</script><script src=https://ole12138.gitee.io//js/ie10-viewport-bug-workaround.js></script><script src=https://ole12138.gitee.io//js/bootie-docs.js></script></body></html>