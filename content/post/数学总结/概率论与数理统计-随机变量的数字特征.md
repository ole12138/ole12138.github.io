---
title: "概率论与数理统计-随机变量的数字特征"
date: 2020-11-27T09:24:48+08:00
draft: false
categories: ["数学"]
tags: ["概率论", "随机变量", "随机变量的数字特征", "数学期望", "均值", "方差", "协方差", "相关系数", "矩", "协方差矩阵", "n维正态分布", "二次型", "矩阵合同"]
markup: pandoc
math: true
---

# 概率论与数理统计-随机变量的数字特征

随机变量及其概率分布章节，我们讨论了**随机变量的分布函数**，它完整反映了随机变量（在一定范围内）的概率特性。

然而很多时候，我们不需要或者很难知道随机变量的完整特性，只需要知道它的某些重要指标。
（比如在调查一群人的身高或者某地居民的收入时，我们经常关心这些量的均值或者个体之间的差异。在碰到多个随机变量时，还需要一些指标来反映这些随机变量之间的关系。）

与随机变量密切相关的指标统称为**数字特征**。重要的数字特征有数学期望、方差、协方差、相关系数以及矩等.

## 数学期望

### 离散型随机变量的数学期望

#### 离散型随机变量的数学期望的定义

设离散型随机变量X的概率分布律为$P\left(X=x_{k}\right)=p\left(x_{k}\right), \quad k=1,2, \cdots$
如果无穷级数$\sum_{k=1}^{\infty} x_{k} p\left(x_{k}\right)$绝对收敛，
则称$\sum_{k=1}^{\infty} x_{k} p\left(x_{k}\right)$为**（离散型）随机变量X的数学期望**，简称数学期望或均值，
记作 $E(X)$，即$E(X)=\sum_{k=1}^{\infty} x_{k} p\left(x_{k}\right)$

#### 常见离散型随机变量的数学期望

##### 0-1分布的期望$E(X)=p$

> 设X服从参数为p的两点分布（0-1分布），即$P(X=0)=1-p, \quad P(X=1)=p, \quad 0<p<1$
> 则$E(X)=1 \times p+0 \times(1-p)=p$

##### 二项分布$X \sim B(n, p)$的期望$E(X)=n p$

> 证明（方法一）：
>
> 因为$X \sim B(n, p)$，所以$P(X=k)=C_{n}^{k} p^{k}(1-p)^{n-k}, \quad k=0,1,2, \cdots, n$
> 则：
> $\begin{aligned} E(X) &=\sum_{k=0}^{n} k \mathrm{C}_{n}^{k} p^{k}(1-p)^{n-k}=\sum_{k=0}^{n} \frac{k n !}{k !(n-k) !} p^{k}(1-p)^{n-k} \\ &=n p \sum_{k=1}^{n} \frac{(n-1) !}{(k-1) ![(n-1)-(k-1)] !} p^{k-1}(1-p)^{(n-1)-(k-1)} \\ &=n p \sum_{k=1}^{n} C_{n-1}^{k-1} p^{k-1}(1-p)^{(n-1)-(k-1)} \end{aligned}$
> 令$m=k-1$,
> 则：
> $\begin{aligned} \sum_{k=1}^{n} \mathrm{C}_{n-1}^{k-1} p^{k-1}(1-p)^{(n-1)-(k-1)} &=\sum_{m=0}^{n-1} \mathrm{C}_{n-1}^{m} p^{m}(1-p)^{(n-1)-m} \\ &=[p+(1-p)]^{n-1} \\ &=1 \end{aligned}$
> 从而$E(X)=n p$

> 证明（方法二）：
> 若$X \sim B(n, p)$，则X可以表示成n个独立的0-1型随机变量的和，
> 即$X=X_{1}+X_{2}+\cdots+X_{n}$，其中$X_{i}=\left\{\begin{array}{ll}1, & \text { 第i次试验中A发生, } \\ 0, & \text { 否则. }\end{array}\right.$，$i=1,2, \cdots, n$
> 根据后面期望的性质：[$E\left(X_{1}+X_{2}+\cdots+X_{n}\right)=E\left(X_{1}\right)+E\left(X_{2}\right)+\cdots+E\left(X_{n}\right)$](#$E\left(X_{1}+X_{2}+\cdots+X_{n}\right)=E\left(X_{1}\right)+E\left(X_{2}\right)+\cdots+E\left(X_{n}\right)$)
> 有$E(X)=E\left(\sum_{i=1}^{n} X_{i}\right)=\sum_{i=1}^{n} E\left(X_{i}\right)=n p$

##### 几何分布 $X \sim G(p)$的期望$E(X)=\frac{1}{p}$

> 因为 $X \sim G(p),$ 所以$P(X=k)=(1-p)^{k-1} p, \quad k=1,2, \cdots$
> 则$E(X)=\sum_{k=1}^{\infty} k(1-p)^{k-1} p=p \sum_{k=1}^{\infty} k(1-p)^{k-1}$
>
> 根据高等数学幂级数的知识，有如下幂级数的和函数：
> $\sum_{k=0}^{\infty} x^{k}=\frac{1}{1-x}, \quad|x|<1$
> 根据幂级数的逐项可导性质，有：
> $\sum_{k=1}^{\infty} k x^{k-1}=\frac{1}{(1-x)^{2}}, \quad|x|<1$
> 取$x=1-p$,则：
> $\sum_{k=1}^{\infty} k(1-p)^{k-1}=\frac{1}{p^{2}}$
> 因此$E(X)=p \sum_{k=1}^{\infty} k(1-p)^{k-1}=\frac{1}{p}$

##### 泊松分布$X\sim P(\lambda)$的期望$E(X)=\lambda$

> 因为$X\sim P(\lambda)$，则$P(X=k)=\frac{\lambda^{k}}{k !} \mathrm{e}^{-\lambda}, \quad k=0,1,2, \cdots$
> 则$E(X)=\sum_{k=0}^{\infty} k \frac{\lambda^{k} \mathrm{e}^{-\lambda}}{k !}=\lambda \mathrm{e}^{-\lambda} \sum_{k=1}^{\infty} \frac{\lambda^{k-1}}{(k-1) !}=\lambda \mathrm{e}^{-\lambda} \mathrm{e}^{\lambda}=\lambda$

### 连续型随机变量的数学期望

#### 连续型随机变量数学期望的定义

设连续型随机变量 $X$ 的密度函数为 $f(x) .$ 
若积分 $\int_{-\infty}^{+\infty} x f(x) \mathrm{d} x$ 绝对收敛,则称 $\int_{-\infty}^{+\infty} x f(x) \mathrm{d} x$ 为**连续型随机变量 $X$ 的数学期望**, 简称**期望**或**均值**, 
记作 $E(X),$ 即$E(X)=\int_{-\infty}^{+\infty} x f(x) \mathrm{d} x$

注意：某些分布的数学期望可能不存在。（密度函数不绝对收敛）

#### 常见连续型随机变量的数学期望

##### 均匀分布$X \sim U[a, b]$的期望$E(X)=\frac{a+b}{2}$

> 因为$X \sim U[a, b]$，所以X的密度函数为：
> $f(x)=\left\{\begin{array}{ll}\frac{1}{b-a}, & a \leqslant x \leqslant b \\ 0, & \text { 其他. }\end{array}\right.$
> 于是：
> $E(X)=\int_{-\infty}^{+\infty} x f(x) \mathrm{d} x=\int_{a}^{b} \frac{x}{b-a} \mathrm{~d} x=\frac{a+b}{2}$ 

##### 指数分布$X \sim e(\lambda)$的期望$E(X)=\frac{1}{\lambda}$

> 因为$X \sim e(\lambda)$，所以X的密度函数为$f(x)=\left\{\begin{array}{ll}\lambda \mathrm{e}^{-\lambda x}, & x \geqslant 0 \\ 0, & x<0\end{array}\right.$
> 于是$E(X)=\int_{-\infty}^{+\infty} x f(x) \mathrm{d} x=\int_{0}^{+\infty} x \lambda \mathrm{e}^{-\lambda x} \mathrm{~d} x=\frac{1}{\lambda}$

##### 正态分布$X \sim N\left(\mu, \sigma^{2}\right)$的期望$E(X)=\mu$

> 因为$X \sim N\left(\mu, \sigma^{2}\right)$，所以X的密度函数为$f(x)=\frac{1}{\sqrt{2 \pi} \sigma} \mathrm{e}^{-\frac{(x-\mu)^{2}}{2 \sigma^{2}}}, \quad-\infty<x<+\infty$
> 于是$E(X)=\int_{-\infty}^{+\infty} x \frac{1}{\sqrt{2 \pi} \sigma} \mathrm{e}^{-\frac{(x-\mu)^{2}}{2 \sigma^{2}}} \mathrm{~d} x$
> 令 $t=\frac{x-\mu}{\sigma},$ 则：
> $\begin{aligned} E(X) &=\frac{1}{\sqrt{2 \pi}} \int_{-\infty}^{+\infty}(\sigma t+\mu) \mathrm{e}^{-\frac{t^{2}}{2}} \mathrm{~d} t \\ &=\frac{\mu}{\sqrt{2 \pi}} \int_{-\infty}^{+\infty} \mathrm{e}^{-\frac{t^{2}}{2}} \mathrm{~d} t \\ &=\mu \end{aligned}$

### 随机变量函数的数学期望

#### 随机变量X的函数$g(X)$的期望

很多时候需要计算随机变量X的某个函数$g(X)$的期望。

方法一：自然会想到先求$g(X)$的分布，再按期望的定义来求$E[g(X)]$.

方法二：但是很多时候，$g(X)$的分布并不容易求出，下面的定理给出另一种方法。

> 定理：设X为一个随机变量，$g(x)$为一元函数，
> 1）如果X为离散型随机变量，分布律为$P\left(X=x_{k}\right)=p\left(x_{k}\right), \quad k=1,2, \cdots$，
> 则$E[g(X)]=\sum_{k=1}^{\infty} g\left(x_{k}\right) p\left(x_{k}\right)$
> 2）如果X为连续性随机变量，密度函数为$f(x)$，
> 则$E[g(X)]=\int_{-\infty}^{+\infty} g(x) f(x) \mathrm{d} x$

这个定理告诉我们，由X的分布即可求出其函数$g(X)$的期望，而无需求出$g(X)$的分布。

#### 二维随机变量$(X,Y)$的函数$g(X,Y)$的期望

类似一维的情况，有两种方法。

方法一：自然会想到先求$g(X,Y)$的分布，再按期望的定义来求$E[g(X,Y)]$.

方法二：但是很多时候，$g(X,Y)$的分布并不容易求出，根据下面的定理，由$(X,Y)$的分布即可直接求出其函数$Z=g(X,Y)$的期望

> 定理：设$(X,Y)$为二维随机变量，$g(x,y)$为二元函数。
> 1）如果$(X,Y)$为二维离散型随机变量，联合分布律为$P\left(X=x_{i}, Y=y_{j}\right)=p_{i j}, \quad i=1,2, \cdots, \quad j=1,2, \cdots$，
> 则$E[g(X, Y)]=\sum_{i=1}^{\infty} \sum_{j=1}^{\infty} g\left(x_{i}, y_{j}\right) p_{i j}$
> 2）如果$(X,Y)$为二维离散型随机变量，联合密度函数为$f(x,y)$，
> 则$E[g(X, Y)]=\int_{-\infty}^{+\infty} \int_{-\infty}^{+\infty} g(x, y) f(x, y) \mathrm{d} x \mathrm{~d} y$



特别的，我们取$g(X,Y) = X$和$g(X,Y)=Y$。即已知$(X,Y)$分布或者密度函数时可求$E(X)$和$E(Y)$.

可以按照方法二求解：

> 以二维连续型为例，设联合密度函数为$f(x,y)$，则：
> $E(X)=\int_{-\infty}^{+\infty} \int_{-\infty}^{+\infty} x f(x, y) \mathrm{d} x \mathrm{~d} y$
> $E(Y)=\int_{-\infty}^{+\infty} \int_{-\infty}^{+\infty} y f(x, y) \mathrm{d} x \mathrm{d} y$

当然也可以按照方法一求解：

> 先求X和Y各自的边缘密度$f_X(x)$和$f_Y(y)$，
> 再利用$E(X)=\int_{-\infty}^{+\infty} x f_{X}(x) \mathrm{d} x$和$E(Y)=\int_{-\infty}^{+\infty} y f_{Y}(y) \mathrm{d} y$求解

#### 高维随机变量$(X_1,X_2, \cdots, X_n)$的函数$g(X_1,X_2, \cdots, X_n)$的期望

类似二维的情况，有相同的两种方法。并且有类似的定理存在。

### 期望的性质

#### $E(C)=C$

设C为常数，则$E(C)=C$

#### $E(kX)= k E(X)$

设k为常数，X为随机变量，则$E(kX)= k E(X)$

#### $E(X+Y)=E(X)+E(Y)$

对于随机变量X和Y，有$E(X+Y)=E(X)+E(Y)$

#### $E\left(X_{1}+X_{2}+\cdots+X_{n}\right)=E\left(X_{1}\right)+E\left(X_{2}\right)+\cdots+E\left(X_{n}\right)$

这是上一条的推论：对于n个随机变量$X_{1}+X_{2}+\cdots+X_{n}$，有$E\left(X_{1}+X_{2}+\cdots+X_{n}\right)=E\left(X_{1}\right)+E\left(X_{2}\right)+\cdots+E\left(X_{n}\right)$

#### 随机变量X与Y独立$\Rightarrow$ $E(X Y)=E(X) E(Y)$

设随机变量X和Y独立，则$E(X Y)=E(X) E(Y)$

> 证明：
> 二维连续型$(X,Y)$情况（离散型类似可证）
> 设$(X,Y)$的联合密度函数为$f(x,y)$,
> 边缘密度函数微分别$f_X(x)$和$f_Y(y)$,
> 由于X和Y独立，则$f(x,y)=f_X(x)f_Y(y)$，
> 则：
> $\begin{aligned} E(X Y) &=\int_{-\infty}^{+\infty} \int_{-\infty}^{+\infty} x y f(x, y) \mathrm{d} x \mathrm{~d} y \\ &=\int_{-\infty}^{+\infty} \int_{-\infty}^{+\infty} x y f_{X}(x) f_{Y}(y) \mathrm{d} x \mathrm{~d} y \\ &=\left(\int_{-\infty}^{+\infty} x f_{X}(x) \mathrm{d} x\right)\left(\int_{-\infty}^{+\infty} y f_{Y}(y) \mathrm{d} y\right) \\ &=E(X) E(Y) \end{aligned}$

#### $X_1,X_2, \cdots, X_n$相互独立$\Rightarrow$ $E\left(X_{1} X_{2} \cdots X_{n}\right)=E\left(X_{1}\right) E\left(X_{2}\right) \cdots E\left(X_{n}\right)$

这是上一条的推论：设n个随机变量$X_1,X_2, \cdots, X_n$相互独立，则$E\left(X_{1} X_{2} \cdots X_{n}\right)=E\left(X_{1}\right) E\left(X_{2}\right) \cdots E\left(X_{n}\right)$

## 方差

随机变量的期望反应的是随机变量的均值。除了均值之外，人们还常关心随机变量取值的波动性或者稳定性如何。
衡量波动性的一个简单办法是看随机变量每个可能取值与期望值的差距$|X-E(X)|$,很显然这是一个随机变量。
因此想到用$|X-E(X)|$的均值$E\left[|X-E(X)|\right]$来反映波动性，
但绝对值在数学上比较难处理，因此实际中使用$E\left[X-E(X)\right]^2$来**反映随机变量波动性的大小**，也即反映随机变量稳定性如何，由此引出方差的定义。

### 方差的定义与常用公式

#### 方差的定义$D(X)=E\left[X-E(X)\right]^2$

设X为一随机变量，若$E\left[X-E(X)\right]^2$存在，则称$E\left[X-E(X)\right]^2$为随机变量X的方差，记为$D(X)$，
即$D(X)=E\left[X-E(X)\right]^2$

注意：随机变量X的方差$D(X)$结果是个数值。

#### 方差的常用式$D(X)=E\left(X^{2}\right)-[E(X)]^{2}$

> 证明
> 利用期望的性质，则
> $\begin{aligned} D(X) &=E[X-E(X)]^{2}=E\left\{X^{2}-2 X E(X)+[E(X)]^{2}\right\} \\ &=E\left(X^{2}\right)-2[E(X)]^{2}+[E(X)]^{2} \\ &=E\left(X^{2}\right)-[E(X)]^{2} \end{aligned}$

### 离散型随机变量的方差

设离散型随机变量X的概率分布律为$P\left(X=x_{k}\right)=p\left(x_{k}\right), \quad k=1,2, \cdots$，
则随机变量X的方差
$D(X)=E\left[X-E(X)\right]^2 \\=\sum_{i=1}^{\infty}\left[x_{i}-E(X)\right]^{2} p\left(x_{i}\right)$

也常利用$D(X)=E\left(X^{2}\right)-[E(X)]^{2}$来计算某些离散型随机变量的方差。

#### 0-1分布的方差$D(X)=p(1-p)$

> 证明
> 设X服从参数为p的两点分布（0-1分布），[显然$E(X)=p$](#0-1分布的期望$E(X)=p$),
> 又$E\left(X^{2}\right)=1^{2} \times p+0^{2} \times(1-p)=p$，
> 则$D(X)=E\left(X^{2}\right)-[E(X)]^{2}=p(1-p)$

#### 二项分布$X \sim B(n, p)$的方差$D(X)=n p(1-p)$

> 证明（要用到后面方差的性质）：
>
> 我们知道$X=X_{1}+X_{2}+\cdots+X_{n}$， （参见[二项分布$X \sim B(n, p)$期望$E(X)=n p$的证明方法二](#二项分布$X \sim B(n, p)$的期望$E(X)=n p$)）
> 而[0-1分布的方差$D(X_i)=p(1-p)$](#0-1分布的方差$D(X)=p(1-p)$),
> 又$X_1,X_2, \cdots, X_n$相互独立，
> 于是根据[$X_1,X_2, \cdots, X_n$相互独立$\Rightarrow$ $D\left(X_{1}+X_{2}+\cdots+X_{n}\right)=D\left(X_{1}\right)+D\left(X_{2}\right)+\cdots+D\left(X_{n}\right)$](#随机变量$X_1,X_2, \cdots, X_n$相互独立$\Rightarrow$ $D\left(X_{1}+X_{2}+\cdots+X_{n}\right)=D\left(X_{1}\right)+D\left(X_{2}\right)+\cdots+D\left(X_{n}\right)$)
> 得$D(X)=D\left(\sum_{i=1}^{n} X_{i}\right)=\sum_{i=1}^{n} D\left(X_{i}\right)=n p(1-p)$

#### 泊松分布$X\sim P(\lambda)$的方差$D(X)=\lambda$

> 我们知道[泊松分布$X\sim P(\lambda)$的期望$E(X)=\lambda$](#泊松分布$X\sim P(\lambda)$的期望$E(X)=\lambda$)
> 而：
> $\begin{aligned} E\left(X^{2}\right) &=\sum_{k=0}^{\infty} k^{2} \frac{\lambda^{k}}{k !} \mathrm{e}^{-\lambda}=\sum_{k=1}^{\infty} k \frac{\lambda^{k}}{(k-1) !} \mathrm{e}^{-\lambda} \\ &=\sum_{k=1}^{\infty}[(k-1)+1] \frac{\lambda^{k}}{(k-1) !} \mathrm{e}^{-\lambda} \\ &=\sum_{k=2}^{\infty} \frac{\lambda^{k}}{(k-2) !} \mathrm{e}^{-\lambda}+\sum_{k=1}^{\infty} \frac{\lambda^{k}}{(k-1) !} \mathrm{e}^{-\lambda} \end{aligned}$
> 又有$\sum_{k=1}^{\infty} \frac{\lambda^{k}}{(k-1) !} \mathrm{e}^{-\lambda}=\lambda \cdot\sum_{k=1}^{\infty} \frac{\lambda^{k-1}}{(k-1) !} \mathrm{e}^{-\lambda}=\lambda$ 
> 以及$\sum_{k=2}^{\infty} \frac{\lambda^{k}}{(k-2) !} \mathrm{e}^{-\lambda}=\lambda^{2} \mathrm{e}^{-\lambda} \sum_{k=2}^{\infty} \frac{\lambda^{k-2}}{(k-2) !}=\lambda^{2} \mathrm{e}^{-\lambda} \mathrm{e}^{\lambda}=\lambda^{2}$
> 所以$E\left(X^{2}\right)=\lambda^{2}+\lambda$
> 则$D(X)=E\left(X^{2}\right)-[E(X)]^{2}=\lambda$

### 连续型随机变量的方差

设连续型随机变量 $X$ 的密度函数为 $f(x) .$ 
则随机变量X的方差
$D(X)=\int_{-\infty}^{+\infty}[x-E(X)]^{2} f(x) \mathrm{d} x$

#### 均匀分布$X \sim U[a, b]$的方差$D(X)=\frac{(b-a)^{2}}{12}$

> $X \sim U[a, b]$，
> 前面已求出$E(X)=\frac{a+b}{2}$，
> 而$E\left(X^{2}\right)=\int_{a}^{b} \frac{x^{2}}{b-a} \mathrm{~d} x=\frac{a^{2}+a b+b^{2}}{3}$
> 从而$D(X)=E\left(X^{2}\right)-[E(X)]^{2}=\frac{(b-a)^{2}}{12}$

#### 指数分布$X \sim e(\lambda)$的方差$D(X)=\frac{1}{\lambda^{2}}$

> 因为$X \sim e(\lambda)$，
> 前面已经求得$E(X)=\frac{1}{\lambda}$，
> 而随机变量函数$X^2$的期望$E\left(X^{2}\right)=\int_{0}^{+\infty} x^{2} \lambda \mathrm{e}^{-\lambda x} \mathrm{~d} x=\frac{2}{\lambda^{2}}$
> 从而$D(X)=E\left(X^{2}\right)-[E(X)]^{2}=\frac{1}{\lambda^{2}}$

#### 正态分布$X \sim N\left(\mu, \sigma^{2}\right)$的方差$D(X)=\sigma^{2}$

> $X \sim N\left(\mu, \sigma^{2}\right)$，
> 前面已求出$E(X)=\mu$，
> 而$E\left(X^{2}\right)=\int_{-\infty}^{+\infty} x^{2} \frac{1}{\sqrt{2 \pi} \sigma} \mathrm{e}^{-\frac{(x-\mu)^{2}}{2 \sigma^{2}}} \mathrm{~d} x$，
> 令$t=\frac{x-\mu}{\sigma}$，利用分部积分法容易求得$E\left(X^{2}\right)=\sigma^{2}+\mu^{2}$，
>
> 从而$D(X)=E\left(X^{2}\right)-[E(X)]^{2}=\sigma^{2}$

### 方差的性质

方差就具有如下一些重要性质（设所涉及的随机变量的方差均存在）

#### $D(C)=0$

设 $C$ 为一常数, $X$ 为一随机变量, 则$D(C)=0$

#### $D(k X)=k^{2} D(X)$

设 $k$ 为一常数, $X$ 为一随机变量, 则$D(k X)=k^{2} D(X)$

> 证明
> $D(k X)=E\left(k^{2} X^{2}\right)-[E(k X)]^{2}\\=k^{2} E\left(X^{2}\right)-k^{2}[E(X)]^{2}\\=k^{2} D(X)$

#### 随机变量X与Y相互独立$\Rightarrow$ $D(X+Y)=D(X)+D(Y)$

对随机变量 $X$ 和 $Y$ 相互独立, 则$D(X+Y)=D(X)+D(Y)$

> 证明
> $\begin{aligned} D(X+Y) &=E(X+Y)^{2}-[E(X+Y)]^{2} \\ &=E\left(X^{2}+2 X Y+Y^{2}\right)-\left\{[E(X)]^{2}+2 E(X) E(Y)+[E(Y)]^{2}\right\} \\ &=E\left(X^{2}\right)-[E(X)]^{2}+E\left(Y^{2}\right)-[E(Y)]^{2}+2[E(X Y)-E(X) E(Y)] \\ &=D(X)+D(Y)+2[E(X Y)-E(X) E(Y)] \end{aligned}$
> X与Y相互独立，由[随机变量X与Y独立$\Rightarrow$ $E(X Y)=E(X) E(Y)$](#随机变量X与Y独立$\Rightarrow$ $E(X Y)=E(X) E(Y)$)可知 $E(X Y)-E(X) E(Y)=0$，
> 从而$D(X+Y)=D(X)+D(Y)$

#### 随机变量$X_1,X_2, \cdots, X_n$相互独立$\Rightarrow$ $D\left(X_{1}+X_{2}+\cdots+X_{n}\right)=D\left(X_{1}\right)+D\left(X_{2}\right)+\cdots+D\left(X_{n}\right)$

这是上一条的推论。

## 协方差与相关系数

期望反映了一个随机变量的平均取值，
方差反映了一个随机变量的波动大小。

有时还需要描述两个随机变量之间的相互关系，这就需要引入协方差和相关系数的概念。

### 协方差的定义

设随机交量 $X$ 和 $Y$ 的期望都存在, 且 $E(X Y)$ 也存在,
我们称$E[(X-E(X))(Y-E(Y)]]$ 为 $X$ 和 $Y$ 的**协方差**, 记为 $\operatorname{Cov}(X, Y),$ 
即$\operatorname{Cov}(X, Y)=E[(X-E(X))(Y-E(Y))]$

> 分析一下协方差的意义：
> 如果协方差为正，说明$X-E(X)$和$Y-E(Y)$倾向于同时为正或者同时为负，即X大于均值E(X)时，Y往往大于均值E(Y)，X与Y变化趋势比较一致。
> 如果协方差为负，说明$X-E(X)$和$Y-E(Y)$倾向于有相反的变化趋势。
> 因此，**协方差一定程度上反映了两个随机变量之间的联系**。

除了上面协方差的定义式，协方差的计算也常用公式[$\operatorname{Cov}(X, Y)=E(X Y)-E(X) E(Y)$](#$\operatorname{Cov}(X, Y)=E(X Y)-E(X) E(Y)$)

### 协方差的性质

协方差有如下性质

#### $\operatorname{Cov}(X, Y)=\operatorname{Cov}(Y, X)$

#### $\operatorname{Cov}(X, C)=0$

设C为常数，X为随机变量，则$\operatorname{Cov}(X, C)=0$

#### $\operatorname{Cov}(a X+b Y, Z)=a \operatorname{Cov}(X, Z)+b \operatorname{Cov}(Y, Z)$

设a,b为常数，X,Y,Z为随机变量，则$\operatorname{Cov}(a X+b Y, Z)=a \operatorname{Cov}(X, Z)+b \operatorname{Cov}(Y, Z)$

#### $\operatorname{Cov}(X, Y)=E(X Y)-E(X) E(Y)$

此公式由定义式变形而来。这条公式也时计算协方差时的常用公式

#### 随机变量X与Y相互独立$\Rightarrow$ $\operatorname{Cov}(X, Y)=0$

这算是上一条的推论：
X与Y相互独立，则$E(X Y)=E(X) E(Y)$,
根据上一条性质$\operatorname{Cov}(X, Y)=E(X Y)-E(X) E(Y)$
可知$\operatorname{Cov}(X, Y)=0$

#### $D(X+Y)=D(X)+D(Y)+2 \operatorname{Cov}(X, Y)$

### 相关系数的定义

从协方差的定义可以看出，协方差$\operatorname{Cov}(X, Y)$是有量纲的量，它的量纲等于X与Y的乘积。
如果X及Y的量纲改变，那么其数值就会改变，进而协方差$\operatorname{Cov}(X, Y)$的数值也会发生较大的变化。
这样用协方差$\operatorname{Cov}(X, Y)$来刻画X与Y的关系就不方便了。为了客服这个困难，引进随机变量之间的相关系数的概念。

**定义**：设随机变量X，Y的方差$D(X)$与$D(Y)$均为正，
称$\frac{\operatorname{Cov}(X, Y)}{\sqrt{D(X) D(Y)}}$为X与Y的**相关系数**，记为$\rho_{XY}$,
即$\rho_{X Y}=\frac{\operatorname{Cov}(X, Y)}{\sqrt{D(X) D(Y)}}$

不难验证，X和Y的相关系数是X和Y标准化[^1]后的随机变量的协方差：
$\rho_{X Y}=\operatorname{Cov}\left(\frac{X-E(X)}{\sqrt{D(X)}}, \frac{Y-E(Y)}{\sqrt{D(Y)}}\right)$

[^ 1]: 注意区分[一般的无量纲化](https://zhuanlan.zhihu.com/p/93350539)操作，以及[随机变量的标准化](https://baike.baidu.com/item/%E6%A0%87%E5%87%86%E5%8C%96%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F)

### 相关系数的性质

#### $\left|\rho_{X Y}\right| \leqslant 1$

设$\rho_{X Y}$是随机变量X与Y的相关系数，则$\left|\rho_{X Y}\right| \leqslant 1$

#### $\left|\rho_{X Y}\right| = 1 \Leftrightarrow Y=aX+b (a \neq 0)$

设$\rho_{X Y}$是随机变量X与Y的相关系数，$\left|\rho_{X Y}\right| = 1$的充分必要条件是$P(Y=aX+b)=1,  (a \neq 0)$,
且$\rho_{X Y}=\left\{\begin{array}{ll}1, & a>0 \\ -1, & a<0\end{array}\right.$

从上面两条性质可以看出，相关系数刻画了随机变量之间的线性相关性；
当$\rho_{X Y}$越接近1时，X与Y的正线性相关性越明显；当$\rho_{X Y}$越接近-1时，X与Y的负线性相关性就越明显；
当$\rho_{X Y}$越接近0时，X与Y的线性相关性就越弱，当$\rho_{X Y}=0$我们也称X与Y不相关。

#### 随机变量X与Y相互独立$\Rightarrow$ $\rho_{X Y}=0$

我们知道[随机变量X与Y相互独立$\Rightarrow$ $\operatorname{Cov}(X, Y)=0$](#随机变量X与Y相互独立$\Rightarrow$ $\operatorname{Cov}(X, Y)=0$)，
从而$\rho_{X Y}=0$

注意：$\rho_{X Y}=0$，并不能得到X与Y独立的结论。

### 常见二维随机变量的相关系数

#### $(X,Y)$服从圆盘均匀分布时的相关系数$\rho_{X Y}=0$

二维连续型随机变量$(X,Y)$服从圆盘$x^{2}+y^{2} \leqslant 1$均匀分布时，
联合密度函数为$f(x, y)=\left\{\begin{array}{ll}\frac{1}{\pi}, & x^{2}+y^{2} \leqslant 1 \\ 0, & \text { 其他. }\end{array}\right.$，
则：
$E(X Y)=\iint_{x^{2}+y^{2} \leqslant 1} \frac{x y}{\pi} \mathrm{d} x \mathrm{~d} y=\frac{1}{\pi} \int_{-1}^{1} \mathrm{~d} x \int_{-\sqrt{1-x^{2}}}^{\sqrt{1-x^{2}}} x y \mathrm{~d} y=0$
$E(X)=\iint_{x^{2}+y^{2} \leqslant 1} \frac{x}{\pi} \mathrm{d} x \mathrm{~d} y=\frac{1}{\pi} \int_{-1}^{1} \mathrm{~d} x \int_{-\sqrt{1-x^{2}}}^{\sqrt{1-x^{2}}} x \mathrm{~d} y=0$
同理可得$E(Y)=0$
于是$\operatorname{Cov}(X, Y)=E(X Y)-E(X) E(Y)=0$
从而$\rho_{X Y}=0$

#### 二维正态分布$(X, Y) \sim N\left(\mu_{1}, \mu_{2}, \sigma_{1}^{2}, \sigma_{2}^{2}, \rho\right)$时的相关系数$\rho_{X Y}=\rho$

$(X, Y) \sim N\left(\mu_{1}, \mu_{2}, \sigma_{1}^{2}, \sigma_{2}^{2}, \rho\right),$ 
上一章[二维连续型随机变量的正态分布](./概率论与数理统计-随机变量及其概率分布#二维连续型随机变量的正态分布)有结论：若$(X, Y) \sim N\left(\mu_{1}, \mu_{2}, \sigma_{1}^{2}, \sigma_{2}^{2}, \rho\right)$，则$X \sim N\left(\mu_{1}, \sigma_{1}^{2}\right), Y \sim N\left(\mu_{2}, \sigma_{2}^{2}\right)$。
上一章[求随机函数$Z=X+Y$的分布](./概率论与数理统计-随机变量及其概率分布#连续型二维随机变量$(X,Y)$，求随机函数$Z=X+Y$的分布)还有结论：若$X \sim N\left(\mu_{1}, \sigma_{1}^{2}\right), Y \sim N\left(\mu_{2}, \sigma_{2}^{2}\right)$，且X与Y独立，则$X+Y \sim N\left(\mu_{1}+\mu_{2}, \sigma_{1}^{2}+\sigma_{2}^{2}\right)$。
由这两条结论以及一维正态分布的期望和方差，立即可知：
$E(X)=\mu_{1}, E(Y)=\mu_{2}, D(X)=\sigma_{1}^{2}, D(Y)=\sigma_{2}^{2}$
于是协方差为：
$\begin{aligned} \operatorname{Cov}(X, Y) &=\frac{\sigma_{1} \sigma_{2}}{2 \pi \sqrt{1-\rho^{2}}} \int_{-\infty}^{+\infty} \int_{-\infty}^{+\infty} u_{1} u_{2} \mathrm{e}^{-\frac{u_{1}^{2}-2 \rho u_{1} u_{2}+u_{2}^{2}}{2\left(1-\rho^{2}\right)}} \mathrm{d} u_{1} \mathrm{~d} u_{2} \\ &=\frac{\sigma_{1} \sigma_{2}}{2 \pi \sqrt{1-\rho^{2}}} \int_{-\infty}^{+\infty} \int_{-\infty}^{+\infty} u_{1} u_{2} \mathrm{e}^{-\frac{1}{2}\left[\frac{\left(u_{1}-\rho u_{2}\right)^{2}}{1-\rho^{2}}+u_{2}^{2}\right]} \mathrm{d} u_{1} \mathrm{~d} u_{2} \end{aligned}$
再作变量代换$t_{1}=\frac{u_{1}-\rho u_{2}}{\sqrt{1-\rho^{2}}}, t_{2}=u_{2}$，则：
$\begin{aligned} \operatorname{Cov}(X, Y) &=\frac{\sigma_{1} \sigma_{2} \rho}{2 \pi} \int_{-\infty}^{+\infty} \int_{-\infty}^{+\infty} t_{2}^{2} \mathrm{e}^{-\frac{1}{2}\left(t_{1}^{2}+t_{2}^{2}\right)} \mathrm{d} t_{1} \mathrm{~d} t_{2} \\ &=\sigma_{1} \sigma_{2} \rho \end{aligned}$
从而$\rho_{X Y}=\rho$

> 上面得到了结论：二维正态分布$(X, Y) \sim N\left(\mu_{1}, \mu_{2}, \sigma_{1}^{2}, \sigma_{2}^{2}, \rho\right)$，相关系数$\rho_{X Y}=\rho$
> 而上一章有结论：[二维正态分布$(X, Y) \sim N\left(\mu_{1}, \mu_{2}, \sigma_{1}^{2}, \sigma_{2}^{2}, \rho\right)$中X与Y独立$\Leftrightarrow$ $\rho = 0$](./概率论与数理统计-随机变量及其概率分布#二维正态分布$(X, Y) \sim N\left(\mu_{1}, \mu_{2}, \sigma_{1}^{2}, \sigma_{2}^{2}, \rho\right)$中X与Y独立$\Leftrightarrow$ $\rho = 0$)，
> 结合可得结论二维正态分布$(X, Y) \sim N\left(\mu_{1}, \mu_{2}, \sigma_{1}^{2}, \sigma_{2}^{2}, \rho\right)$中X与Y独立$\Leftrightarrow$ 相关系数$\rho_{XY} = 0$

## 矩与协方差矩阵

### 随机变量X的k阶原点矩

设X是随机变量，若$\mu_{k}=E\left(X^{k}\right), \quad k=1,2, \cdots$存在，则称它为X的k阶原点矩。

### 随机变量X的k阶中心矩

设X是随机变量，若$\nu_{k}=E\left[(X-E(X))^{k}\right], \quad k=1,2,3, \cdots$存在，则称它为X的k阶中心矩。

X的二阶中心矩即为X的方差$D(X)$

### 随机变量X与Y的$k+l$阶混合原点矩

设X和Y是随机变量，若$E\left(X^{k} Y^{l}\right), \quad k, l=1,2, \cdots$存在，则称它为X与Y的$k+l$阶混合原点矩。

### 随机变量X与Y的$k+l$阶混合中心矩

设X和Y是随机变量，若$E\left[(X-E(X))^{k}(Y-E(Y))^{l}\right], \quad k, l=1,2, \cdots$存在，则称它为X与Y的$k+l$阶混合中心矩。

X和Y的协方差$\operatorname{Cov}(X, Y)$就是X和Y的二阶混合中心矩。

### 协方差矩阵

设n维随机变量$\left(X_{1}, X_{2}, \cdots, X_{n}\right)$的二阶混合中心矩（两两的协方差）：
$c_{i j}=\operatorname{Cov}\left(X_{i}, X_{j}\right)=E\left[\left(X_{i}-E\left(X_{i}\right)\right)\left(X_{j}-E\left(X_{j}\right)\right)\right], \quad i, j=1,2, \cdots,n$
都存在，
则称矩阵$\boldsymbol{C}=\left(\begin{array}{cccc}c_{11} & c_{12} & \cdots & c_{1 n} \\ c_{21} & c_{22} & \cdots & c_{2 n} \\ \vdots & \vdots & & \vdots \\ c_{n 1} & c_{n 2} & \cdots & c_{n n}\end{array}\right)$
为n维随机变量$\left(X_{1}, X_{2}, \cdots, X_{n}\right)$的协方差矩阵

### 期望向量

设n维随机变量$\left(X_{1}, X_{2}, \cdots, X_{n}\right)$的每一个分量$X_{i}(i=1,2, \cdots,n)$的期望$E(X_i)$都存在，
则称向量$\mu=\left(\begin{array}{c}\mu_{1} \\ \mu_{2} \\ \vdots \\ \mu_{n}\end{array}\right)=\left(\begin{array}{c}E\left(X_{1}\right) \\ E\left(X_{2}\right) \\ \vdots \\ E\left(X_{n}\right)\end{array}\right)$
为n维随机变量$\left(X_{1}, X_{2}, \cdots, X_{n}\right)$的期望向量。

## n维正态分布

### 二维正态分布的矩阵表示法

先回忆[二维正态分布](./概率论与数理统计-随机变量及其概率分布#二维连续型随机变量的正态分布)：其联合密度函数为：
$\begin{aligned} f(x, y)=& \frac{1}{2 \pi \sigma_{1} \sigma_{2} \sqrt{1-\rho^{2}}} \\ & \times \exp \left\{-\frac{1}{2\left(1-\rho^{2}\right)}\left[\frac{\left(x-\mu_{1}\right)^{2}}{\sigma_{1}^{2}}-2 \rho \frac{\left(x-\mu_{1}\right)\left(y-\mu_{2}\right)}{\sigma_{1} \sigma_{2}}+\frac{\left(y-\mu_{2}\right)^{2}}{\sigma_{2}^{2}}\right]\right\} \end{aligned}$

我们想把指数部分写成矩阵形式，
首先我们记$\boldsymbol{x}=\left(\begin{array}{l}x_{1} \\ x_{2}\end{array}\right)$
有了[期望向量](#期望向量)和[协方差矩阵](#协方差矩阵)的概念，
我们可得$(X_1,Y)$的期望向量与协方差：
$\boldsymbol{\mu}=\left(\begin{array}{l}\mu_{1} \\ \mu_{2}\end{array}\right)$，
$\boldsymbol{C}=\left(\begin{array}{ll}c_{11} & c_{12} \\ c_{21} & c_{22}\end{array}\right)=\left(\begin{array}{cc}\sigma_{1}^{2} & \rho \sigma_{1} \sigma_{2} \\ \rho \sigma_{1} \sigma_{2} & \sigma_{2}^{2}\end{array}\right)$
而C的行列式，逆矩阵分别为：
$|\boldsymbol{C}|=\sigma_{1}^{2} \sigma_{2}^{2}\left(1-\rho^{2}\right)$，
$C^{-1}=\frac{1}{\sigma_{1}^{2} \sigma_{2}^{2}\left(1-\rho^{2}\right)}\left(\begin{array}{cc}\sigma_{2}^{2} & -\rho \sigma_{1} \sigma_{2} \\ -\rho \sigma_{1} \sigma_{2} & \sigma_{1}^{2}\end{array}\right)$
通过简单计算可知$(X_1,Y)$的联合密度可写成
$f\left(x_{1}, x_{2}\right)=(2 \pi)^{-\frac{2}{2}}|C|^{-\frac{1}{2}} \exp \left\{-\frac{1}{2}(x-\mu)^{\mathrm{T}} C^{-1}(x-\mu)\right\}$

### n维正态分布的矩阵表示法

沿用上述形式，可以给出n维正态分布的定义：

若有n维随机变量$\left(X_{1}, X_{2}, \cdots, X_{n}\right)$的联合密度函数维：
$f\left(x_{1}, x_{2}, \cdots, x_{n}\right)=(2 \pi)^{-\frac{n}{2}}|C|^{-\frac{1}{2}} \exp \left\{-\frac{1}{2}(x-\mu)^{\mathrm{T}} C^{-1}(x-\mu)\right\}$
其中$\boldsymbol{x}=\left(\begin{array}{c}x_{1} \\ x_{2} \\ \vdots \\ x_{n}\end{array}\right)$，$\mu$ 及 $C$ 分别表示 $\left(X_{1}, X_{2}, \cdots, X_{n}\right)$ 的期望向量及协方差矩阵，
则称n维随机变量$\left(X_{1}, X_{2}, \cdots, X_{n}\right)$服从**n维正态分布**。

服从n维正态分布的随机变量也称n维正态随机变量。

### n维正态分布的性质

1. n维正态随机变量$\left(X_{1}, X_{2}, \cdots, X_{n}\right)$的每个分量$X_{i}(i=1,2, \cdots,n)$都服从一维正态分布。
2. n维随机变量$\left(X_{1}, X_{2}, \cdots, X_{n}\right)$服从n维正态分布$\Leftrightarrow$n维随机变量$\left(X_{1}, X_{2}, \cdots, X_{n}\right)$的任意线性组合$\sum_{i=1}^{n} l_{i} X_{i}$服从一维正态分布（其中 $l_{1}, l_{2}, \cdots, l_{n}$ 不全为零 ）
3. 若n维随机变量$\left(X_{1}, X_{2}, \cdots, X_{n}\right)$服从n维正态分布，则"$X_{1}, X_{2}, \cdots, X_{n}$相互独立”等价于“$X_{1}, X_{2}, \cdots, X_{n}$两两不相关”

## 附：常见随机变量分布的期望与方差汇总

### 常见离散型随机变量的分布

| 离散型随机变量的分布       | 期望               | 方差            |
| -------------------------- | ------------------ | --------------- |
| 0-1分布                    | $E(X)=p$           | $D(X)=p(1-p)$   |
| 二项分布$X \sim B(n, p)$   | $E(X)=n p$         | $D(X)=n p(1-p)$ |
| 泊松分布$X\sim P(\lambda)$ | $E(X)=\lambda$     | $D(X)=\lambda$  |
| 几何分布 $X \sim G(p)$     | $E(X)=\frac{1}{p}$ |                 |

### 常见连续型随机变量的分布

| 连续型随机变量的分布                           | 期望                     | 方差                         |
| ---------------------------------------------- | ------------------------ | ---------------------------- |
| 均匀分布$X \sim U[a, b]$                       | $E(X)=\frac{a+b}{2}$     | $D(X)=\frac{(b-a)^{2}}{12}$  |
| 指数分布$X \sim e(\lambda)$                    | $E(X)=\frac{1}{\lambda}$ | $D(X)=\frac{1}{\lambda^{2}}$ |
| 正态分布$X \sim N\left(\mu, \sigma^{2}\right)$ | $E(X)=\mu$               | $D(X)=\sigma^{2}$            |

